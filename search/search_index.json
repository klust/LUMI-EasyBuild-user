{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Package list","text":"<p>Last processed: Thu Sep 18 15:21:29 UTC 2025</p> <p>: Specific user documentation available</p> <p>: Technical documentation available</p> <p>: Archived application</p>","boost":0.5},{"location":"#a","title":"a","text":"<ul> <li> <p>absl </p> </li> <li> <p>ant </p> </li> <li> <p>APR </p> </li> <li> <p>APR-util </p> </li> <li> <p>AsciiDoc</p> </li> </ul>","boost":0.5},{"location":"#b","title":"b","text":"<ul> <li> <p>baselibs</p> </li> <li> <p>Bison</p> </li> <li> <p>Blitz++</p> </li> <li> <p>Boost</p> </li> <li> <p>buildtools</p> </li> <li> <p>bzip2</p> </li> </ul>","boost":0.5},{"location":"#c","title":"c","text":"<ul> <li> <p>ccpe </p> </li> <li> <p>ccpe-cpe </p> </li> <li> <p>CDO</p> </li> <li> <p>Chapel </p> </li> <li> <p>CMake</p> </li> <li> <p>CMOR</p> </li> <li> <p>CrayPath</p> </li> <li> <p>cURL</p> </li> <li> <p>CVS-cvs</p> </li> </ul>","boost":0.5},{"location":"#d","title":"d","text":"<ul> <li> <p>DocBook-XSL </p> </li> <li> <p>Doxygen</p> </li> </ul>","boost":0.5},{"location":"#e","title":"e","text":"<ul> <li> <p>EasyBuild</p> </li> <li> <p>ecCodes</p> </li> <li> <p>Elk </p> </li> <li> <p>ESMF </p> </li> <li> <p>expat</p> </li> </ul>","boost":0.5},{"location":"#f","title":"f","text":"<ul> <li> <p>feh </p> </li> <li> <p>FFmpeg </p> </li> <li> <p>file</p> </li> <li> <p>flex</p> </li> </ul>","boost":0.5},{"location":"#g","title":"g","text":"<ul> <li> <p>GDAL </p> </li> <li> <p>Ghostscript </p> </li> <li> <p>git </p> </li> <li> <p>Go </p> </li> <li> <p>GPP </p> </li> <li> <p>GROMACS</p> </li> <li> <p>GROMACS-SWAXS </p> </li> <li> <p>gv </p> </li> </ul>","boost":0.5},{"location":"#h","title":"h","text":"<ul> <li> <p>help2man</p> </li> <li> <p>hpcat </p> </li> <li> <p>htop</p> </li> <li> <p>hwloc </p> </li> <li> <p>HyperQueue</p> </li> </ul>","boost":0.5},{"location":"#i","title":"i","text":"<ul> <li> <p>Imlib2 </p> </li> <li> <p>Info-ZIP </p> </li> </ul>","boost":0.5},{"location":"#j","title":"j","text":"<ul> <li>json-c</li> </ul>","boost":0.5},{"location":"#l","title":"l","text":"<ul> <li> <p>LAMMPS</p> </li> <li> <p>libexif </p> </li> <li> <p>libnsl </p> </li> <li> <p>libreadline</p> </li> <li> <p>libtirpc </p> </li> <li> <p>libtree </p> </li> <li> <p>libxc </p> </li> <li> <p>likwid </p> </li> <li> <p>lumi-allocations </p> </li> <li> <p>lumi-CPEtools</p> </li> <li> <p>lumi-GPUtools </p> </li> <li> <p>lumi-tools </p> </li> <li> <p>lumi-training-tools </p> </li> <li> <p>lz4 </p> </li> <li> <p>lzip-bootstrap </p> </li> <li> <p>lzip-tools </p> </li> </ul>","boost":0.5},{"location":"#m","title":"m","text":"<ul> <li> <p>M4</p> </li> <li> <p>makedepf90 </p> </li> </ul>","boost":0.5},{"location":"#n","title":"n","text":"<ul> <li> <p>nano </p> </li> <li> <p>NCO</p> </li> <li> <p>ncurses </p> </li> <li> <p>ncurses-headers</p> </li> <li> <p>Nek5000</p> </li> <li> <p>nmap </p> </li> </ul>","boost":0.5},{"location":"#o","title":"o","text":"<ul> <li> <p>oneAPI-DPCPP-compiler</p> </li> <li> <p>OpenFOAM </p> </li> <li> <p>OpenSSL</p> </li> <li> <p>OpenStackClient</p> </li> <li> <p>ORCA </p> </li> </ul>","boost":0.5},{"location":"#p","title":"p","text":"<ul> <li> <p>p7zip </p> </li> <li> <p>Paraver </p> </li> <li> <p>PCRE2</p> </li> <li> <p>PDT </p> </li> <li> <p>Perl</p> </li> <li> <p>PLUMED</p> </li> <li> <p>pocl-UNFINISHED </p> </li> <li> <p>PROJ </p> </li> <li> <p>PRoot </p> </li> <li> <p>PyTorch </p> </li> </ul>","boost":0.5},{"location":"#q","title":"q","text":"<ul> <li> <p>Qt5 </p> </li> <li> <p>QuantumESPRESSO </p> </li> </ul>","boost":0.5},{"location":"#r","title":"r","text":"<ul> <li> <p>R </p> </li> <li> <p>rclone </p> </li> <li> <p>Rust </p> </li> </ul>","boost":0.5},{"location":"#s","title":"s","text":"<ul> <li> <p>ScaLAPACK </p> </li> <li> <p>SCons </p> </li> <li> <p>seq-integer-headerlib </p> </li> <li> <p>Serf </p> </li> <li> <p>snakemake </p> </li> <li> <p>spdlog </p> </li> <li> <p>SQLite </p> </li> <li> <p>stack</p> </li> <li> <p>Subversion </p> </li> <li> <p>syslibs </p> </li> <li> <p>systools</p> </li> </ul>","boost":0.5},{"location":"#t","title":"t","text":"<ul> <li> <p>tabulate-pranav </p> </li> <li> <p>talloc </p> </li> <li> <p>tree </p> </li> </ul>","boost":0.5},{"location":"#u","title":"u","text":"<ul> <li>UnZip </li> </ul>","boost":0.5},{"location":"#v","title":"v","text":"<ul> <li>VirtualGL-UNFINISHED </li> </ul>","boost":0.5},{"location":"#x","title":"x","text":"<ul> <li> <p>X11</p> </li> <li> <p>xmlto</p> </li> </ul>","boost":0.5},{"location":"#z","title":"z","text":"<ul> <li> <p>Zip </p> </li> <li> <p>zlib</p> </li> <li> <p>Zoltan </p> </li> </ul>","boost":0.5},{"location":"a/APR/","title":"APR","text":"<p>[package list]</p>","boost":10},{"location":"a/APR/#apr","title":"APR","text":"","boost":10},{"location":"a/APR/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider APR/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>APR/1.7.0-static (EasyConfig: APR-1.7.0-static.eb)</p> <p>EasyConfig used to experiment for building syslibs for the main software stack.</p> </li> <li> <p>APR/1.7.0 (EasyConfig: APR-1.7.0.eb)</p> <p>EasyConfig used to experiment for building syslibs for the main software stack.</p> </li> </ul>","boost":10},{"location":"a/APR/#technical-documentation","title":"Technical documentation","text":"<ul> <li>APR home page</li> </ul>","boost":10},{"location":"a/APR/#easybuild","title":"EasyBuild","text":"<p>APR is mostly a building tool for other Apache packages. The only use so far in our stack is to build Serf which in turn is needed for Subversion.</p> <ul> <li> <p>APR support in the EasyBuilders repository</p> </li> <li> <p>APR support in the CSCS repository</p> </li> </ul>","boost":10},{"location":"a/APR/#version-170-for-the-system-toolchain","title":"Version 1.7.0 for the SYSTEM toolchain","text":"<ul> <li> <p>The only purpose of these EasyConfigs are to prepare for integration in     syslibs, a module of build dependencies for some tools that we want to     compile against the system libraries (and with the SYSTEM toolchain).</p> </li> <li> <p>We started from a CSCS EasyConfig.</p> </li> </ul>","boost":10},{"location":"a/APR-util/","title":"APR-util","text":"<p>[package list]</p>","boost":10},{"location":"a/APR-util/#apr-util","title":"APR-util","text":"","boost":10},{"location":"a/APR-util/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider APR-util/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>APR-util/1.6.1-static (EasyConfig: APR-util-1.6.1-static.eb)</p> </li> <li> <p>APR-util/1.6.1 (EasyConfig: APR-util-1.6.1.eb)</p> </li> </ul>","boost":10},{"location":"a/APR-util/#technical-documentation","title":"Technical documentation","text":"<ul> <li>APR home page</li> </ul>","boost":10},{"location":"a/APR-util/#notes","title":"Notes","text":"<ul> <li>The pkgconfig file apr-util-1.pc lacks the path to the expat library     which in case of a build with EasyBuild is different from the one to the     APR-util libraries. The same holds for the bin/apu-1-config script.     This is fixed in installopts (or could be fixed in postinstallcmds)</li> </ul>","boost":10},{"location":"a/APR-util/#easybuild","title":"EasyBuild","text":"<p>APR and APR-util are mostly building tools for other Apache packages. The only use so far in our stack is to build Serf which in turn is needed for Subversion.</p> <ul> <li> <p>APR-util support in the EasyBuilders repository</p> </li> <li> <p>APR-util support in the CSCS repository</p> </li> </ul>","boost":10},{"location":"a/APR-util/#version-161-for-the-system-toolchain","title":"Version 1.6.1 for the SYSTEM toolchain","text":"<ul> <li> <p>The only purpose of these EasyConfigs are to prepare for integration in     syslibs, a module of build dependencies for some tools that we want to     compile against the system libraries (and with the SYSTEM toolchain).</p> </li> <li> <p>We started from a CSCS EasyConfig.</p> </li> </ul>","boost":10},{"location":"a/AsciiDoc/","title":"AsciiDoc","text":"<p>[package list]</p>","boost":10},{"location":"a/AsciiDoc/#asciidoc","title":"AsciiDoc","text":"","boost":10},{"location":"a/AsciiDoc/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider AsciiDoc/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>AsciiDoc/9.1.1 (EasyConfig: AsciiDoc-9.1.1.eb)</li> </ul>","boost":10},{"location":"a/absl/","title":"absl","text":"<p>[package list]</p>","boost":10},{"location":"a/absl/#absl","title":"absl","text":"","boost":10},{"location":"a/absl/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider absl/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>absl/1.3.0-cpeGNU-22.08-cray-python-3.9.4.2 (EasyConfig: absl-1.3.0-cpeGNU-22.08-cray-python-3.9.4.2.eb)</li> </ul>","boost":10},{"location":"a/absl/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>absl-py on PyPi</p> </li> <li> <p> absl-py on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"a/absl/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>There is no separate EasyConfig for <code>absl-py</code> in the EasyBuilders repository.</p> </li> <li> <p>Support for absl-py in the CSCS repository as absl</p> </li> </ul> <p>Note that we call the module <code>absl</code> and not <code>absl-py</code> as would be expected in the EasyBuild universum because we would have had to use a more complicated EasyConfig structure as the name of the module is <code>absl</code> and not <code>absl_py</code> and the sanity check fails.</p>","boost":10},{"location":"a/absl/#version-130-for-cpegnu2208","title":"Version 1.3.0 for cpeGNU/22.08","text":"<ul> <li>The EasyConfig is a heavily adapted one from an old CSCS EasyConfig.</li> </ul>","boost":10},{"location":"a/ant/","title":"ant","text":"<p>[package list]</p>","boost":10},{"location":"a/ant/#ant","title":"ant","text":"","boost":10},{"location":"a/ant/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider ant/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>ant/1.10.12-Java-11 (EasyConfig: ant-1.10.12-Java-11.eb)</li> </ul>","boost":10},{"location":"a/ant/#technical-documentation","title":"Technical documentation","text":"","boost":10},{"location":"a/ant/#easybuild","title":"EasyBuild","text":"","boost":10},{"location":"a/ant/#version-11012-for-2208","title":"Version 1.10.12 for 22.08","text":"<ul> <li> <p>The EasyConfig is based on the EasyBuilders one but with a version bump      to the latest version.</p> </li> <li> <p>TODO: <code>antRun</code> does not work: <code>sh</code> on LUMI does not support the <code>exec</code> call.     Need to switch the script to bash?</p> </li> </ul>","boost":10},{"location":"b/Bison/","title":"Bison","text":"<p>[package list]</p>","boost":10},{"location":"b/Bison/#bison","title":"Bison","text":"","boost":10},{"location":"b/Bison/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Bison/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>Bison/3.7.6-buildtoolsDevel (EasyConfig: Bison-3.7.6-buildtoolsDevel.eb)</li> </ul>","boost":10},{"location":"b/Blitz%2B%2B/","title":"Blitz++","text":"<p>[package list]</p>","boost":10},{"location":"b/Blitz%2B%2B/#blitz","title":"Blitz++","text":"","boost":10},{"location":"b/Blitz%2B%2B/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Blitz++/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>Blitz++/1.0.2-cpeGNU-24.03 (EasyConfig: Blitz++-1.0.2-cpeGNU-24.03.eb)</li> </ul>","boost":10},{"location":"b/Boost/","title":"Boost","text":"<p>[package list]</p>","boost":10},{"location":"b/Boost/#boost","title":"Boost","text":"","boost":10},{"location":"b/Boost/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Boost/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>Boost/1.82.0-cpeCray-23.09-TPSL (EasyConfig: Boost-1.82.0-cpeCray-23.09-TPSL.eb)</p> </li> <li> <p>Boost/1.82.0-cpeCray-23.09 (EasyConfig: Boost-1.82.0-cpeCray-23.09.eb)</p> </li> </ul>","boost":10},{"location":"b/baselibs/","title":"baselibs","text":"<p>[package list]</p>","boost":10},{"location":"b/baselibs/#baselibs","title":"baselibs","text":"","boost":10},{"location":"b/baselibs/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider baselibs/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>baselibs/20.06-cpeGNU-20.06 (EasyConfig: baselibs-20.06-cpeGNU-20.06.eb)</li> </ul>","boost":10},{"location":"b/buildtools/","title":"buildtools","text":"<p>[package list]</p>","boost":10},{"location":"b/buildtools/#buildtools","title":"buildtools","text":"","boost":10},{"location":"b/buildtools/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider buildtools/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>buildtools/21.06-buildtoolsDevel (EasyConfig: buildtools-21.06-buildtoolsDevel.eb)</p> </li> <li> <p>buildtools/24.03-debug (EasyConfig: buildtools-24.03-debug.eb)</p> </li> </ul>","boost":10},{"location":"b/bzip2/","title":"bzip2","text":"<p>[package list]</p>","boost":10},{"location":"b/bzip2/#bzip2","title":"bzip2","text":"","boost":10},{"location":"b/bzip2/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider bzip2/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>bzip2/1.0.8-static (EasyConfig: bzip2-1.0.8-static.eb)</li> </ul>","boost":10},{"location":"c/CDO/","title":"CDO","text":"<p>[package list]</p>","boost":10},{"location":"c/CDO/#cdo","title":"CDO","text":"","boost":10},{"location":"c/CDO/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider CDO/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>CDO/2.1.1-cpeGNU-23.03 (EasyConfig: CDO-2.1.1-cpeGNU-23.03.eb)</li> </ul>","boost":10},{"location":"c/CMOR/","title":"CMOR","text":"<p>[package list]</p>","boost":10},{"location":"c/CMOR/#cmor","title":"CMOR","text":"","boost":10},{"location":"c/CMOR/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider CMOR/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>CMOR/3.7.2-cpeGNU-23.03 (EasyConfig: CMOR-3.7.2-cpeGNU-23.03.eb)</li> </ul>","boost":10},{"location":"c/CMake/","title":"CMake","text":"<p>[package list]</p>","boost":10},{"location":"c/CMake/#cmake","title":"CMake","text":"","boost":10},{"location":"c/CMake/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider CMake/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>CMake/3.21.0-buildtoolsDevel (EasyConfig: CMake-3.21.0-buildtoolsDevel.eb)</li> </ul>","boost":10},{"location":"c/CVS-cvs/","title":"CVS-cvs","text":"<p>[package list]</p>","boost":10},{"location":"c/CVS-cvs/#cvs-cvs","title":"CVS-cvs","text":"","boost":10},{"location":"c/CVS-cvs/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider CVS-cvs/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>CVS-cvs/CVS-1.12.13 (EasyConfig: CVS-1.12.13.eb)</li> </ul>","boost":10},{"location":"c/Chapel/","title":"Chapel","text":"<p>[package list]</p>","boost":10},{"location":"c/Chapel/#chapel","title":"Chapel","text":"","boost":10},{"location":"c/Chapel/#license-information","title":"License information","text":"<p>Chapel is being developed under the terms of the  Apache 2.0 license that can also be found in the  LICENSE.chapel file in the Chapel GitHub. It also relies on various 3rd party packages about which information is available in the  LICENSE file in the Chapel GitHub.</p> <p>After installing and loading the module, these files can also be found in <code>$EBROOTCHAPEL/share/licenses/Chapel</code>.</p>","boost":10},{"location":"c/Chapel/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Chapel/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>Chapel/2.5.0-cpeCray-24.03 (EasyConfig: Chapel-2.5.0-cpeCray-24.03.eb)</p> <p>Chapel without GPU support. cpeCray was used to compile the Chapel compiler and must be present together with the  right CPU target module when running also, which is why this should be installed in <code>partition/L</code>, <code>partition/C</code> or <code>partition/G</code>, with the latter making little sense as GPU support is not enabled.</p> </li> <li> <p>Chapel/2.5.0-rocm-noComm (EasyConfig: Chapel-2.5.0-rocm-noComm.eb)</p> <p>Chapel without GPU support. Tricky version that can work in CrayEnv also. It claims to use the SYSTEM toolchain, but under the hood it is using the Cray compiler to build Chapel. You should be able to install it even for CrayEnv (by using <code>module load LUMI partition/CrayEnv EasyBuild-user</code>, but it will only work for the CPU target that you find here close to the top of the  EasyBuild recipe.</p> </li> <li> <p>Chapel/2.5.0 (EasyConfig: Chapel-2.5.0.eb)</p> <p>Chapel without GPU support. Tricky version that can work in CrayEnv also. It claims to use the SYSTEM toolchain, but under the hood it is using the Cray compiler to build Chapel. You should be able to install it even for CrayEnv (by using <code>module load LUMI partition/CrayEnv EasyBuild-user</code>, but it will only work for the CPU target that you find here close to the top of the  EasyBuild recipe.</p> </li> </ul>","boost":10},{"location":"c/Chapel/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>Chapel web page</p> </li> <li> <p>Chapel on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"c/Chapel/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>There is no support for Chapel in the EasyBuilders repository.</p> </li> <li> <p>There is no support for Chapel in the CSCS repository.</p> </li> <li> <p>Spack package chapel</p> </li> </ul>","boost":10},{"location":"c/Chapel/#version-250","title":"Version 2.5.0","text":"<ul> <li>The EasyConfig is a LUST development. Also see the comments in the     EasyConfig itself.</li> </ul>","boost":10},{"location":"c/CrayPath/","title":"CrayPath","text":"<p>[package list]</p>","boost":10},{"location":"c/CrayPath/#craypath","title":"CrayPath","text":"","boost":10},{"location":"c/CrayPath/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider CrayPath/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>CrayPath/0.1 (EasyConfig: CrayPath-0.1.eb)</li> </ul>","boost":10},{"location":"c/cURL/","title":"cURL","text":"<p>[package list]</p>","boost":10},{"location":"c/cURL/#curl","title":"cURL","text":"","boost":10},{"location":"c/cURL/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider cURL/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>cURL/7.83.1-devel (EasyConfig: cURL-7.83.1-devel.eb)</li> </ul>","boost":10},{"location":"c/ccpe/","title":"ccpe","text":"<p>[package list]</p>","boost":10},{"location":"c/ccpe/#ccpe","title":"ccpe","text":"","boost":10},{"location":"c/ccpe/#license-information","title":"License information","text":"<p>These containers contain proprietary software and can only be used by LUMI users on LUMI. You cannot take these containers to another system. Doing so will be considered a severe violation of the conditions of use, as you should respect software licenses, and can lead to permanent termination of your access to LUMI.</p> <p>The use of the containers is also covered by the HPE End User License Agreement - Enterprise Version. Please read this document carefully!</p>","boost":10},{"location":"c/ccpe/#user-documentation","title":"User documentation","text":"<p>These containers are beta software</p> <p>They are made available by HPE without guarantee of suitability for your purpose, as a way for users to test programming environments that are not (yet) on the system. </p> <p>LUST together with HPE have made modules and implemented changes to the  containers to adapt them to LUMI and integrate somewhat in the regular  environment.</p> <p>However, working with these containers is different from working with a  programming environment that is installed natively on the system and requires a good insight in how containers work. So they are not for every user, and LUST can only offer very limited support. These containers are only for  users who are very experienced with the Cray Programming Environment and also understand how singularity containers work.</p> <p>The container only offers <code>PrgEnv-cray</code> and <code>PrgEnv-gnu</code>.  With some imports from the system, we also offer <code>PrgEnv-amd</code>, but it may not be entirely as intended by the version of the PE as we may be  using a different version of ROCm. The container does contain some elements of <code>PrgEnv-nvidia</code> but that is obviously not functional on LUMI. <code>PrgEnv-aocc</code> is not available.</p> <p>HPE has a community Slack channel for feedback and questions at slack.hpdev.io, channel <code>#hpe-cray-programming-environment</code>, but bear in mind that this is mostly a community channel, monitored by some developers, but those developers don't have time to answer each and every question themselves. It is a low volume channel and in no means a support channel for inexperienced users.</p>","boost":10},{"location":"c/ccpe/#where-to-get-the-containers","title":"Where to get the containers?","text":"<p>We're negotiating with HPE to see if we can provide the container in a central place  for LUMI users and only for use on LUMI. </p> <p>However, currently the only way to get access to the containers is to download the containers from the HPE support site. You will need to sign in or  create an account first.</p> <p>You can then use the search feature (magnifying glass) to search for \"HPE CPE Software Container\", restricting your search to \"Drivers and Software\". At the time of writing, the most recent version available was a container for CPE 24.11 (but no guarantee that this link remains valid, so therefore also the link).</p> <p>To the left of the page that opens now, you will actually see a list of older versions also.</p> <p>Please read the licensing conditions very carefully! You are not allowed to distribute the software (so within a project it is best that every user downloads the software and agrees with the  license).</p> <p>You can then use the \"Obtain Software\" button to get access to the downloadable files. Select the file, or all three files, and click the \"curl Copy\" button. This will  give you a file (downloadUrls.txt) with the <code>curl</code> commands that you can use on the  LUMI login nodes to download the files. The links are only valid for 24 hours and should not be passed to others.</p> <p>The text continues for the 24.11 container, so you'll need to adapt for other containers.</p> <p>After downloading the container files to LUMI, proceed with the following steps:</p> <ul> <li> <p>(Optional:) Verify the integrity of the downloaded <code>.tar.gz</code> file:</p> <pre><code>sha256sum HPE_CPE_Container_24.11.5.tar.gz | awk '{print $1}' | \\\n    diff -w -q HPE_CPE_Container_24.11.5.tar.gz.sha256 -\n</code></pre> </li> <li> <p>Untar the container:</p> <pre><code>tar xvf HPE_CPE_Container_24.11.5.tar.gz\n</code></pre> </li> <li> <p>The container comes in docker format and needs to be converted to the Singularity SIF format:</p> <pre><code>cd HPE_CPE_Container_24.11.5\ngunzip cpe_2411.tgz\nsingularity build cpe_24.11.sif docker-archive://cpe_2411.tar\n</code></pre> </li> </ul> <p>The resulting <code>cpe_2411.sif</code> file is what is needed as the source file for the EasyBuild modules that we suggest to use to make using the containers easier.</p>","boost":10},{"location":"c/ccpe/#how-to-enable-the-containers","title":"How to enable the containers?","text":"<p>We recommend using our EasyBuild modules to run the HPE CPE containers as these modules do create a lot of bind mounts to provide all necessary parts from the system to the container.</p> <p>All modules provide a number of environment variables to make life easier:</p> <ul> <li> <p>Outside (and brought into) the container, <code>SIF</code> and <code>SIFCCPE</code> point to the container file,     which is very handy to use with the <code>singularity</code> command.</p> </li> <li> <p>Inside the container, <code>INITCCPE</code> contains the commands to fully initialise     the CPE in the container. Use as <code>eval $INITCCPE</code>.</p> <p>This is not needed when using <code>singularity run</code> or the corresponding wrapper script.</p> </li> <li> <p>Outside (and brought into) the container, <code>EXPORTCCPE</code> is a list of environment     variables set by the <code>ccpe</code> modules that we want to bring in the container or     in a job script, even if we otherwise want to start the job script with a clean     environment.</p> </li> <li> <p>Outside (and brought into) the container, <code>SWITCHTOCCPE</code> is an environment variable     containing a large block of code that is used at the start of the job script to     switch to executing the job script in the container.</p> </li> </ul> <p>The module also provides access to four wrapper scripts to start the container. Note though that those wrapper scripts only function properly when the module is loaded. They do not take care of the bindings themselves and in that sense are certainly different from the wrapper scripts provided by Tykky/lumi-container-wrapper. All these scripts do however purge all modules before going into the container, as modules from the system PE are not valid in the container, and fully clear Lmod. Currently, the following scripts are provided:</p> <ul> <li> <p><code>ccpe-shell</code> to start a shell in the container. The arguments of <code>ccpe-shell</code>     are simply added to the <code>singularity shell $SIF</code>.</p> </li> <li> <p><code>ccpe-exec</code> to run a command in the container. The arguments of <code>ccpe-exec</code>      are simply added to the <code>singularity exec $SIF</code> command.</p> </li> <li> <p><code>ccpe-run</code> to run the container. The arguments of <code>ccpe-run</code>     are simply added to the <code>singularity run $SIF</code> command.</p> </li> <li> <p><code>ccpe-singularity</code> will clean up the environment for the singularity, then     call <code>singularity</code> passing all arguments to <code>singularity</code>. So with this      command, you still need to specify the container also (e.g., using the      <code>SIF</code> or <code>SIFCCPE</code> environment variable), but can specify options for      the singularity subcommand also.</p> </li> </ul>","boost":10},{"location":"c/ccpe/#how-to-get-a-proper-environment-in-the-container","title":"How to get a proper environment in the container?","text":"<p>Unfortunately, there seems to be no way to properly (re-)initialise the shell  or environment in the container directly through <code>singularity shell</code> or  <code>singularity exec</code>.</p> <p>The following strategies can be used:</p> <ul> <li> <p>In the container, the environment variable <code>INITCCPE</code> contains the necessary     commands to get a working Lmod environment again, but then with the relevant     CPE modules for the container. Run as</p> <pre><code>eval $INITCCPE\n</code></pre> </li> <li> <p>Alternatively, sourcing <code>/etc/bash.bashrc</code> will also properly set up Lmod.</p> </li> </ul> <p>Cases that do give you a properly initiated shell, are <code>singularity exec bash -i</code>  and <code>singularity run</code>. These commands do source <code>/etc/bash.bashrc</code> but do not  read <code>/etc/profile</code>. But the latter shouldn't matter too much as that is usually used to set environment variables, and those that are typically set in that file and the files it calls, are typically fine for the container, or overwritten anyway by the files sourced by <code>/etc/bash.bashrc</code>.</p> <p>To install the container module, chose the appropriate EasyConfig from this page, and make sure you have a properly set up environment as explained in the  LUMI documentation in the \"Installing software\"section,  \"EasyBuild\". In particular, it is important to set a proper location using <code>EBU_USER_PREFIX</code>, as your home directory will quickly fill up if you install in the default  location. To install the container, use</p> <pre><code>module load LUMI/24.03 partition/container\neb ccpe-24.11-rocm-6.2-LUMI.eb --sourcepath &lt;directory with the cpe_2411.sif file&gt;\n</code></pre> <p>Any more recent version of the LUMI stack on the system will also work for the installation.</p> <p>After that, the module installed by the EasyConfig (in this case, <code>ccpe/24.11-rocm-6.2-LUMI</code>) will be available in all versions of the <code>LUMI</code> stack on the system and in <code>CrayEnv</code>. So, e.g.,</p> <pre><code>module load CrayEnv ccpe/24.11-rocm-6.2-LUMI\n</code></pre> <p>is enough to gain access to the container and all its tools explained on this page.</p> <p>This is a beta product and support is limited. LUST cannot really offer much support, though we are interested in learning about issues as this is useful feedback for HPE. There  is also a low-activity community Slack channel that you can gain access to by visiting slack.hpedev.io and selecting the #hpe-cray-programming-environment channel. This is a community forum though and not continuously followed by the developers, so don't expect that there will always be a solution to your issue. These containers are really  meant for experienced users who want to experiment with a newer version before it becomes available on LUMI.</p>","boost":10},{"location":"c/ccpe/#launching-jobs-a-tale-of-two-environments","title":"Launching jobs: A tale of two environments","text":"<p>The problem with running jobs, is that they have to deal with two incompatible environments:</p> <ol> <li> <p>The environment outside the container that does not know about the HPE Cray     PE modules of the PE version in the container, and may not know about some other     modules depending on how <code>/appl/lumi</code> is set up (as this may point to a totally     separate software stack specific for the container but mounted on <code>/appl/lumi</code>     so that it behaves just as the regular stacks on the system).</p> </li> <li> <p>The environment inside the container that does not know about the HPE Cray PE     modules installed in the system, and may not know about some other      modules depending on how <code>/appl/lumi</code> is set up.</p> </li> </ol> <p>This is important, because unloading a module in Lmod requires access to the correct module file, as unloading is done by \"executing the module file in reverse\": The module file is executed, but each action that changes the environment, is reversed. Even a <code>module purge</code> will not work correctly without the proper modules available. Environment variables set by the modules may remain set. This is also why the module provides the <code>ccpe-*</code> wrapper scripts for singularity: These scripts are meant to be executed in  an environment that is valid outside the container, and clean up that environment before starting commands in the container so that the container initialisation can start from  a clean inherited environment.</p> See how broken the job environment can be... <p>This example is developed running a container for the 24.11 programming environment on LUMI in March 2025 with the 24.03 programming environment as the default.</p> <p>The 24.03 environment comes with <code>cce/17.0.1</code> while the 24.11 environment comes with <code>cce/18.0.1</code>. When loading the module, it sets the environment variable 'CRAY_CC_VERSION' to the version of the CCE compiler.</p> <p>Start up the container:</p> <pre><code>ccpe-run\n</code></pre> <p>Check the version of the module tool:</p> <pre><code>module --version\n</code></pre> <p>which returns version 8.7.37:</p> <pre><code>Modules based on Lua: Version 8.7.37  [branch: release/cpe-24.11] 2024-09-24 16:53 +00:00\n    by Robert McLay mclay@tacc.utexas.edu    \n</code></pre> <p>and list the modules:</p> <pre><code>module list\n</code></pre> <p>returns</p> <pre><code>Currently Loaded Modules:\n1) craype-x86-rome                                 6) cce/18.0.1           11) PrgEnv-cray/8.6.0\n2) libfabric/1.15.2.0                              7) craype/2.7.33        12) ModuleLabel/label (S)\n3) craype-network-ofi                              8) cray-dsmml/0.3.0     13) lumi-tools/24.05  (S)\n4) perftools-base/24.11.0                          9) cray-mpich/8.1.31    14) init-lumi/0.2     (S)\n5) xpmem/2.9.6-1.1_20240510205610__g087dc11fc19d  10) cray-libsci/24.11.0\n\nWhere:\nS:  Module is Sticky, requires --force to unload or purge\n</code></pre> <p>so we start with the Cray programming environment loaded.</p> <p>Now use an interactive <code>srun</code> session to start a session on the compute node.</p> <pre><code>srun -n1 -c1 -t10:00 -psmall -A&lt;my_account&gt; --pty bash\n</code></pre> <p>Let's check the version of the module tool again:</p> <pre><code>module --version\n</code></pre> <p>now returns version 8.7.32: </p> <pre><code>Modules based on Lua: Version 8.7.32  2023-08-28 12:42 -05:00\n    by Robert McLay mclay@tacc.utexas.edu\n</code></pre> <p>as we are no longer in the container but in a regular LUMI environment. </p> <p>Trying</p> <pre><code>module list\n</code></pre> <p>returns</p> <pre><code>Currently Loaded Modules:\n6) craype-x86-rome                                 6) cce/18.0.1           11) PrgEnv-cray/8.6.0\n7) libfabric/1.15.2.0                              7) craype/2.7.33        12) ModuleLabel/label (S)\n8) craype-network-ofi                              8) cray-dsmml/0.3.0     13) lumi-tools/24.05  (S)\n9) perftools-base/24.11.0                          9) cray-mpich/8.1.31    14) init-lumi/0.2     (S)\n10) xpmem/2.9.6-1.1_20240510205610__g087dc11fc19d  10) cray-libsci/24.11.0\n\nWhere:\nS:  Module is Sticky, requires --force to unload or purge\n</code></pre> <p>so the modules we were using in the container.</p> <p>The environment variable <code>CRAY_CC_VERSION</code> is also set:</p> <pre><code>echo $CRAY_CC_VERSION\n</code></pre> <p>returns <code>18.0.1</code>.</p> <p>Now do a</p> <pre><code>module purge\n</code></pre> <p>which shows the perfectly normal output</p> <pre><code>The following modules were not unloaded:\n(Use \"module --force purge\" to unload all):\n\n1) ModuleLabel/label   2) lumi-tools/24.05   3) init-lumi/0.2\n\nThe following sticky modules could not be reloaded:\n\n1) lumi-tools\n</code></pre> <p>and </p> <pre><code>module list\n</code></pre> <p>now shows</p> <pre><code>Currently Loaded Modules:\n1) ModuleLabel/label (S)   2) lumi-tools/24.05 (S)   3) init-lumi/0.2 (S)\n\nWhere:\nS:  Module is Sticky, requires --force to unload or purge\n</code></pre> <p>but </p> <pre><code>echo $CRAY_CC_VERSION\n</code></pre> <p>still return <code>18.0.1</code>, so even though it appears that the <code>cce/18.0.1</code> module has been unloaded, not all (if any) environment variables set by the module, have been correctly unset. </p> <p>We can now load the <code>cce</code> module again:</p> <pre><code>module load cce\n</code></pre> <p>and now</p> <pre><code>module list cce\n</code></pre> <p>returns</p> <pre><code>Currently Loaded Modules Matching: cce\n1) cce/17.0.1\n</code></pre> <p>so it appears we have the <code>cce</code> module from the system. This went well in this case. And in fact,</p> <pre><code>module list\n</code></pre> <p>which returns</p> <pre><code>Currently Loaded Modules:\n1) ModuleLabel/label (S)   4) craype/2.7.31.11     7) craype-network-ofi   10) PrgEnv-cray/8.5.0\n2) lumi-tools/24.05  (S)   5) cray-dsmml/0.3.0     8) cray-mpich/8.1.29    11) cce/17.0.1\n3) init-lumi/0.2     (S)   6) libfabric/1.15.2.0   9) cray-libsci/24.03.0\n\nWhere:\nS:  Module is Sticky, requires --force to unload or purge\n</code></pre> <p>suggests that some other modules, like <code>cray-mpich</code> and <code>cray-libsci</code> have also been reloaded.</p> <pre><code>echo $CRAY_CC_VERSION\n</code></pre> <p>returns <code>17.0.1</code> as expected, and after</p> <pre><code>module purge\n</code></pre> <p>we now note that</p> <pre><code>echo $CRAY_CC_VERSION\n</code></pre> <p>returns nothing and is reset.</p> <p>However, it is clear that we are now in an environment where we cannot use what we prepared in the container.</p>","boost":10},{"location":"c/ccpe/#job-script-template-to-run-the-batch-script-in-the-container","title":"Job script template to run the batch script in the container","text":"<p>To make writing job scripts easier, some common code has been put in an environment variable that can be executed via the <code>eval</code> function of bash.</p> <p>This job script will start with as clean an environment as possible, except when called from a correctly initialised container with passing of the full environment:</p> <pre><code>#!/bin/bash\n#\n# This test script should be submitted with sbatch from within a CPE 24.11 container.\n# It shows very strange behaviour as the `module load` of some modules fails to show\n# those in `module list` and also fails to change variables that should be changed.\n#\n#SBATCH -J example-jobscript\n#SBATCH -p small\n#SBATCH -n 1\n#SBATCH -c 1\n#SBATCH -t 5:00\n#SBATCH -o %x-%j.md\n# And add line for account\n\n#\n# Ensure that the environment variable SWITCHTOCCPE and with it \n#\nif [ -z \"${SWITCHTOCCPE}\" ]\nthen\n    module load CrayEnv ccpe/24.11-LUMI || exit\nfi\n\n#\n# Now switch to the container and clean up environments when needed and possible.\n#\neval $SWITCHTOCCPE\n\n#\n# Here you have the container environment and can simply work as you would normally do:\n# Build your environment and start commands. But you'll still have to be careful with\n# srun as whatever you start with srun will not automatically run in the container.\n#\n\nmodule list\n\nsrun &lt;srun options&gt; singularity exec $SIFCCPE &lt;command&gt;\n</code></pre> <p>What this job script does:</p> <ul> <li> <p>The body of the job script (lines after <code>eval $SWITCHTOCCPE</code>) will always run in the container.</p> <p>This is where you would insert your code that you want to run in the container.</p> </li> <li> <p>When launching this batch script from within the container:</p> <ul> <li> <p>When launched with <code>--export</code> flag, the body will run in the environment of the calling container.</p> <p>It does require that the job is started from a properly initialised container with active Lmod though, as that currently sets the environment variable to detect if the container is properly initialised. </p> <p>If you started the calling container with <code>ccpe-run</code>, there is no issue though. In other cases, you  may have to execute <code>eval $INITCCPE</code>. But in general, if you were able to load Cray PE modules before calling <code>sbatch</code>, you should be OK.</p> </li> <li> <p>When launched using <code>sbatch --export=$EXPORTCCPE</code>, the body will run in a clean container environment,     but will not need to re-load the container module.</p> </li> <li> <p>Behaviour with <code>--export=none</code>: As the container cannot be located, </p> <pre><code>if [ -z \"${SWITCHTOCCPE}\" ]\nthen\n    module load CrayEnv ccpe/24.11-LUMI || exit\nfi\n</code></pre> <p>will first try to load the container module, and if successful, proceed creating a clean environment.</p> <p>Note that you need to adapt that line to the module you are actually using!</p> </li> </ul> </li> <li> <p>When launching this batch script from a regular system shell:</p> <ul> <li> <p>When launched using <code>sbatch --export=$EXPORTCCPE</code>, the body will run in a clean container environment.</p> </li> <li> <p>When launched with <code>--export</code> flag, <code>eval $SWITCHTOCCPE</code> will first try to clean the system     environment (and may fail during that phase if it cannot find the modules that you had loaded     when calling <code>sbatch</code>.)</p> <p>If the <code>ccpe</code> module was not loaded when calling the job script, the block </p> <pre><code>if [ -z \"${SWITCHTOCCPE}\" ]\nthen\n    module load CrayEnv ccpe/24.11-LUMI || exit\nfi\n</code></pre> <p>will try to take care of that. If the module can be loaded, the script will proceed with building a clean container environment.</p> <p>Note that you need to adapt that line to the module you are actually using!</p> </li> <li> <p>Behaviour with <code>--export=none</code>: As the container cannot be located, </p> <pre><code>if [ -z \"${SWITCHTOCCPE}\" ]\nthen\n    module load CrayEnv ccpe/24.11-LUMI || exit\nfi\n</code></pre> <p>will first try to load the container module, and if successful, proceed creating a clean environment.</p> <p>Note that you need to adapt that line to the module you are actually using!</p> </li> </ul> </li> <li> <p>So in all cases you get a clean environment (which is the only logical thing to get) except     if <code>sbatch</code> was already called from within the container without <code>--export</code> flag.</p> </li> </ul> <p>For technical information about how all this works under the hood (and it may  be important to understand this to always use the template correctly), check the subsection \"Starting jobs\" in the  \"Technical documentation\" section of this page.</p>","boost":10},{"location":"c/ccpe/#next-steps","title":"Next steps:","text":"<ul> <li>Build MPI tools to better document how to start such jobs, with a proper example     in these notes.</li> </ul>","boost":10},{"location":"c/ccpe/#known-restrictions","title":"Known restrictions","text":"<ul> <li> <p><code>PrgEnv-aocc</code> is not provided by the container. The ROCm version is taken from the     system and may not be the optimal one for the version of the PE.</p> </li> <li> <p><code>salloc</code> does not work in the container.</p> <p>Workaround: USe <code>salloc</code> outside the container, then go into the container with  <code>ccpe-run</code>.</p> </li> </ul>","boost":10},{"location":"c/ccpe/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider ccpe/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>ccpe/24.11-B-rocm-6.2-LUMI (EasyConfig: ccpe-24.11-B-rocm-6.2-LUMI.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This B-rocm version bind mounts the actual ROCm installation from a SquashFS file provided on LUMI which should give better compile performance than when simply mounting a directory from one of the LUMI parallel file systems with the ROCm installation. Some libraries  on the OS side may not be the best version, so in  case of trouble, switch to the CZ-rocm version.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/24.11-C-rocm-6.2-LUMI (EasyConfig: ccpe-24.11-C-rocm-6.2-LUMI.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This C-rocm version also integrates ROCm in the container and installs it using the  SUSE zypper install tool, guaranteeing that all dependencies are also present in the right version. As such, it is the most robust variant of the containers with  ROCm. However, installing ROCm with the unprivileged build process is extremely slow,  so expect long build times (over one and a half hour on a compute node), rendering this approach rather inefficient. The assembly of the container may also run out-of-memory on the login nodes as the memory available to a single user is restricted to 96GB.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/24.11-CZ-rocm-6.2-LUMI (EasyConfig: ccpe-24.11-CZ-rocm-6.2-LUMI.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This CZrocm version also integrates ROCm in the container and installs it using the  SUSE zypper install tool, guaranteeing that all dependencies are also present in the right version. As such, it is the most robust variant of the containers with  ROCm. However, installing ROCm with the unprivileged build process is extremely slow,  so expect long build times (over one and a half hour on a compute node), rendering this approach rather inefficient. The assembly of the container may also run out-of-memory on the login nodes as the memory available to a single user is restricted to 96GB.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/24.11-LUMI (EasyConfig: ccpe-24.11-LUMI.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/24.11-raw (EasyConfig: ccpe-24.11-raw.eb)</p> <p>This is a module to enable work in the CPE container for 24.11 as it comes from HPE, so with no modifications inside the containers to better match with LUMI.</p> <p>Slurm support will not work when used with a self-downloaded version, but at the  moment we are not yet allowed to distribute a modified version ourselves that  has the necessary features built-in. The other <code>ccpe/24.11</code> versions support Slurm though.</p> </li> <li> <p>ccpe/25.03-B-rocm-6.3-SP5-LUMI (EasyConfig: ccpe-25.03-B-rocm-6.3-SP5-LUMI.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This B-rocm version bind mounts the actual ROCm installation from a SquashFS file provided on LUMI which should give better compile performance than when simply mounting a directory from one of the LUMI parallel file systems with the ROCm installation. Some libraries  on the OS side may not be the best version, so in  case of trouble, switch to the C-rocm version.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/25.03-B-rocm-6.3-SP5-LUMI.v1 (EasyConfig: ccpe-25.03-B-rocm-6.3-SP5-LUMI.v1.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This C-rocm version also integrates ROCm in the container and installs it using the  SUSE zypper install tool, guaranteeing that all dependencies are also present in the right version. As such, it is the most robust variant of the containers with  ROCm. However, installing ROCm with the unprivileged build process is extremely slow,  so expect long build times (over one and a half hour on a compute node), rendering this approach rather inefficient. The assembly of the container may also run out-of-memory on the login nodes as the memory available to a single user is restricted to 96GB.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/25.03-B-rocm-6.3-SP5-LUMI.v2 (EasyConfig: ccpe-25.03-B-rocm-6.3-SP5-LUMI.v2.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This B-rocm version bind mounts the actual ROCm installation from a SquashFS file provided on LUMI which should give better compile performance than when simply mounting a directory from one of the LUMI parallel file systems with the ROCm installation. Some libraries  on the OS side may not be the best version, so in  case of trouble, switch to the C-rocm version.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/25.03-C-rocm-6.3-SP5-LUMI (EasyConfig: ccpe-25.03-C-rocm-6.3-SP5-LUMI.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This C-rocm version also integrates ROCm in the container and installs it using the  SUSE zypper install tool, guaranteeing that all dependencies are also present in the right version. As such, it is the most robust variant of the containers with  ROCm. However, installing ROCm with the unprivileged build process is extremely slow,  so expect long build times (over one and a half hour on a compute node), rendering this approach rather inefficient. The assembly of the container may also run out-of-memory on the login nodes as the memory available to a single user is restricted to 96GB.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/25.03-C-rocm-6.3-SP5-LUMI.v1 (EasyConfig: ccpe-25.03-C-rocm-6.3-SP5-LUMI.v1.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This C-rocm version also integrates ROCm in the container and installs it using the  SUSE zypper install tool, guaranteeing that all dependencies are also present in the right version. As such, it is the most robust variant of the containers with  ROCm. However, installing ROCm with the unprivileged build process is extremely slow,  so expect long build times (over one and a half hour on a compute node), rendering this approach rather inefficient. The assembly of the container may also run out-of-memory on the login nodes as the memory available to a single user is restricted to 96GB.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/25.03-C-rocm-6.3-SP5-LUMI.v2 (EasyConfig: ccpe-25.03-C-rocm-6.3-SP5-LUMI.v2.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This C-rocm version also integrates ROCm in the container and installs it using the  SUSE zypper install tool, guaranteeing that all dependencies are also present in the right version. As such, it is the most robust variant of the containers with  ROCm. However, installing ROCm with the unprivileged build process is extremely slow,  so expect long build times (over one and a half hour on a compute node), rendering this approach rather inefficient. The assembly of the container may also run out-of-memory on the login nodes as the memory available to a single user is restricted to 96GB.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/25.03-CT-rocm-6.3-SP5-LUMI (EasyConfig: ccpe-25.03-CT-rocm-6.3-SP5-LUMI.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This CT-rocm version also integrates ROCm in the container. It does so by simply un-tar-ing a file prepared on LUMI with the whole ROCm installation. Some libraries on the OS side may not be the best version, so in case of trouble, switch to the CZ-rocm version.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/25.03-CT-rocm-6.3-SP5-LUMI.v1 (EasyConfig: ccpe-25.03-CT-rocm-6.3-SP5-LUMI.v1.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This CT-rocm version also integrates ROCm in the container. It does so by simply un-tar-ing a file prepared on LUMI with the whole ROCm installation. Some libraries on the OS side may not be the best version, so in case of trouble, switch to the CZ-rocm version.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> <li> <p>ccpe/25.03-CT-rocm-6.3-SP5-LUMI.v2 (EasyConfig: ccpe-25.03-CT-rocm-6.3-SP5-LUMI.v2.eb)</p> <p>This module provides a modified version of the CPE container as it comes from HPE. The goal is to integrate it better with the current LUMI environment. Changes to the container are also made through this EasyConfig, so you may use it as a template to adapt the CPE containers to your needs.</p> <p>This CT-rocm version also integrates ROCm in the container. It does so by simply un-tar-ing a file prepared on LUMI with the whole ROCm installation. Some libraries on the OS side may not be the best version, so in case of trouble, switch to the CZ-rocm version.</p> <p>This container can be installed in <code>partition/container</code> via LUMI/24.03 or more recent LUMI stacks, after which the module will be available in CrayEnv and all versions of the LUMI stack.</p> </li> </ul>","boost":10},{"location":"c/ccpe/#technical-documentation","title":"Technical documentation","text":"<p>These containers should not be spread outside LUMI, and some even contain unofficial versions and should not be spread to more users than needed. So do not spread without explicit agreement with HPE.</p>","boost":10},{"location":"c/ccpe/#issues","title":"Issues","text":"","boost":10},{"location":"c/ccpe/#which-approach","title":"Which approach?","text":"<ol> <li> <p>One can do as much as possible outside the container, injecting any change via bind     mounts. This makes for very easy debugging, as one can simply change those injected     files without rebuilding the container.</p> <p>As we shall see below, some minimal components have to be injected though to get Slurm to work.</p> </li> <li> <p>Create a custom container, implementing modifications and additions as much as possible     in the container.</p> <p>This also enables us to install a lot of extra software in the container, and give users an easy way to build a fully customised version. </p> <p>It also greatly simplifies the list of bind mounts.</p> <p>Debugging is a bit easier, but if we store copies from the files installed in the container also outside the container, it is still easy to temporarily inject them and experiment with changes.</p> </li> </ol> <p>The first approach also enables us to make the standard container available on a place  accessible to all users, without the need for them to store a copy in their project. On the other hand, having a local copy protects against changes that admins may make, and the size of the container is small compared to the size of a dataset one can expect for users who use LUMI to solve bigger problems.</p>","boost":10},{"location":"c/ccpe/#managing-bind-mounts","title":"Managing bind mounts","text":"<p>It is not hard to build a module that sets the <code>SINGULARITY_BIND</code> environment variable with all necessary bind mounts. Moreover, that environment variable is also made available in the container so can be further propagated easily to a job script.</p>","boost":10},{"location":"c/ccpe/#a-tale-of-two-environments","title":"A tale of two environments","text":"<p>On the system and inside the container, the module view is different. On the system, one sees all modules form the programming environments installed on the system, and modules in the LUST-installed stacks and possibly other local stacks.</p> <p>In the container, one sees a different set of programming environment modules, and depending on which software stacks are mounted, a different set of software stack modules.</p> <p>This matters because Lmod can only fully unload a module if it has access to the module file. Unloading is done by executing the module file while reversing the effect of commands that  make changes in the environment. If you execute a <code>module purge</code> or <code>module --force purge</code> on a list of modules for which not all module files are available, they will still appear as unloaded, but environment variables set by these modules will not be unset, and worse, directories will not be correctly removed from PATH-style environment variables. Lmod will not warn for that: It is a feature that any unload operation always succeeds, even if it could not be done correctly.</p> <p>This may be troublesome for the programming environment. As so much data is communicated to the  compiler wrappers via environment variables, they may be mislead and do unintended operations like trying to link in libraries that should not be linked in.</p> <p>This has implication on how we go into containers - one should clean up the system environment before entering in the container - and on Lmod: One should not use the same cache for both environments. It also complicates starting jobs.</p> <p>All these elements will be discussed below.</p>","boost":10},{"location":"c/ccpe/#wrapper-scripts","title":"Wrapper scripts","text":"<p>The EasyBuild-installed modules do provide some wrapper scripts that make some tasks  easier. They try to deal with the two environments problem by first purging the system environment before calling the singularity command.</p>","boost":10},{"location":"c/ccpe/#singularity-shell-wrapper-script-ccpe-shell","title":"<code>singularity shell</code> wrapper script <code>ccpe-shell</code>","text":"<p>This is a convenience wrapper script and is not useful if you want to pass arguments  to singularity (rather than to the shell it starts).</p> <p>The script does a clean-up of the modules in your environment and then cleans up Lmod  completely, as the environment outside the container is not compatible with the environment  in the container and as the loaded modules are needed to correctly unload them. It  does save the environment variables set by the <code>ccpe</code> module to restore them after  the <code>module --force purge</code> operation as otherwise the container wouldn't function properly  anymore. </p> <p>To make sure that <code>/etc/profile</code> would execute properly if it were called, the script  also unsets <code>PROFILEREAD</code>, as the environment generated by the system <code>/etc/profile</code>  may not be the ideal one for the container.</p>","boost":10},{"location":"c/ccpe/#singularity-exec-wrapper-script-ccpe-exec","title":"<code>singularity exec</code> wrapper script <code>ccpe-exec</code>","text":"<p>This is a convenience wrapper script and is not useful if you want to pass arguments  to singularity rather than to the command you start.</p> <p>It performs the same functions as <code>ccpe-shell</code>, but passes its arguments to the <code>singularity exec $SIFCCPE</code> command.</p>","boost":10},{"location":"c/ccpe/#singularity-run-wrapper-script-ccpe-run","title":"<code>singularity run</code> wrapper script <code>ccpe-run</code>","text":"<p>This is a convenience wrapper script and is not useful if you want to pass arguments  to singularity (rather than to the command it tries to run, if given).</p> <p>It performs the same functions as <code>ccpe-shell</code>, but passes its arguments to the <code>singularity run $SIFCCPE</code> command.</p>","boost":10},{"location":"c/ccpe/#singularity-wrapper-script-ccpe-singularity","title":"<code>singularity</code> wrapper script <code>ccpe-singularity</code>","text":"<p>This wrapper only cleans up the environment and then calls <code>singularity</code> passing all arguments of the wrapper unmodified to the <code>singularity</code> command. So you also need to pass the name of the container image, but can now call any singularity command with all singularity command-specific options in a clean environment.</p>","boost":10},{"location":"c/ccpe/#lmod-caches","title":"Lmod caches","text":"<p>As the environment in the container is not compatible with the environment outside,  we cannot use the regular user Lmod cache, or it may get corrupted, certainly if a  user is working both in and out of the container at the same time.</p> <p>Possible solutions/workarounds:</p> <ol> <li> <p>Work with <code>LMOD_IGNORE_CACHE=1</code> in the container.      As the whole of <code>/appl/lumi</code> is mounted in the containers by our EasyConfigs, this      will slow down module searches in Lmod considerably.</p> </li> <li> <p>Modify <code>/opt/cray/pe/lmod/lmod/libexec/myGlobals.lua</code>: Look for the line with <code>usrCacheDir</code>      and define a unique directory for it, e.g., <code>.cache/lmod/ccpe-{version}{versionsuffix}</code>     or any other container-specific version string.</p> <p>This procedure is very easy in the approach where we do as much as possible work inside the container. All one need is a <code>sed</code> command in the <code>%post</code> section of the build process.</p> <p>When trying to do everything as much as possible outside the container, the solution is  to use a <code>singularity exec</code> to copy the file from the container to the system, edit that file (both can be done in a <code>postinstallcmds</code> in EasyBuild), and then bind mount that file to  the container.</p> </li> </ol>","boost":10},{"location":"c/ccpe/#initialisation","title":"Initialisation","text":"<p>We need two types of initialisation of the CPE container:</p> <ul> <li> <p>When first going into the container, an environment fully compatible with the container     needs to be set up.</p> </li> <li> <p>When starting Slurm jobs from within the container that should also run in the container,      then we really would like an option to propagate that environment.</p> <p>This requires some care when writing the job script, but the module defines an environment variable that can be <code>eval</code>'ed to properly initialise the environment in the job script and run the job script itself in a container. </p> </li> </ul> <p>Also, a full initialisation cannot be done entirely in the container:</p> <ul> <li> <p>Singularity will pass the environment from the calling process. This includes also the Lmod     data structures and all variables set by the currently loaded modules.</p> <p>While it is easy to reset the Lmod data structures, it is not possible to properly reset all other environment variables that are set by those modules. This can only be done by unloading the modules (which executes the module script while reverting the effect of all commands that set something in the environment). As the regular CPE modules from the system are not available in the container, the unloading cannot be done in the container but has to be done before calling singularity.</p> </li> <li> <p>When running an interactive shell in the container, you then want to construct a proper environment     in the container. Singularity may source <code>/etc/bash.bashrc</code> which in turn may or may not source     other initialisation scripts such as <code>/etc/bash.bashrc.local</code>.</p> <p>It looks like if you call <code>singularity exec</code> or <code>singularity shell</code>, there is no automatic initialisation taking place though. So we create an environment variable in the container, <code>INITCCPE</code>, that will at least take care of initialising Lmod properly.  </p> </li> </ul> <p>Initialisation is influenced by the following scripts:</p> <ul> <li> <p>Scripts in <code>/singularity.d/env</code>: Used at the start of <code>singularity shell</code>, <code>singularity exec</code>,     <code>singularity run</code>.</p> <p>What one can do in these scripts, is limited though. It is a good place to set environment variables that should be available in the container.</p> </li> <li> <p>What happens with <code>profile</code>, <code>bash.bashrc</code>, <code>profile.local</code> and <code>bash.bashrc.local</code>, depends      also on which Linux variant, et., is being used.</p> <p>For the CPE containers:</p> <ul> <li> <p>In SUSE, one is advised to only use <code>profile.local</code> and <code>bash.bashrc.local</code> for site-specific     changes and to not change <code>profile</code> and <code>bash.bashrc</code>.</p> </li> <li> <p><code>/etc/profile</code> will source the scripts in <code>/etc/profile.d</code> and then source <code>/etc/profile/local</code>     if that script exists. The script does not exist in the CPE containers though.</p> </li> </ul> <p>However, neither of those is called when a shell is started with <code>singularity shell</code> or <code>singlarity exec</code>. As can be seen from files in <code>/.singularity.d/actions</code>, <code>singularity  exec</code> simply execs the command in a restricted shell (<code>/bin/sh</code>) while <code>singularity shell</code> starts bash with the <code>--norc</code> option.</p> <p><code>singularity run</code> as defined for the CPE container however does source <code>/etc/bash.bashrc</code> and hence <code>/etc/bash.bashrc.local</code> and the <code>~/.bashrc</code> file from the user. However, after reading <code>~/.bashrc</code>, there is still some code somewhere that resets the <code>PS1</code> environment variable to either the value of <code>SINGULARITYENV_PS1</code> or <code>Singlarity&gt;</code>. Somehow, before calling <code>~/.bashrc</code>, <code>PROMPT_COMMAND</code> is set to something like <code>PS1=&lt;prompt from singularity&gt; ; unset PROMPT_COMMAND</code>. Now if PROMPT_COMMAND is set, it is executed before showing the prompt defined by <code>PS1</code> and this hence resets the prompt that is set in., e.g., <code>~/.bashrc</code>.</p> </li> </ul> <p>As currently we have no proper solution to fully initialise the container from the  regular Linux scripts when using <code>singularity shell</code> or <code>singularity exec</code>,  the modules define the <code>INITCCPE</code> environment variable which  contains the commands to execute to initialise Lmod in the container.  Use <code>eval $INITCCPE</code> for that purpose.</p> <p>Our EasyBuild modules do provide a <code>/etc/bash.bashrc.local</code> file that does the same  initialisations as <code>eval $INITCCPE</code>. So calling <code>source /etc/bash.bashrc</code> is also an option  to initialise Lmod in the container.</p>","boost":10},{"location":"c/ccpe/#knowing-we-are-in-the-container","title":"Knowing we are in the container","text":"<p>There are different solutions for that purpose in job scripts:</p> <ul> <li> <p>Check if the directory <code>/.singularity.d</code> exists</p> </li> <li> <p>Singularity sets a number of environment variables, e.g., <code>SINGULARITY_CONTAINER</code>,      and one can check for those.</p> </li> <li> <p>Specifically for the CPE containers, one could also check for one of the environment     variables set by the <code>ccpe</code> modules.</p> </li> </ul> <p>During interactive use:</p> <ul> <li> <p>Singularity will set the prompt to <code>Singularity&gt;</code></p> <p>It does so in a dirty way by putting the command to set the prompt in the environment variable <code>PROMPT_COMMAND</code> and then unset that environment variable as part of the command. As a consequence, in those cases where <code>~/.bashrc</code> is read, any prompt defined in that script may be reset with the singularity one if you do not explicitly unset <code>PROMPT_COMMAND</code>.</p> </li> <li> <p>It is possible to overwrite the default singularity prompt by setting <code>SINGULARITYENV_PS1</code>.</p> </li> <li> <p>One can define a suitable prompt in <code>~/.bashrc</code>, at least for <code>singularity run</code>, and use any of     the tricks given above to detect if one <code>~/.bashrc</code> is executing in the container.</p> </li> </ul>","boost":10},{"location":"c/ccpe/#how-to-recognise-if-an-environment-is-compatible-with-the-container","title":"How to recognise if an environment is compatible with the container?","text":"<p>There is no easy way to see this from the PE modules that are loaded as these modules do not set environment variables that point at the release of the PE, except that in recent version, the PE release is part of the version number for LibSci and perftools.</p> <p>Current solution: Set and environment variable: <code>CCPE_VERSION={version}{versionsuffix}}</code>  (or some other unique version for the container) after a proper initialisation of the environment in the container.</p> <p>This is important as we do not want to clear an environment that is compatible with  the container when we start a job or jog step, and only want to do so if it is not. </p> <p>When starting Slurm jobs from within the container, this is important as one can then set the necessary  environment variables in the calling container already, mimicking the behaviour that users are used to from running jobs outside containers. Moreover, we need to be able to set up an environment in the job script that is then properly inherited when using <code>srun</code> to create job steps as otherwise, each MPI rank would also have  to first create a proper environment.</p>","boost":10},{"location":"c/ccpe/#getting-slurm-to-work","title":"Getting Slurm to work","text":"<p>The container images that LUST provides have been prepared for Slurm support.</p> <p>The container images that LUST provides as base images, have been modified in two crucial places to enable Slurm support by only bind mounting other files and directories. The text below is relevant though if you want to download your own image from the HPE support site and derive from our EasyConfigs to use (on, e.g., a different system for which you happen to be licensed to use the containers).</p> <p>Bind mounting the Slurm commands and libraries and some other libraries and work directories that they use, is not enough to get Slurm working properly in the container. The container needs to know the <code>slurm</code> user with the correct user- and groupid. The <code>slurm</code> user has to be known in <code>/etc/passwd</code> and <code>/etc/group</code> in the container.</p> <p>We know only one way to accomplish this: Rebuilding the container and using the <code>%files</code> section in the definition file to copy those two files from LUMI:</p> <pre><code>Bootstrap: localimage\n\nFrom: cpe_2411.sif\n\n%files\n\n    /etc/group\n    /etc/passwd\n</code></pre> <p>Approaches that try to modify these files in the <code>%post</code> phase, don't work. At that moment you're running a script in singularity, and you don't see the real files, but virtual ones with information about your userid and groups added to those files. Any edit will fail or be discarded, depending on how you do it.</p> <p>Bind-mounting those files from the system also does not work, as singularity then assumes that those files contain all groups and userid, and will not add the lines for  userid and groups of the user that is running the container to the virtual copies.</p> <p>We have adapted the base images that we provide so that the <code>-raw</code> modules below that only rely on bind mounts and environment variables set through the module, can still support running Slurm commands inside the container. However, if a user wants to adapt those scripts for another container downloaded from the HPE web site, or even the same container if they are licensed to use it elsewhere and want to build on our work, they will have to rebuild that image with the above definition file.</p> <p>And of course, if they would like to use it on a different system, things can be different, as, e.g., the numeric user and group id for the Slurm user may be different.  Forget about portability of containers if you need to use these tricks...</p>","boost":10},{"location":"c/ccpe/#starting-jobs","title":"Starting jobs","text":"<p>The problem with running jobs, is that they have to deal with two incompatible environments, as discussed before.</p> <p>We'd like to run the job script in the container to be able to construct an environment compatible with the container, but Slurm will of course start a job batch script or regular job step in a regular system shell. So we will need to call singularity at the right point.</p> <p>In total there are six scenarios that we take into account for jobs launched with <code>sbatch</code>:</p> <ol> <li> <p>Jobs can be launched from within the container:</p> <ol> <li> <p>Using <code>sbatch</code> without <code>--export</code>: LUMI uses the default behaviour of Slurm, which is      inheriting the full environment. As we like to run the batch script also in a container,     we'd also like to inherit that environment in the container that the job will start up.</p> <p>This is also the behaviour that we want when starting job steps with <code>srun</code> from within the container.</p> </li> <li> <p>Using <code>sbatch</code> with <code>--export=$EXPORTCCPE</code>: The environment variable <code>EXPORTCCPE</code> contains     the names of all environment variables set by the <code>ccpe</code> module and that are essential to      be able to run the container. So with this way of starting, the batch script will start     with a clean environment with  no system modules loaded, yet the essential environment variables     needed to start the container in the batch script will still be there.</p> </li> <li> <p>Using <code>sbatch</code> with <code>--export=NONE</code>: The batch script will start in a clean system environment,     unaware of the CPE container from which it was started.</p> </li> </ol> </li> <li> <p>Jobs can be launched from the system:</p> <ol> <li> <p>Using <code>sbatch</code> without <code>--export</code>: Now the batch script will run in the system environment     and that environment has to be cleaned up before starting the singularity container.</p> <p>That clean-up is no different from the clean-up the wrapper scripts do.</p> <p>Note that one cannot be sure that the environment variables from the <code>ccpe</code> moudle will be  set as the batch script can be launched without them.</p> </li> <li> <p>Using <code>sbatch</code> with <code>--export=$EXPORTCCPE</code>: Not really different from when launching from within     the container. If the <code>ccpe</code> module is not loaded and EXPORTCCPE is undefined, this may behave a      little strange...</p> </li> <li> <p>Using <code>sbatch</code> with <code>--export=NONE</code>: The batch script will start in a clean system environment.</p> </li> </ol> </li> </ol> <p>The steps that we take to start a job and execute the job script in the container:</p> <ol> <li> <p>One should first ensure that necessary environment variables to find back the container, do the     proper bindings, etc., are defined. So one my have to load the container if those variables are     not present. This code should not be executed in the container as it would fail to find the module     anyway.</p> </li> <li> <p>Except in one case, we now have a system environment with just some default module loaded, or      other modules also loaded.</p> <p>Clear that environment in a similar way as we do for the wrappers.</p> </li> <li> <p>Restart the job script in the singularity container, but skip the code for the previous two steps.</p> </li> <li> <p>Ensure that the container is properly initialised if we did not inherit a valid container environment.</p> </li> <li> <p>Execute the remainder of the job script in the container.</p> </li> </ol> <p>Possible code to accomplish this is:</p> <pre><code>#!/bin/bash\n#SBATCH -J jobscript-template\n\u2026\n\n#\n# Step 1: Make sure the container environment variables are set.\n# \nif [ -z \"${SWITCHTCCPE}\" ]\nthen\n    module load CrayEnv ccpe/24.11-LUMI || exit\nfi\n\nif [ ! -d \"/.singularity.d\" ]\nthen\n\n    #\n    # Clear the system environment\n    #\n    if [ \"$CCPE_VERSION\" != \"{local_ccpe_version}\" ]\n    then\n\n        for var in ${{EXPORTCCPE//,/ }}\n        do\n            if [ -v $var ] \n            then\n                eval $(declare -p $var | sed -e \"s/$var/save_$var/\")\n            fi\n        done\n\n        module --force purge\n        eval $($LMOD_DIR/clearLMOD_cmd --shell bash --full --quiet)\n        unset LUMI_INIT_FIRST_LOAD\n        unset PROFILEREAD\n\n        for var in ${{save_EXPORTCCPE//,/ }}\n        do\n            varname=\"save_$var\"\n            if [ -v $varname ]\n            then\n                eval $(declare -p $varname | sed -e \"s/save_$var/$var/\")\n                unset $varname\n            fi\n        done\n\n    fi\n\n    # \n    # Restart the job script in the container\n    #\n    exec singularity exec \"$SIFCCPE\" \"$0\" \"$@\"\n\nfi\n\n#\n# Ensure that the container is properly initialised, if this is not yet the case\n#\nif [ \"$CCPE_VERSION\" != \"{local_ccpe_version}\" ]\nthen\n\n    lmod_dir=\"/opt/cray/pe/lmod/lmod\"\n\n    function clear-lmod() {{ [ -d $HOME/.cache/lmod ] &amp;&amp; /bin/rm -rf $HOME/.cache/lmod ; }}\n\n    source /etc/cray-pe.d/cray-pe-configuration.sh\n\n    source $lmod_dir/init/profile\n\n    mod_paths=\"/opt/cray/pe/lmod/modulefiles/core /opt/cray/pe/lmod/modulefiles/craype-targets/default $mpaths /opt/cray/modulefiles /opt/modulefiles\"\n    MODULEPATH=\"\"\n    for p in $(echo $mod_paths)\n    do \n        if [ -d $p ] \n        then\n            MODULEPATH=$MODULEPATH:$p\n        fi\n    done\n    export MODULEPATH=${{MODULEPATH/:/}}\n\n    LMOD_SYSTEM_DEFAULT_MODULES=$(echo ${{init_module_list:-PrgEnv-$default_prgenv}} | sed -E \"s_[[:space:]]+_:_g\") ;\n    export LMOD_SYSTEM_DEFAULT_MODULES\n    eval \"source $BASH_ENV &amp;&amp; module --initial_load --no_redirect restore\"\n    unset lmod_dir\n\n    export CCPE_VERSION=\"{local_ccpe_version}\"\n\nfi\n\nunset SLURM_EXPORT_ENV ;\n\n# \n# From here on, the user can insert the code that runs in the container.\n#\n\nmodule list\n\nsrun \u2026 singularity exec $SIFCCPE &lt;command&gt; \n</code></pre> <p>This is of course way to complicated to expose to users, but line 57-86 is  put in the environment variable <code>INITCCPE</code> so that code can be replaced with <code>eval $INITCCPE</code>, and then the whole block from line 13 till (and including) line 88 is put in the environment variable <code>SWITCHTOCCPE</code> so that block can be replaced with <code>eval $SWITCHTOCCPE</code></p> <p>So basically, all that a user needs is</p> <pre><code>#!/bin/bash\n#SBATCH -J jobscript-template\n\u2026\n\n#\n# Step 1: Make sure the container environment variables are set.\n# \nif [ -z \"${SWITCHTCCPE}\" ]\nthen\n    module load CrayEnv ccpe/24.11-LUMI || exit\nfi\n\n#\n# Steps 2-4: Clean up, switch to executing in the container and ensure a proper \n# container environment.\n#\neval $SWITCHTOCCPE\n\n# \n# From here on, the user can insert the code that runs in the container.\n#\n\nmodule list\n\nsrun \u2026 singularity exec $SIFCCPE &lt;command&gt; \n</code></pre> <p>Let us analyse the code a bit more:</p> <p>The block from line 13 till 53 is only executed if not in the  context of the container, so the first time the batch script runs.  If it does not detect an environment from the container (the test on line 19, with <code>{local_ccpe_version}</code> replaced with the actual version string for the container as determined by the EasyConfig) then:</p> <ul> <li> <p>It first saves some environment variables set by the CCPE modules that should not be erased.</p> <p>This needed some clever bash trickery to avoid that environment variables get expanded.</p> </li> <li> <p>Next, it purges all currently loaded modules which hopefully are from the system environment      as otherwise variables may not be unset,</p> </li> <li> <p>Next it clears Lmod to that all Lmod data structures are removed. Lmod does     come with its own command to do that which is what we call here in the special     way required by Lmod (as the command basically generates a sequence of bash     commands that do the work).</p> </li> <li> <p>Next it restores the environment variables from the <code>ccpe</code> module as they have been erased by     the <code>module purge</code>.</p> </li> </ul> <p>Finally, on line 50m it restarts the batch script with all its arguments in the container.  This causes the batch script to execute again from the start,  but as <code>SWITCHTOCCPE</code> should be defined when we get here, and since we will now be in the container, all code discussed so far will be skipped.</p> <p>The code between line 54 and 86 is already executed in the container.  So if the code detects that there is already a valid environment for the container (where we again simply test for the value of <code>CCPE_VERSION</code>), nothing more is done, but if there is no proper environment, the remaining part of this routine basically runs the code used on LUMI to initialise Lmod with the proper modules from the HPE Cray Programming Environment, but now in the container. As it is done in the container,  you will get the programming environment from the container.</p> <p>On line 88, the script unsets <code>SLURM_EXPORT_ENV</code>. This environment variable would be  set by Slurm if <code>--export</code> was used to submit the batch job, but we do not want this to propagate to job steps started with <code>srun</code> in the container, as there we want the full environment that the user builds in the job script to be propagated.</p> <p>The <code>salloc</code> command does not yet work in a container</p> <p>Currently, we haven't found a way yet to get the <code>salloc</code> command to work properly when started in the container. The workaround is to use <code>salloc</code> outside the container, then go in the container.</p>","boost":10},{"location":"c/ccpe/#easybuild","title":"EasyBuild","text":"","boost":10},{"location":"c/ccpe/#container-for-2411-obtained-from-the-hpe-support-web-site","title":"Container for 24.11 obtained from the HPE support web site.","text":"","boost":10},{"location":"c/ccpe/#version-ccpe-2411-raw-with-system-rocm","title":"Version: ccpe-24.11-raw with system ROCm","text":"<p>In this version, we use the container obtained from the HPE web site without changes in the container, but try to do everything via files and directories that we  bind mount in the container and environment variables that we inject into the container  using <code>SINGULARITYENV_*</code>.</p> <ul> <li> <p>The goal of the EasyConfig is to mimic what the <code>ccpe-config</code> script     from HPE does:</p> <ul> <li>Binding other files from the system</li> <li>Binding Slurm commands</li> <li>Binding libfabric install</li> <li>Binding some system files</li> </ul> </li> <li> <p>Variables defined at the top of the EasyConfig file:</p> <ul> <li> <p><code>local_ccpe_version</code>: This will be used as the value for <code>CCPE_VERSION</code> and     the directory used for the Lmod cache. Set to <code>24.11-raw</code> for this      container.</p> </li> <li> <p><code>local_appl_lumi</code>: System subdirectory that will be used for <code>/appl/lumi</code>     in the container.</p> </li> </ul> </li> <li> <p>We inject the file <code>/.singularity.d/env/99-z-ccpe-init</code> which we use     to define additional environment variables in the container that can     then be used to execute commands.</p> <p>Currently used so that <code>eval $INITCCPE</code> does a full (re)initialization of Lmod so that it functions in the same way as on LUMI.</p> </li> <li> <p>Lmod cache strategy: in <code>postinstallcmds</code>, we copy the file     <code>/opt/cray/pe/lmod/lmod/libexec/myGlobals.lua</code> to the <code>config</code> subdirectory     of the installation directory, edit the path to the Lmod cache with <code>sed</code>,     and then use a bind mount to inject the file in the container when running.</p> </li> <li> <p>libfabric and CXI provider: Bind mount from the system.</p> <p>To find the correct directories and files to bind, execute the following commands:</p> <pre><code>module --redirect show libfabric | grep '\"PATH\"' | awk -F'\"' '{ print $4 }' | sed -e 's|/bin||'\nmodule --loc --redirect show libfabric | sed -e 's|\\(.*libfabric.*\\)/.*|\\1|'\nldd $(module --redirect show libfabric | grep '\"LD_LIBRARY_PATH\"' | awk -F'\"' '{ print $4 }')/libfabric.so | grep libcxi | awk '{print $3}'\n</code></pre> </li> <li> <p>ROCm: ROCm version from the system, so 6.0.3 at the time of writing.</p> <p>To find the correct directories and files to bind, execute the following commands:</p> <p><pre><code>module --loc --redirect show rocm\nmodule --loc --redirect show amd\nmodule --redirect show rocm | grep ROCM_PATH | awk -F'\"' '{ print $4 }'\necho \"$(module --redirect show rocm | grep PKG_CONFIG_PATH | awk -F'\"' '{ print $4 }')/$(module --redirect show rocm | grep PE_PKGCONFIG_LIBS | awk -F'\"' '{ print $4 }').pc\"\n</code></pre> -   Slurm support is provided as much as possible by binding files from the system to ensure that the same version is used in the container as LUMI uses, as otherwise we may expect conflicts.</p> <p>There is an issue though users use this EasyConfig with a freshly downloaded copy of the container. See the remarks earlier in this text on getting Slurm to work in the container.</p> </li> <li> <p>We made a deliberate choice to not hard-code the bindings in the <code>ccpe-*</code>     scripts in case a user would want to add to the environment <code>SINGULARITY_BIND</code> variable,     and also deliberately did not hard-code the path to the container file     in those scripts as in this module, a user can safely delete the container     from the installation directory and use the copy in <code>/appl/local/containers/easybuild-sif-images</code>      instead if they built the container starting from our images and in <code>partition/container</code>.</p> <p>The <code>ccpe-*</code> wrapper scripts are defined in the EasyConfig itself (multiline strings) and brought on the system in <code>postinstallcmds</code> via a trick with bash HERE documents.</p> </li> </ul>","boost":10},{"location":"c/ccpe/#version-ccpe-2411-lumi-with-system-rocm","title":"Version: ccpe-24.11-LUMI with system ROCm","text":"<p>In this version, we made several modifications to the container so that we can install  a LUMI software stack almost the way we would do so without a container. Several of the files that we bind mount in the <code>-raw</code> version are now also included in the container build itself, though we still store copies of it in the installation directory, subdirectory <code>config</code>, which may be useful to experiment with changes and overwrite the versions in the container.</p> <ul> <li> <p>Variables defined at the top of the EasyConfig file:</p> <ul> <li> <p><code>local_ccpe_version</code>: This will be used as the value for <code>CCPE_VERSION</code> and     the directory used for the Lmod cache. Set to <code>24.11-raw</code> for this      container.</p> </li> <li> <p><code>local_appl_lumi</code>: System subdirectory that will be used for <code>/appl/lumi</code>     in the container.</p> </li> </ul> </li> <li> <p>The container that has been provided by LUST as a starting point, does     have some protection built in to prevent it being taken to other systems.     One element of that protection, is some checks of the <code>/etc/slurm/slurm.conf</code>     file. </p> <p>To be able to use the <code>%post</code> section during the \"unpriveleged proot build\" process, that file has to be present in the container. Therefore we copy that file in the <code>%files</code> phase, but remove it again in the <code>%post</code> phase as whe running the container, the whole Slurm configuration directory is bind mounted in the container.</p> </li> <li> <p>We inject the file <code>/.singularity.d/env/99-z-ccpe-init</code> which we use     to define additional environment variables in the container that can     then be used to execute commands.</p> <p>Currently used so that <code>eval $INITCCPE</code> does a full (re)initialization of Lmod so that it functions in the same way as on LUMI.</p> </li> <li> <p>As the container is already set up to support a runscript, we simply inject     a new one via <code>%files</code> which makes it easier to have a nice layout in the      runscript and in the container definition file.</p> </li> <li> <p>Lmod cache strategy: User cache stored in a separate directory,      <code>~/.cache/lmod/ccpe-%(version)s-%(versionsuffix)s</code>, by editing     <code>/opt/cray/pe/lmod/lmod/libexec/myGlobals.lua</code>.</p> </li> <li> <p>libfabric and CXI provider: Bind mount from the system.</p> <p>To find the correct directories and files to bind, execute the following commands:</p> <pre><code>module --redirect show libfabric | grep '\"PATH\"' | awk -F'\"' '{ print $4 }' | sed -e 's|/bin||'\nmodule --loc --redirect show libfabric | sed -e 's|\\(.*libfabric.*\\)/.*|\\1|'\nldd $(module --redirect show libfabric | grep '\"LD_LIBRARY_PATH\"' | awk -F'\"' '{ print $4 }')/libfabric.so | grep libcxi | awk '{print $3}'\n</code></pre> </li> <li> <p>ROCm: ROCm version from the system, so 6.0.3 at the time of writing.</p> <p>To find the correct directories and files to bind, execute the following commands:</p> <pre><code>module --loc --redirect show rocm\nmodule --loc --redirect show amd\nmodule --redirect show rocm | grep ROCM_PATH | awk -F'\"' '{ print $4 }'\necho \"$(module --redirect show rocm | grep PKG_CONFIG_PATH | awk -F'\"' '{ print $4 }')/$(module --redirect show rocm | grep PE_PKGCONFIG_LIBS | awk -F'\"' '{ print $4 }').pc\"\n</code></pre> </li> <li> <p>Slurm support is still provided as much as possible by binding files from the system     to ensure that the same version is used in the container as LUMI uses, as otherwise     we may expect conflicts.</p> <p>One thing is done during the build process though: We need to copy the <code>/etc/group</code>  and <code>/etc/passwd</code> files from the system into the container during the <code>%files</code> phase (editing those files in the <code>%post</code> phase does not work). </p> </li> <li> <p>We made a deliberate choice to not hard-code the bindings in the <code>ccpe-*</code>     scripts in case a user would want to add to the environment <code>SINGULARITY_BIND</code> variable,     and also deliberately did not hard-code the path to the container file     in those scripts as in this module, a user can safely delete the container     from the installation directory and use the copy in <code>/appl/local/containers/easybuild-sif-images</code>      instead if they built the container starting from our images and in <code>partition/container</code>.</p> <p>The <code>ccpe-*</code> wrapper scripts are defined in the EasyConfig itself (multiline strings) and brought on the system in <code>postinstallcmds</code> via a trick with bash HERE documents.</p> </li> <li> <p>The sanity check is specific to the 24.11 containers and will need to be updated     for different versions of the programming environment.</p> </li> </ul>","boost":10},{"location":"c/ccpe/#versions-2411-rocm-62-lumi","title":"Versions 24.11-*-rocm-6.2-LUMI","text":"<p>These containers build upon the <code>24.11-LUMI</code> container but add ROCm 6.2.4 to the container.</p> <p>Three different ways are used:</p> <ul> <li> <p><code>24.11-B-rocm-6.2-LUMI</code> bind mounts a SquashFS file with ROCm 6.2.4 to the container.     This keeps the size of the container small and makes it easier to adapt the container     to the needs of a specific project.</p> </li> <li> <p><code>24.11-C-rocm-6.2-LUMI</code> puts the ROCm installation inside the container. It is installed     from a compressed tar file that is uncompressed during the build process in EasyBuild.     It probably offers only a very minor performance advantage over the <code>-B-rocm</code> version     when building software and even less when running. Build time is less than with the      next version though.</p> </li> <li> <p><code>24.11-CZ-rocm-6.2-LUMI</code> installs ROCm from the AMD site using the SUSE <code>zypper</code> tool.     It is the slowest of the three approaches with build times easily exceeding an hour and     a half. However, using <code>zypper</code> enables users to change the ROCm version themselves      more easily, and also ensures that all OS dependencies are available in the proper version.</p> </li> </ul> <p>Our advise is to start with the <code>-B-rocm</code> version and if there are issues that may come from library compatibility versions, switch to the <code>-CZ-rocm</code> versions.</p> <p>The three containers differ in the way <code>/opt/rocm-6.2.4</code> is populated:</p> <ul> <li> <p><code>24.11-B-rocm-6.2-LUMI</code>: The container build recipe only creates the <code>/opt/rocm-6.2.4</code>     directory as a mount point and as it is needed to successfully complete some other steps     discussed below.</p> </li> <li> <p><code>24.11-C-rocm-6.2-LUMI</code>: In the <code>%files</code> section, we copy a bzip2-compressed tar file with     the ROCm 6.2.4 installation from a central place on LUMI and then in <code>%post</code> untar this in     the right location and delete the compressed tar file again.</p> </li> <li> <p><code>24.11-CZ-rocm-6.2-LUMI</code>: Here we use the SUSE <code>zypper</code> install tool to install ROCm      from AMD-provided packages.</p> </li> </ul> <p>In the first two cases, the ROCm SquashFS file and corresponding bzip2-compressed tar files were obtained from a ROCm installation in another container. To repeat the trick as  a user, you will have to modify either the bind mount source (<code>-B-rocm</code>) or the location of the compressed tar file (<code>-C-rocm</code> variant) as these are in a location managed by LUST.</p> <ul> <li> <p>The <code>rocm</code>, <code>amd</code> and <code>amd-mixed</code> module files are copied from the system (in <code>%files</code>) and      and then edited through <code>sed</code> in <code>%post</code> to change the version to 6.2.4.</p> </li> <li> <p>The <code>rocm*.pc</code> files in <code>/usr/lib64/pkgconfig</code> are copied from the system ((in <code>%files</code>) and      and then edited through <code>sed</code> in <code>%post</code> to change the version to 6.2.4.</p> </li> <li> <p>Also in <code>%post</code>, a symbolic link for <code>/opt/rocm</code> is created pointing to <code>/opt/rocm-6.2.4</code>      through <code>/etc/alternatives</code>.</p> </li> </ul>","boost":10},{"location":"c/ccpe/#versions-2504-rocm-63-sp5-lumi","title":"Versions 25.04-*-rocm-6.3-SP5-LUMI","text":"<p>These containers build upon the Cray SUSE 15 SP5 version of the container. They add both ROCm 6.3.4 and 6.2.4 to the container. The rationale is that the CPE in the container is really meant to be used with ROCm 6.3, but running with ROCm 6.3 may fail as the driver on LUMI is too old, so one can experiment with both versions or see if it is possible to  compile with ROCm 6.3 (which may happen even if another ROCm version is loaded anyway as  the CCE compiler now already includes some code from ROCm 6.3) while run with the older  version of the libraries.</p> <p>Three different versions are currently provided:</p> <ul> <li> <p><code>25.04-B-rocm-6.3-SP5-LUMI</code> bind mounts SquashFS file with ROCm 6.2.4 and 6.3.4      to the container.     This keeps the size of the container small and makes it easier to adapt the container     to the needs of a specific project.</p> </li> <li> <p><code>25.04-CT-rocm-6.3-SP5-LUMI</code> puts the ROCm installation (6.2.4 and 6.3.4) inside the container.      It is installed from a compressed tar file provided by LUST     that is uncompressed during the build process in EasyBuild.     It probably offers only a very minor performance advantage over the <code>-B-rocm</code> version     when building software and even less when running. Build time is less than with the      next version though.</p> </li> <li> <p><code>25.04-C-rocm-6.3-SP5-LUMI</code> installs ROCm 6.2.4 and 6.3.4 from the AMD site using the SUSE <code>zypper</code> tool.     It is the slowest of the three approaches with build times easily exceeding an hour and     a half. However, using <code>zypper</code> enables users to change the ROCm version themselves      more easily, and also ensures that all OS dependencies are available in the proper version.</p> </li> </ul> <p>Our advise is to start with the <code>-B-rocm</code> version and if there are issues that may come from library compatibility versions, switch to the <code>-C-rocm</code> versions. The <code>-CT-rocm</code> version is really only useful if you want to lower the installation time of the container module a bit.</p> <p>The three containers differ in the way <code>/opt/rocm-6.2.4</code> and <code>/opt/rocm-6.3.4</code> are populated:</p> <ul> <li> <p><code>25.04-B-rocm-6.3-SP5-LUMI</code>: The container build recipe only creates the <code>/opt/rocm-6.2.4</code>     and <code>/opt/rocm-6.3.4</code> directories as mount points     and as it is needed to successfully complete some other steps discussed below.</p> </li> <li> <p><code>25.04-CT-rocm-6.3-SP5-LUMI</code>: In the <code>%files</code> section, we copy two bzip2-compressed tar files with     the ROCm 6.2.4 and 6.3.4 installations from a central place on LUMI and then in <code>%post</code> untar this in     the right location and delete the compressed tar file again.</p> </li> <li> <p><code>25.04-C-rocm-6.3-SP5-LUMI</code>: Here we use the SUSE <code>zypper</code> install tool to install ROCm      6.2.4 and 6.3.4 from AMD-provided packages.</p> </li> </ul> <p>Furthermore,</p> <ul> <li> <p>The <code>rocm</code>, <code>amd</code> and <code>amd-mixed</code> module files are copied from the system (in <code>%files</code>) and      and then edited through <code>sed</code> in <code>%post</code> to change the version to 6.2.4 and 6.3.4.</p> </li> <li> <p>The <code>rocm*.pc</code> files in <code>/usr/lib64/pkgconfig</code> are copied from the system ((in <code>%files</code>) and      and then edited through <code>sed</code> in <code>%post</code> to change the version to 6.2.4 and 6.3.4.</p> </li> <li> <p>Also in <code>%post</code>, a symbolic link for <code>/opt/rocm</code> is created pointing to <code>/opt/rocm-6.3.4</code>      through <code>/etc/alternatives</code>.</p> </li> </ul> <p>Other elements in the build:</p> <ul> <li> <p>After creating the <code>.sif</code> file from the download, rename it to      <code>cpe-25.03-SP5.sif</code> and put it in a place where EasyBuild can find it.</p> </li> <li> <p>Variables defined at the top of the EasyConfig file:</p> <ul> <li> <p><code>local_ccpe_version</code>: This will be used as the value for <code>CCPE_VERSION</code> and     the directory used for the Lmod cache. Set to <code>24.11-raw</code> for this      container.</p> </li> <li> <p><code>local_appl_lumi</code>: System subdirectory that will be used for <code>/appl/lumi</code>     in the container.</p> </li> <li> <p>ROCm-related variables:</p> <ul> <li> <p><code>local_rocm_version</code>: System ROCm version, currently <code>6.0.3</code></p> </li> <li> <p><code>local_c1_rocm_version</code>: Default ROCm version for the container, <code>6.3.4</code></p> </li> <li> <p><code>local_c2_rocm_version</code>: Backup ROCm version for the container, <code>6.2.4</code>.</p> </li> </ul> </li> </ul> </li> <li> <p>The file <code>/.singularity.d/env/99-z-ccpe-init</code> is used     to define additional environment variables in the container that can     then be used to execute commands. It is generated in the EasyConfig and     then injected in the container through the <code>%files</code> section of the definition     file.</p> <p>Currently used so that <code>eval $INITCCPE</code> does a full (re)initialization of Lmod so that it functions in the same way as on LUMI.</p> </li> <li> <p>The <code>/etc/bash/bashrc.local</code> file is replaced with one that just calls     <code>eval $INITCCPE</code>, and there is an empty placeholder for <code>/etc/profile.local</code>.</p> </li> <li> <p>As the container is already set up to support a runscript, we simply inject     a new one via <code>%files</code> which makes it easier to have a nice layout in the      runscript and in the container definition file.</p> </li> <li> <p>Compared to the 24.11 container, several packages were missing so a lot more     needs to be added with <code>zypper</code>. This includes an editor, but more importantly,     only the C and POSIX locales were known which was not even enough to use      <code>archspec</code> or install some other packages that give additional effects in     EasyBuild. The solution was to install <code>glibc-locale</code>.</p> </li> <li> <p>Lmod cache strategy: User cache stored in a separate directory,      <code>~/.cache/lmod/ccpe-%(version)s-%(versionsuffix)s</code>, by editing     <code>/opt/cray/pe/lmod/lmod/libexec/myGlobals.lua</code>.</p> </li> <li> <p>libfabric and CXI provider: Bind mount from the system.</p> <p>To find the correct directories and files to bind, execute the following commands:</p> <pre><code>module --redirect show libfabric | grep '\"PATH\"' | awk -F'\"' '{ print $4 }' | sed -e 's|/bin||'\nmodule --loc --redirect show libfabric | sed -e 's|\\(.*libfabric.*\\)/.*|\\1|'\nldd $(module --redirect show libfabric | grep '\"LD_LIBRARY_PATH\"' | awk -F'\"' '{ print $4 }')/libfabric.so | grep libcxi | awk '{print $3}'\n</code></pre> </li> <li> <p>The 25.03 containers need the xpmem libraries and module from the system which     is done through bind mounts (could in principle replace with copying from the     system).</p> <p>The <code>xpmem</code> installation in the container is then still broken as the default is not  properly set in <code>/etc/alternatives</code> and as it is not added to the system shared library search path through a file in <code>/etc/ld.so.conf.d</code>, so these are also fixed in the container definition.</p> </li> <li> <p>There are issues with <code>cray-pals</code> on LUMI. Older versions are installed in <code>/opt/cray/pe</code>,     but for some reason, the version that came with 24.03 is actually installed in <code>/opt/cray</code>,     but there the modulefiles are not found.</p> <p>It is also missing in the container, yet used by some other libraries from the  PE.</p> <p>Rather than binding from the system as we do for <code>xpmem</code>, we chose to copy  the libraries to the container. We kept the installation in <code>/opt/cray/pals</code> as otherwise the  modulefiles would not be correct, but copied the modulefiles to the proper locations in <code>/opt/cray/pe</code> rather than trying to adapt the <code>MODULEPATH</code>.</p> <p>Rather than using the trick with the links in <code>/opt/cray/pe/lib64</code>, it gets its own file in <code>/etc/ld.so.conf.d</code> as is the case on LUMI (where the links also exist  though but point to an older version of the library).</p> <p>Moreover, libpals requires a newer version of libjansson then we get with <code>zypper</code> using the OpenSUSE repositories, so we copy it from the system and create the  necessary links.</p> </li> <li> <p>ROCm: Either bound from a SquashFS file, installed from tar files or installed     via <code>zyppr</code>, depending on the container.</p> </li> <li> <p>Slurm support is still provided as much as possible by binding files from the system     to ensure that the same version is used in the container as LUMI uses, as otherwise     we may expect conflicts.</p> <p>One thing is done during the build process though: We need to copy the <code>/etc/group</code>  and <code>/etc/passwd</code> files from the system into the container during the <code>%files</code> phase (editing those files in the <code>%post</code> phase does not work). </p> </li> <li> <p>We made a deliberate choice to not hard-code the bindings in the <code>ccpe-*</code>     scripts in case a user would want to add to the environment <code>SINGULARITY_BIND</code> variable,     and also deliberately did not hard-code the path to the container file     in those scripts as in this module, a user can safely delete the container     from the installation directory and use the copy in <code>/appl/local/containers/easybuild-sif-images</code>      instead if they built the container starting from our images and in <code>partition/container</code>.</p> <p>The <code>ccpe-*</code> wrapper scripts are defined in the EasyConfig itself (multiline strings) and brought on the system in <code>postinstallcmds</code> via a trick with bash HERE documents.</p> </li> <li> <p>The sanity check is specific to the 25.11 containers and will need to be updated     for different versions of the programming environment. We've tried to catch everything     which depends on the version of the PE in variables in the EasyConfig, defined      just above the sanity check commands (currently only 1).</p> </li> </ul>","boost":10},{"location":"c/ccpe/#archived-easyconfigs","title":"Archived EasyConfigs","text":"<p>The EasyConfigs below are additional easyconfigs that are not directly available on the system for installation. Users are advised to use the newer ones and these archived ones are unsupported. They are still provided as a source of information should you need this, e.g., to understand the configuration that was used for earlier work on the system.</p> <ul> <li> <p>EasyConfig ccpe-23.12-cce_17-18-rocm-5.4.1-17_18-COPY.eb, with module ccpe/23.12-cce_17-18-rocm-5.4.1-17_18-COPY</p> </li> <li> <p>EasyConfig ccpe-23.12-cce_17-18-rocm-5.4.1-17_18.eb, with module ccpe/23.12-cce_17-18-rocm-5.4.1-17_18</p> </li> </ul>","boost":10},{"location":"c/ccpe-cpe/","title":"ccpe-cpe","text":"<p>[package list]</p>","boost":10},{"location":"c/ccpe-cpe/#ccpe-cpe","title":"ccpe-cpe","text":"","boost":10},{"location":"c/ccpe-cpe/#archived-easyconfigs","title":"Archived EasyConfigs","text":"<p>The EasyConfigs below are not directly available on the system for installation. They are however still a useful source of information if you want to port the the install recipe to the currently available environments on LUMI.</p> <ul> <li>EasyConfig ccpe-cpe-23.09.eb, with module ccpe-cpe/23.09</li> </ul>","boost":10},{"location":"d/DocBook-XSL/","title":"DocBook-XSL","text":"<p>[package list]</p>","boost":10},{"location":"d/DocBook-XSL/#docbook-xsl","title":"DocBook-XSL","text":"","boost":10},{"location":"d/DocBook-XSL/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider DocBook-XSL/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>DocBook-XSL/1.79.1-CSCS (EasyConfig: DocBook-XSL-1.79.1-CSCS.eb)</p> </li> <li> <p>DocBook-XSL/1.79.1 (EasyConfig: DocBook-XSL-1.79.1.eb)</p> </li> </ul>","boost":10},{"location":"d/DocBook-XSL/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>(Former) home on SourceForge</p> <ul> <li>SourceForge downloads</li> </ul> </li> <li> <p>New development home on GitHub</p> </li> </ul> <p>As the release strategy on GitHub is unclear the EasyConfig files stick to the SourceForge releases for now.</p>","boost":10},{"location":"d/DocBook-XSL/#easyconfigs","title":"EasyConfigs","text":"<ul> <li> <p>No support for DocTools-XSL in the EasyBuilders repository as of August 2021</p> </li> <li> <p>No support for DocTools-XSL in the CSCS repository as of August 2021</p> </li> </ul>","boost":10},{"location":"d/DocBook-XSL/#strategy-for-the-cscs-version-which-has-etcxml-present","title":"Strategy for the CSCS version which has /etc/xml present","text":"<ul> <li> <p>All files from the tar-file are installed in the install directory.</p> </li> <li> <p>The <code>install.sh</code> script does not make sense in our case.</p> </li> <li> <p>The <code>rewritePrefix</code> fields in <code>catalog.xml</code> are rewritten to point     to the correct directory. The <code>catalog.xml</code> file is also renamed to     <code>docbook.xml</code>.</p> </li> <li> <p>A new main catalog is generated based on the system <code>/etc/xml/catalog</code>     file with the paths corrected for the system entries (not yet robust!)     and a new entry added for <code>docbook.xml</code>.</p> </li> <li> <p>The module also sets the environment variable <code>XML_CATALOG_FILES</code> to     point to the new <code>catalog</code> file in the install directory.</p> <p>This implies that the main system catalog is no longer used. Any update to it will not be reflected in this module unless the module is reinstalled!</p> </li> </ul>","boost":10},{"location":"d/DocBook-XSL/#strategy-on-lumi-as-long-as-there-is-no-etcxml-to-integrate-with","title":"Strategy on LUMI as long as there is no /etc/xml to integrate with","text":"<ul> <li> <p>All files from the tar-file are installed in the install directory.</p> </li> <li> <p>The <code>install.sh</code> script does not make sense in our case.</p> </li> <li> <p>The <code>rewritePrefix</code> fields in <code>catalog.xml</code> are rewritten to point     to the correct directory.</p> </li> </ul>","boost":10},{"location":"d/Doxygen/","title":"Doxygen","text":"<p>[package list]</p>","boost":10},{"location":"d/Doxygen/#doxygen","title":"Doxygen","text":"","boost":10},{"location":"d/Doxygen/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Doxygen/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>Doxygen/1.9.1-buildtoolsDevel (EasyConfig: Doxygen-1.9.1-buildtoolsDevel.eb)</li> </ul>","boost":10},{"location":"e/ESMF/","title":"ESMF","text":"<p>[package list]</p>","boost":10},{"location":"e/ESMF/#esmf","title":"ESMF","text":"","boost":10},{"location":"e/ESMF/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider ESMF/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>ESMF/8.6.0-cpeCray-24.03-MPI.werktNogNiet (EasyConfig: ESMF-8.6.0-cpeCray-24.03-MPI.werktNogNiet.eb)</p> </li> <li> <p>ESMF/8.6.0-cpeCray-24.03-sequential (EasyConfig: ESMF-8.6.0-cpeCray-24.03-sequential.eb)</p> </li> <li> <p>ESMF/8.6.0-cpeGNU-24.03-MPI.WerktNogNiet (EasyConfig: ESMF-8.6.0-cpeGNU-24.03-MPI.WerktNogNiet.eb)</p> </li> <li> <p>ESMF/8.6.0-cpeGNU-24.03-sequential (EasyConfig: ESMF-8.6.0-cpeGNU-24.03-sequential.eb)</p> </li> </ul>","boost":10},{"location":"e/ESMF/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>ESMF home page</p> </li> <li> <p>ESMF on SourceForge</p> </li> <li> <p>ESMF on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> <li> <p>ESMF documetation</p> <ul> <li>ESMF build documentation](https://earthsystemmodeling.org/docs/release/latest/ESMF_usrdoc/node10.html)</li> </ul> </li> </ul>","boost":10},{"location":"e/ESMF/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>ESMF support in the EasyBuilders repository</p> </li> <li> <p>ESMF support in the CSCS repository</p> </li> </ul> <p>Note that ESMF uses a custom EasyBlock which needs adaptations for Cray systems.</p>","boost":10},{"location":"e/ESMF/#esmf-811-for-cpe-2108","title":"ESMF 8.1.1 for CPE 21.08","text":"<ul> <li> <p>The EasyConfig file is an adaptation from the CSCS one.</p> </li> <li> <p>TODO: The EasyBuilders version uses a patch. Does this add functionality?</p> </li> <li> <p>Building fails with cpeAMD, with very strange error messages.</p> </li> </ul>","boost":10},{"location":"e/ESMF/#esmf-820-for-cpe-2108","title":"ESMF 8.2.0 for CPE 21.08","text":"<ul> <li>This version does not compile with gfortran unless the flag to allow argument     mismatch is used. The problem is that the build procedure does not pick up     <code>F90FLAGS</code> etc., so we've done some hand work with <code>preconfigopts</code> and     <code>prebuildopts</code>.</li> </ul>","boost":10},{"location":"e/ESMF/#esmf-830-for-cpe-2206","title":"ESMF 8.3.0 for CPE 22.06","text":"<ul> <li> <p>Near-trivial version bump, but the way the sources are distributed has changed.</p> </li> <li> <p>Building with AOCC still fails.</p> </li> <li> <p>Note that the build process does include some testing.</p> </li> </ul>","boost":10},{"location":"e/ESMF/#version-841-from-cpe-2212-on","title":"Version 8.4.1 from CPE 22.12 on","text":"<ul> <li> <p>Trivial version bump of the 8.3.0 EasyConfig</p> </li> <li> <p>For LUMI/23.12, license information was added to the installation.</p> </li> </ul>","boost":10},{"location":"e/ESMF/#version-860-for-lumi2403","title":"Version 8.6.0 for LUMI/24.03","text":"<ul> <li> <p>Trivial version bump of the 8.4.1 EasyConfig for LUMI/23.12.</p> </li> <li> <p>Added buildtools.</p> </li> <li> <p>It seems that on the GPU nodes, some code is compiled that is otherwise not compiled     (as it caused a problem) so there may be some support for GPU acceleration.</p> <p>The cpeCray version does not yet build on LUMI-G.</p> </li> </ul>","boost":10},{"location":"e/ESMF/#version-860-for-2411","title":"Version 8.6.0 for 24.11","text":"<ul> <li> <p>Needed a second version. It turns out that the version compiled with <code>mpiuni</code> is serial,     while <code>mpicomm = mpi</code> is needed to build an MPI-aware version.</p> </li> <li> <p>Corrected the home page.</p> </li> </ul>","boost":10},{"location":"e/EasyBuild/","title":"EasyBuild","text":"<p>[package list]</p>","boost":10},{"location":"e/EasyBuild/#easybuild","title":"EasyBuild","text":"","boost":10},{"location":"e/EasyBuild/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider EasyBuild/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>EasyBuild/5.1.1-bootstrap (EasyConfig: EasyBuild-5.1.1-bootstrap.eb)</p> <p>This EasyConfig installs a minimal version of EasyBuild without the EasyConfigs. It installs EasyBuild for use with a cray-python Python interpreter (in this case, 3.11.7), but the installation can be done with an EasyBuild module that uses a different Python. Its main goal was to explore settings for EasyBuild 5 and to test a proper install  recipe with all bells and whistles that can only be installed from an EasyBuild executable using the same EasyBuild version.</p> </li> <li> <p>EasyBuild/5.1.1-LUMI (EasyConfig: EasyBuild-5.1.1-LUMI.eb)</p> </li> <li> <p>EasyBuild/5.1.1 (EasyConfig: EasyBuild-5.1.1.eb)</p> </li> </ul>","boost":10},{"location":"e/Elk/","title":"Elk","text":"<p>[package list]</p>","boost":10},{"location":"e/Elk/#elk","title":"Elk","text":"","boost":10},{"location":"e/Elk/#license-information","title":"License information","text":"<p>Elk is freely available under the GNU General Public License version 3.</p>","boost":10},{"location":"e/Elk/#user-documentation","title":"User documentation","text":"<p>Elk is \"an all-electron full-potential linearised augmented-planewave (FP-LAPW) code. Designed to be as developer friendly as possible so that new developments in the field of density functional theory (DFT) can be added quickly and reliably.\". Elk can be run on LUMI-C.</p> <p>There is currently no version of Elk that can use the AMD GPUs in the LUMI-G.</p>","boost":10},{"location":"e/Elk/#installing-elk","title":"Installing Elk","text":"<p>We provide automatic installation scripts for several versions of Elk. In general, the installation procedure is described on the EasyBuild page. The step by step procedure to install Elk 10.3.12 is:</p> <ol> <li>Load the LUMI software environment: <code>module load LUMI/24.03</code>.</li> <li>Select the LUMI-C partition: <code>module load partition/C</code>.</li> <li>Load the EasyBuild module: <code>module load EasyBuild-user</code>.</li> </ol> <p>Then, you can run the install command</p> <pre><code>$ eb -r Elk-10.3.12-cpeGNU-24.03.eb\n</code></pre> <p>The installation takes about 3 minutes. Afterwards, you will have a module called \"Elk/10.3.12-cpeGNU-24.03\" installed in your home directory. Load the module to use it</p> <pre><code>$ module load Elk/10.3.12-cpeGNU-24.03\n</code></pre> <p>The main Elk binary, <code>elk</code>, as well as the <code>spacegroup</code> and <code>eos</code> utility programs will now be in your <code>PATH</code>. Launch Elk via the Slurm scheduler with <code>srun elk</code>. Please note that you must do <code>module load LUMI/24.03 partition/C</code> to see your Elk module in the module system. The same applies to the Slurm batch scripts which you send to the compute nodes.</p> <p>You can see other versions of Elk that can be automatically installed by running the EasyBuild command</p> <pre><code>$ eb -S Elk\n</code></pre> <p>or checking the list further down on this page</p>","boost":10},{"location":"e/Elk/#example-batch-script","title":"Example batch script","text":"<p>A typical batch job with 16 MPI ranks per node and 8 OpenMP threads per rank:</p> <pre><code>#!/bin/bash\n#SBATCH -A project_XYZ\n#SBATCH -J elkjob\n#SBATCH -p standard\n#SBATCH -t 10:00:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=16\n#SBATCH --cpus-per-task=8\n\nml LUMI/24.03\nml Elk/10.3.12-cpeGNU-24.03\n\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\nexport OMP_NUM_THREADS=8\nexport OMP_PLACES=cores\nexport OMP_PROC_BIND=false\nexport OMP_STACKSIZE=256M\nulimit -Ss unlimited\n\necho \"Script initiated at `date` on `hostname`\"\nsrun elk &gt; out.log\necho \"Script finished at `date` on `hostname`\"\n</code></pre>","boost":10},{"location":"e/Elk/#species-files-example-input-files-and-elk-makeinc-file","title":"Species files, example input files, and Elk make.inc file.","text":"<p>Elk species files and example input files can be found in the directories <pre><code>$EBROOTELK/species\n$EBROOTELK/examples\n</code></pre> For the case that you would like to build a custom version of Elk, you can find the Elk <code>make.inc</code> file which was generated when building with EasyBuild at <pre><code>$EBROOTELK/make.inc\n</code></pre></p>","boost":10},{"location":"e/Elk/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Elk/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>Elk/10.3.12-cpeGNU-24.03 (EasyConfig: Elk-10.3.12-cpeGNU-24.03.eb)</li> </ul>","boost":10},{"location":"e/Elk/#technical-documentation","title":"Technical documentation","text":"<ul> <li>Elk home page</li> </ul>","boost":10},{"location":"e/Elk/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support in the EasyBuilders repository</p> </li> <li> <p>There is no support for Elk in the CSCS repository.</p> </li> </ul>","boost":10},{"location":"e/Elk/#version-846-for-cpe-2112","title":"Version 8.4.6 for CPE 21.12","text":"<ul> <li> <p>Own development</p> </li> <li> <p>Some scripts copied in the regular EasyBuilders EasyConfig are not installed     in this version.</p> </li> </ul>","boost":10},{"location":"e/Elk/#version-8430-for-cpe-2206","title":"Version 8.4.30 for CPE 22.06","text":"<ul> <li> <p>Straightforward port of the 8.4.6 EasyConfig.</p> </li> <li> <p>A few from the scripts from the <code>utilities</code> subdirectory are now included,     but not <code>utilities/xps</code> as that still contains uncompiled C code so it is     not clear what should be copied there or be built that is not yet built.</p> </li> </ul>","boost":10},{"location":"e/Elk/#version-8710-for-cpe-2208-and-2212","title":"Version 8.7.10 for CPE 22.08 and 22.12","text":"<ul> <li> <p>The make.inc is generated by the EasyConfig.</p> </li> <li> <p>Builds with support for Libxc and Wannier90.</p> </li> </ul>","boost":10},{"location":"e/Elk/#version-10312-for-cpe-2403","title":"Version 10.3.12 for CPE 24.03","text":"<ul> <li>Derived from the 8.7.10 EasyConfig.</li> </ul>","boost":10},{"location":"e/ecCodes/","title":"ecCodes","text":"<p>[package list]</p>","boost":10},{"location":"e/ecCodes/#eccodes","title":"ecCodes","text":"","boost":10},{"location":"e/ecCodes/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider ecCodes/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>ecCodes/2.30.0-cpeGNU-23.03 (EasyConfig: ecCodes-2.30.0-cpeGNU-23.03.eb)</li> </ul>","boost":10},{"location":"e/expat/","title":"expat","text":"<p>[package list]</p>","boost":10},{"location":"e/expat/#expat","title":"expat","text":"","boost":10},{"location":"e/expat/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider expat/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>expat/2.4.1-static (EasyConfig: expat-2.4.1-static.eb)</p> </li> <li> <p>expat/2.4.1 (EasyConfig: expat-2.4.1.eb)</p> </li> </ul>","boost":10},{"location":"f/FFmpeg/","title":"FFmpeg","text":"<p>[package list]</p>","boost":10},{"location":"f/FFmpeg/#ffmpeg","title":"FFmpeg","text":"","boost":10},{"location":"f/FFmpeg/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider FFmpeg/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>FFmpeg/4.3.3-cpeCray-21.08 (EasyConfig: FFmpeg-4.3.3-cpeCray-21.08.eb)</p> </li> <li> <p>FFmpeg/4.3.3-cpeGNU-21.08 (EasyConfig: FFmpeg-4.3.3-cpeGNU-21.08.eb)</p> </li> </ul>","boost":10},{"location":"f/FFmpeg/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>FFmpeg home page</p> </li> <li> <p>FFmpeg internal git</p> </li> </ul>","boost":10},{"location":"f/FFmpeg/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>FFmpeg support in the EasyBuilders repository</p> </li> <li> <p>FFmpeg support in the CSCS repository</p> </li> </ul> <p>Note: It is not clear is NASM is really a dependency. From the documentation it looks like it is only needed at build time so it appears to be wrongly marked as a dependency in EasyBuild.</p>","boost":10},{"location":"f/FFmpeg/#433-for-cpe-2108","title":"4.3.3 for CPE 21.08","text":"<ul> <li>We started from the EasyBuilders ones as those seem to be a lot more complete     at least in the list of dependencies. It may be that this only influences     the executables and not the libraries though.</li> </ul>","boost":10},{"location":"f/feh/","title":"feh","text":"<p>[package list]</p>","boost":10},{"location":"f/feh/#feh","title":"feh","text":"","boost":10},{"location":"f/feh/#license-information","title":"License information","text":"<p>The license for feh can be found in the COPYING file in the GitHub repository.</p> <p>A copy of this file can be found in <code>$EBROOTFEH/share/licenses/feh</code> after installing and loading the module.</p>","boost":10},{"location":"f/feh/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider feh/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>feh/2.26-cpeGNU-24.03 (EasyConfig: feh-2.26-cpeGNU-24.03.eb)</p> </li> <li> <p>feh/3.10.3-cpeGNU-24.03 (EasyConfig: feh-3.10.3-cpeGNU-24.03.eb)</p> </li> </ul>","boost":10},{"location":"f/feh/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>feh homepage</p> <p>feh should be downloaded from its homepage, not from GitHub.</p> </li> <li> <p>feh development on GitHub</p> </li> </ul>","boost":10},{"location":"f/feh/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support for feh in the EasyBuilders repository</p> </li> <li> <p>There is no support for feh in the CSCS repository.</p> </li> <li> <p>Spack support for feh</p> </li> </ul>","boost":10},{"location":"f/feh/#version-226-for-2403","title":"Version 2.26 for 24.03","text":"<ul> <li> <p>The EasyConfig is a direct port of the EasyBuilders one.</p> <p>Also copy the COPYING file to our standard location.</p> </li> </ul>","boost":10},{"location":"f/feh/#version-3103-for-2403","title":"Version 3.10.3 for 24.03","text":"<ul> <li> <p>Starting from the EasyBuilders EasyConfig, but added support for libmagic     from the file package and libexif.</p> <p>Also copy the COPYING file to our standard location.</p> </li> </ul>","boost":10},{"location":"f/file/","title":"file","text":"<p>[package list]</p>","boost":10},{"location":"f/file/#file","title":"file","text":"","boost":10},{"location":"f/file/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider file/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>file/5.32-static (EasyConfig: file-5.32-static.eb)</p> </li> <li> <p>file/5.40-static (EasyConfig: file-5.40-static.eb)</p> </li> </ul>","boost":10},{"location":"f/flex/","title":"flex","text":"<p>[package list]</p>","boost":10},{"location":"f/flex/#flex","title":"flex","text":"","boost":10},{"location":"f/flex/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider flex/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>flex/2.6.4-buildtoolsDevel (EasyConfig: flex-2.6.4-buildtoolsDevel.eb)</li> </ul>","boost":10},{"location":"g/GDAL/","title":"GDAL","text":"<p>[package list]</p>","boost":10},{"location":"g/GDAL/#gdal","title":"GDAL","text":"","boost":10},{"location":"g/GDAL/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider GDAL/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>GDAL/3.8.2-cpeGNU-23.09-noPython (EasyConfig: GDAL-3.8.2-cpeGNU-23.09-noPython.eb)</p> </li> <li> <p>GDAL/3.8.2-cpeGNU-23.09-shared-noPython (EasyConfig: GDAL-3.8.2-cpeGNU-23.09-shared-noPython.eb)</p> </li> <li> <p>GDAL/3.8.2-cpeGNU-23.09-static-noPython (EasyConfig: GDAL-3.8.2-cpeGNU-23.09-static-noPython.eb)</p> </li> </ul>","boost":10},{"location":"g/GDAL/#technical-documentation","title":"Technical documentation","text":"","boost":10},{"location":"g/GDAL/#easybuild","title":"EasyBuild","text":"","boost":10},{"location":"g/GDAL/#gdal-382-for-cpegnu-2309-and-later","title":"GDAL 3.8.2 for cpeGNU 23.09 and later","text":"<ul> <li> <p>Problems with the GDAL CMake build process</p> <ul> <li> <p>The configuration fails with Cray HDF5.</p> </li> <li> <p>It appears that <code>-fPIC</code> is not always automatically added when     building shared libraries, leading to link error.</p> <p>Even introducing the <code>-fPIC</code> flag via <code>toolchainopts</code> doesn't seem to work.</p> </li> </ul> </li> </ul>","boost":10},{"location":"g/GPP/","title":"GPP","text":"<p>[package list]</p>","boost":10},{"location":"g/GPP/#gpp","title":"GPP","text":"","boost":10},{"location":"g/GPP/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider GPP/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>GPP/2.27 (EasyConfig: GPP-2.27.eb)</li> </ul>","boost":10},{"location":"g/GPP/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>GPP web site</p> </li> <li> <p>GPP on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"g/GPP/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>No support for GPP in the EasyBuilders repository</p> </li> <li> <p>No support for GPP in the CSCS repository</p> </li> </ul>","boost":10},{"location":"g/GPP/#version-227-system-toolchain","title":"Version 2,27, SYSTEM toolchain","text":"<ul> <li>ConfigureMake EasyConfig developed from scratch.</li> </ul>","boost":10},{"location":"g/GROMACS/","title":"GROMACS","text":"<p>[package list]</p>","boost":10},{"location":"g/GROMACS/#gromacs","title":"GROMACS","text":"","boost":10},{"location":"g/GROMACS/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider GROMACS/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>GROMACS/2021.4-cpeCray-22.08-PLUMED-2.7.4-CPU (EasyConfig: GROMACS-2021.4-cpeCray-22.08-PLUMED-2.7.4-CPU.eb)</p> </li> <li> <p>GROMACS/2021.4-cpeCray-24.03-PLUMED-2.7.4-CPU (EasyConfig: GROMACS-2021.4-cpeCray-24.03-PLUMED-2.7.4-CPU.eb)</p> </li> <li> <p>GROMACS/2021.4-cpeGNU-22.08-PLUMED-2.7.4-CPU-custom (EasyConfig: GROMACS-2021.4-cpeGNU-22.08-PLUMED-2.7.4-CPU-custom.eb)</p> </li> <li> <p>GROMACS/2021.4-cpeGNU-22.08-PLUMED-2.7.4-noPython-CPU (EasyConfig: GROMACS-2021.4-cpeGNU-22.08-PLUMED-2.7.4-noPython-CPU.eb)</p> </li> <li> <p>GROMACS/2021.4-cpeGNU-22.08-PLUMED-2.8.0-cray-python-3.9.12.1-OpenCL (EasyConfig: GROMACS-2021.4-cpeGNU-22.08-PLUMED-2.8.0-cray-python-3.9.12.1-OpenCL.eb)</p> </li> </ul>","boost":10},{"location":"g/GROMACS-SWAXS/","title":"GROMACS-SWAXS","text":"<p>[package list]</p>","boost":10},{"location":"g/GROMACS-SWAXS/#gromacs-swaxs","title":"GROMACS-SWAXS","text":"","boost":10},{"location":"g/GROMACS-SWAXS/#license-information","title":"License information","text":"<p>GROMACS is distributed under the  GNU Lesser General Public License (LGPL) Version 2.1 or later, but it uses various components licensed differently. An overview is given in the <code>COPYING</code> file in the GitLab repository. It is not clear if GROMACS-SWAXS has an additional license. The information could not be found when preparing this text.</p>","boost":10},{"location":"g/GROMACS-SWAXS/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider GROMACS-SWAXS/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>GROMACS-SWAXS/2021.7-0.5.1-cpeGNU-23.09-CPU (EasyConfig: GROMACS-SWAXS-2021.7-0.5.1-cpeGNU-23.09-CPU.eb)</p> </li> <li> <p>GROMACS-SWAXS/2022.5-0.1-cpeGNU-23.09-CPU (EasyConfig: GROMACS-SWAXS-2022.5-0.1-cpeGNU-23.09-CPU.eb)</p> </li> </ul>","boost":10},{"location":"g/GROMACS-SWAXS/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>GROMACS-SWAXS on the research group's pages</p> </li> <li> <p>GROMACS-SWAXS docs</p> <ul> <li>When trying this first, the system requirements in the installation manual      were outdated compared to remarks found in the GitLab repository on compiler     versions used.</li> </ul> </li> <li> <p>GROMACS-SWAXS GitLab</p> <ul> <li>GitLab releases</li> </ul> </li> <li> <p>There is no support for GROMACS-SWAXS in the EasyBuilders or CSCS repositories.</p> </li> <li> <p>gromacs-swaxs in Spack</p> <p>The spack package confirms that this variant is not compatible with the PLUMED modifications nor with OpenCL or SYCL versions of GROMACS. Otherwise it simply uses the same  build process as for GROMACS.</p> </li> </ul>","boost":10},{"location":"g/GROMACS-SWAXS/#version-20217-051-for-cpegnu2309","title":"Version 2021.7-0.5.1 for cpeGNU/23.09","text":"<ul> <li> <p>This is a trivial port of our EasyConfig for GROMACS 21.7.</p> </li> <li> <p>Generation of double precision binaries was turned off as that option was not     mentioned in the GROMACS-SWAXS instructions. It is not clear if the additions     also support double precision.</p> </li> </ul>","boost":10},{"location":"g/GROMACS-SWAXS/#version-202255-01-for-cpegnu2305","title":"Version 20225.5-0.1 for cpeGNU/23.05","text":"<ul> <li>Port of our EasyConfig for GROMACS 22.6 with the same modifications as used for     the 2021.7-0.5.1 version of GROMACS-SWAXS.</li> </ul>","boost":10},{"location":"g/Ghostscript/","title":"Ghostscript","text":"<p>[package list]</p>","boost":10},{"location":"g/Ghostscript/#ghostscript","title":"Ghostscript","text":"","boost":10},{"location":"g/Ghostscript/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Ghostscript/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>Ghostscript/9.55.0-cpeCray-21.08 (EasyConfig: Ghostscript-9.55.0-cpeCray-21.08.eb)</p> </li> <li> <p>Ghostscript/9.55.0-cpeGNU-21.08 (EasyConfig: Ghostscript-9.55.0-cpeGNU-21.08.eb)</p> </li> </ul>","boost":10},{"location":"g/Ghostscript/#technical-documentation","title":"Technical documentation","text":"<ul> <li>Ghostscript home page</li> </ul>","boost":10},{"location":"g/Ghostscript/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>ghostscript support in the EasyBuilders repository</p> </li> <li> <p>ghostscript support in the CSCS repository</p> </li> </ul>","boost":10},{"location":"g/Ghostscript/#version-9550-for-cpe-2108","title":"Version 9.55.0 for cpe 21.08","text":"<ul> <li> <p>This version should include the new all-C PDF interpreter which should process a lot     more PDF files than older versions.</p> </li> <li> <p>The EasyConfig file is based on the EasyBuilders one with documentation taken from     the UAntwerpen one.</p> </li> </ul>","boost":10},{"location":"g/Go/","title":"Go","text":"<p>[package list]</p>","boost":10},{"location":"g/Go/#go","title":"Go","text":"","boost":10},{"location":"g/Go/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Go/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>Go/1.17.6 (EasyConfig: Go-1.17.6.eb)</li> </ul>","boost":10},{"location":"g/Go/#technical-documentation","title":"Technical documentation","text":"<ul> <li>Go web site</li> </ul>","boost":10},{"location":"g/Go/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Go support in the EasyBuilders repository</p> </li> <li> <p>There is no support for Go in the CSCS repository</p> </li> </ul>","boost":10},{"location":"g/Go/#go-1176","title":"Go 1.17.6","text":"<ul> <li> <p>Introduced with the 21.12 CPE but compiled against the SYSTEM toolchain.</p> </li> <li> <p>The EasyConfig is a direct port of the EasyBuilders one with some additional     documentation.</p> </li> </ul>","boost":10},{"location":"g/git/","title":"git","text":"<p>[package list]</p>","boost":10},{"location":"g/git/#git","title":"git","text":"","boost":10},{"location":"g/git/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider git/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>git/2.33.1-nodocs (EasyConfig: git-2.33.1-nodocs.eb)</p> </li> <li> <p>git/2.33.1 (EasyConfig: git-2.33.1.eb)</p> </li> <li> <p>git/2.37.2-devel (EasyConfig: git-2.37.2-devel.eb)</p> </li> <li> <p>git/2.37.2-devel2 (EasyConfig: git-2.37.2-devel2.eb)</p> </li> <li> <p>git/2.38.1 (EasyConfig: git-2.38.1.eb)</p> </li> </ul>","boost":10},{"location":"g/git/#technical-documentation","title":"Technical documentation","text":"<p>From version 2.38.1 on, we bundle <code>git-lfs</code> in the <code>git</code> module.</p> <ul> <li> <p>Git home page</p> </li> <li> <p>Git on GitHub</p> <ul> <li>GitHub releases via tags</li> </ul> </li> <li> <p>git-lfs GitHub</p> </li> <li> <p>git-lfs project on GitHub</p> </li> </ul>","boost":10},{"location":"g/git/#build-instructions","title":"Build instructions","text":"<p>To install git against the sytem toolchain, several libraries need to be installed in development versions:</p> <ul> <li>Header files libintl.h, iconv.h (glibc-devel on SUSE)</li> <li>zlib with zlib.h (zlib-devel on SUSE)</li> <li>libexpat with expat.h (libexpat-devel on SUSE)</li> <li>libcurl with curl.h (libcurl-devel on SUSE)</li> <li>OpenSSL development libraries?? Needed according to EasyBuilders but not found     in the configure log.</li> </ul> <p>To generate man pages or info pages, AsciiDoc is needed. Furthermore, to generate man pages, xmlto is needed and to generate info pages, TeX is needed (which we really don't want on a cluster).</p>","boost":10},{"location":"g/git/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support for git in the EasyBuilders repository</p> </li> <li> <p>Support for git in the CSCS repository</p> </li> <li> <p>git-lfs support in the EasyBuilders repository.      The EasyBuilders install from sources, but then Go is needed.</p> </li> <li> <p>git-lfs support in the CSCS repository.     CSCS installs generic downloaded binaries.</p> </li> </ul>","boost":10},{"location":"g/git/#git-2331-for-cpe-2108","title":"git 2.33.1 for cpe 21.08","text":"<ul> <li> <p>Started from the EasyBuilders recipe that doesn't build the documentation,     but checked options from configure, switched to OS dependencies and the     SYSTEM toolchain.</p> </li> <li> <p>Further extended that one to one that can also generate the html documentation     and man pages (but not the texinfo documentation at the moment) by building     additional packages that provide the necessary tools. This is not yet finished     on LUMI though as more packages are missing than on eiger.</p> </li> </ul>","boost":10},{"location":"g/git/#git-2351-for-lumi2112","title":"git 2.35.1 for LUMI/21.12","text":"<ul> <li>Straightforward port of the 2.33.1 EasyConfig file</li> </ul>","boost":10},{"location":"g/git/#git-2370-for-lumi2206","title":"git 2.37.0 for LUMI/22.06","text":"<ul> <li>Straightforward port of the 2.35.1 EasyConfig file</li> </ul>","boost":10},{"location":"g/git/#git-2372-for-lumi2208","title":"git 2.37.2 for LUMI/22.08","text":"<ul> <li>Straightforward port of the 2.37.0 EasyConfig file.</li> </ul>","boost":10},{"location":"g/git/#git-2381-for-lumi22","title":"git 2.38.1 for LUMI/22.??","text":"<ul> <li> <p>Bundled with git-lfs, the latter installed from binairies.</p> </li> <li> <p>git is installed using the same procedure as pre-2.38.1 versions. It is still      without the included documentation, but <code>git help</code> seems to work fine.</p> </li> <li> <p>git-lfs is installed without running the included <code>install.sh</code> script as that      one adds information to <code>$HOME/.gitconfig</code> which does not make sense. Also,     the install script doesn't even copy the man pages to the proper location.     Our procedure implemented in the EasyConfig runs the important commands that the     install script would execute and also copies the man pages to the proper location.     It avoids running <code>git lfs install</code> though and leaves that to the user.</p> <p>It is a more complete procedure then the one implemented in the CSCS EasyConfig files.</p> </li> </ul>","boost":10},{"location":"g/gv/","title":"gv","text":"<p>[package list]</p>","boost":10},{"location":"g/gv/#gv","title":"gv","text":"","boost":10},{"location":"g/gv/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider gv/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>gv/3.7.4-cpeCray-21.08 (EasyConfig: gv-3.7.4-cpeCray-21.08.eb)</p> </li> <li> <p>gv/3.7.4-cpeGNU-21.08 (EasyConfig: gv-3.7.4-cpeGNU-21.08.eb)</p> </li> </ul>","boost":10},{"location":"g/gv/#technical-documentation","title":"Technical documentation","text":"<ul> <li>gv home page</li> </ul> <p>Note that gv is dead code, it has not been updated since 2013. So future problems are to be expected.</p> <p>It needs Ghostscript, and needs libXaw3d which is not part of the standard EasyBuild X11 bundle.</p>","boost":10},{"location":"g/gv/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>There is no support for gv in the EasyBuilders repository</p> </li> <li> <p>There is no support for gv in the CSCS repository</p> </li> </ul>","boost":10},{"location":"g/gv/#version-374-from-cpe-2108-on","title":"Version 3.7.4 from cpe 21.08 on","text":"<ul> <li> <p>Build the EasyConfig file from scratch.</p> </li> <li> <p>Chose to extend the X11 bundle with libXaw3d</p> </li> </ul>","boost":10},{"location":"h/HyperQueue/","title":"HyperQueue","text":"<p>[package list]</p>","boost":10},{"location":"h/HyperQueue/#hyperqueue","title":"HyperQueue","text":"","boost":10},{"location":"h/HyperQueue/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider HyperQueue/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>HyperQueue/0.11.0 (EasyConfig: HyperQueue-0.11.0.eb)</p> </li> <li> <p>HyperQueue/0.16.0-cpeGNU-22.12 (EasyConfig: HyperQueue-0.16.0-cpeGNU-22.12.eb)</p> </li> <li> <p>HyperQueue/0.16.0 (EasyConfig: HyperQueue-0.16.0.eb)</p> </li> </ul>","boost":10},{"location":"h/help2man/","title":"help2man","text":"<p>[package list]</p>","boost":10},{"location":"h/help2man/#help2man","title":"help2man","text":"","boost":10},{"location":"h/help2man/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider help2man/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>help2man/1.48.3-buildtoolsDevel (EasyConfig: help2man-1.48.3-buildtoolsDevel.eb)</li> </ul>","boost":10},{"location":"h/hpcat/","title":"hpcat","text":"<p>[package list]</p>","boost":10},{"location":"h/hpcat/#hpcat","title":"hpcat","text":"","boost":10},{"location":"h/hpcat/#license-information","title":"License information","text":"<p>The HPC Affinity Tracker (<code>hpcat</code>) tool is distributed under the MIT license, a copy of which can be found in the  LICENSE file in the hpcat GitHub repository.</p> <p>After installing and downloading the module, the license is also available in the  <code>$EBROOTHPCAT/share/licenses/hpcat</code> subdirectory.</p>","boost":10},{"location":"h/hpcat/#user-documentation","title":"User documentation","text":"<p>Example <code>hpcat</code>:</p> <pre><code>salloc -N2 -pstandard-g -G 16 -t 10:00\nmodule load LUMI/24.03 partition/G hpcat/0.4-cpeGNU-24.03\nsrun -n16 -c7 bash -c 'ROCR_VISIBLE_DEVICES=$SLURM_LOCALID OMP_NUM_THREADS=7 hpcat'\nsrun -n16 -c7 \\\n    --cpu-bind=mask_cpu:0xfe000000000000,0xfe00000000000000,0xfe0000,0xfe000000,0xfe,0xfe00,0xfe00000000,0xfe0000000000 \\\n    bash -c 'ROCR_VISIBLE_DEVICES=$SLURM_LOCALID OMP_NUM_THREADS=7 hpcat'\nsrun -n16 -c7 \\\n    --cpu-bind=mask_cpu:0xfe000000000000,0xfe00000000000000,0xfe0000,0xfe000000,0xfe,0xfe00,0xfe00000000,0xfe0000000000 \\\n    bash -c 'ROCR_VISIBLE_DEVICES=$SLURM_LOCALID OMP_NUM_THREADS=7 OMP_PLACES=cores hpcat'\n</code></pre> <p>Note that in the first <code>srun</code> command, the mapping of resources is not very good. GPUs  don't map to their closest chiplet, and the network adapters are also linked based  on the CPU NUMA domain. In the second case, the mapping is optimal, but except for the Cray compilers, the OpenMP threads can still move in the chiplet. In the last case, these  are also fixed with all compilers.</p>","boost":10},{"location":"h/hpcat/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider hpcat/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>hpcat/0.3-cpeAMD-24.03 (EasyConfig: hpcat-0.3-cpeAMD-24.03.eb)</p> </li> <li> <p>hpcat/0.3-cpeAOCC-24.03 (EasyConfig: hpcat-0.3-cpeAOCC-24.03.eb)</p> </li> <li> <p>hpcat/0.3-cpeCray-24.03 (EasyConfig: hpcat-0.3-cpeCray-24.03.eb)</p> </li> <li> <p>hpcat/0.3-cpeGNU-24.03 (EasyConfig: hpcat-0.3-cpeGNU-24.03.eb)</p> </li> <li> <p>hpcat/0.4-cpeAMD-24.03 (EasyConfig: hpcat-0.4-cpeAMD-24.03.eb)</p> </li> <li> <p>hpcat/0.4-cpeAOCC-24.03 (EasyConfig: hpcat-0.4-cpeAOCC-24.03.eb)</p> </li> <li> <p>hpcat/0.4-cpeCray-24.03 (EasyConfig: hpcat-0.4-cpeCray-24.03.eb)</p> </li> <li> <p>hpcat/0.4-cpeGNU-24.03 (EasyConfig: hpcat-0.4-cpeGNU-24.03.eb)</p> </li> <li> <p>hpcat/0.8-cpeAMD-24.03 (EasyConfig: hpcat-0.8-cpeAMD-24.03.eb)</p> </li> <li> <p>hpcat/0.8-cpeAOCC-24.03 (EasyConfig: hpcat-0.8-cpeAOCC-24.03.eb)</p> </li> <li> <p>hpcat/0.8-cpeCray-24.03 (EasyConfig: hpcat-0.8-cpeCray-24.03.eb)</p> </li> <li> <p>hpcat/0.8-cpeGNU-24.03 (EasyConfig: hpcat-0.8-cpeGNU-24.03.eb)</p> </li> </ul>","boost":10},{"location":"h/hpcat/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>HPE <code>hpcat</code> on GitHub</p> <ul> <li>GitHub releases via tags.</li> </ul> </li> </ul>","boost":10},{"location":"h/hpcat/#easybuild","title":"EasyBuild","text":"<p>There is no support for <code>hpcat</code> in any repository that we know of. The tool was developed for some sites with HPE Cray EX supercomputers.</p>","boost":10},{"location":"h/hpcat/#version-03","title":"Version 0.3","text":"<p>The EasyConfig is really a bit messy for a couple of reasons:</p> <ul> <li> <p>LUMI lacks the <code>hwloc-devel</code> package so we simply copied the header files from another system     and download them from LUMI-O.</p> </li> <li> <p>The Makefile was modified to integrate better with EasyBuild and to work around a problem with     finding the <code>hwloc</code> library on LUMI. </p> <p>Rather than writing a new Makefile or a patch, we actually used a number of <code>sed</code> commands to edit the Makefile:</p> <ul> <li><code>mpicc</code> was replaced with <code>$(CC)</code> so that the wrappers are used instead.</li> <li><code>-O3</code> was replaced with <code>$(CFLAGS)</code> to pick up the options from EasyBuild</li> <li>'-fopenmp' is managed by the Makefile though and not by EasyBuild. On one hand because the     ultimate goal is to integrate with another packages that sometimes needs and sometimes does not     need the OpenMP flags, on the other hand to use <code>$(CFLAGS)</code> also for <code>hipcc</code>.</li> <li><code>-lhwloc</code> is replaced with <code>-Wl,/usr/lib64/libhwloc.so.15</code>. We had to do this through <code>-Wl</code> as     the <code>hipcc</code> driver thought this was a source file.</li> <li>As '-L.' is not needed, it is omitted.</li> </ul> </li> <li> <p>As there is no <code>make install</code>, we simply use the <code>MakeCp</code> EasyBlock, doing the edits to the Makefile in     <code>prebuiltopts</code>.</p> <p>Not that we copy the <code>libhip.so</code> file to the <code>lib</code> directory as that is the conventional  place to store shared objects, but it is not found there by <code>hpcat</code>, so we also create a symbolic link to it in the <code>bin</code> subidrecitory.</p> </li> <li> <p>Note that the accelerator target module should not be loaded when using the wrappers as the OpenMP offload     options cause a problem in one of the header files used.</p> </li> </ul>","boost":10},{"location":"h/hpcat/#version-04","title":"Version 0.4","text":"<p>This version was released shortly after 0.3 with some changes requested by the Frontier  people. </p> <p>The EasyConfig builds on the one for 0.3:</p> <p>The EasyConfig is really a bit messy for a couple of reasons:</p> <ul> <li> <p>LUMI lacks the <code>hwloc-devel</code> package so we simply copied the header files from another system     and download them from LUMI-O.</p> </li> <li> <p>The Makefile was modified to integrate better with EasyBuild and to work around a problem with     finding the <code>hwloc</code> library on LUMI. </p> <p>Rather than writing a new Makefile or a patch, we actually used a number of <code>sed</code> commands to edit the Makefile:</p> <ul> <li><code>mpicc</code> was replaced with <code>$(CC)</code> so that the wrappers are used instead.</li> <li><code>gcc</code> was replaced with <code>$(CC)</code> so that the wrappers are used instead.</li> <li><code>-O3</code> was replaced with <code>$(CFLAGS)</code> to pick up the options from EasyBuild</li> <li>'-fopenmp' is managed by the Makefile though and not by EasyBuild. On one hand because the     ultimate goal is to integrate with another packages that sometimes needs and sometimes does not     need the OpenMP flags, on the other hand to use <code>$(CFLAGS)</code> also for <code>hipcc</code>.</li> <li><code>-lhwloc</code> is replaced with <code>-Wl,/usr/lib64/libhwloc.so.15</code>. We had to do this through <code>-Wl</code> as     the <code>hipcc</code> driver thought this was a source file.</li> <li>As '-L.' is not needed, it is omitted.</li> </ul> </li> <li> <p>As there is no <code>make install</code>, we simply use the <code>MakeCp</code> EasyBlock, doing the edits to the Makefile in     <code>prebuiltopts</code>.</p> <p>Not that we copy the <code>libhip.so</code> file to the <code>lib</code> directory as that is the conventional  place to store shared objects, but it is not found there by <code>hpcat</code>, so we also create a symbolic link to it in the <code>bin</code> subidrecitory.</p> </li> <li> <p>Note that the accelerator target module should not be loaded when using the wrappers as the OpenMP offload     options cause a problem in one of the header files used.</p> </li> </ul>","boost":10},{"location":"h/hpcat/#version-08","title":"Version 0.8","text":"<p>A lot has changed since version 0.4, so the EasyConfig is practically new.</p> <ul> <li> <p>There is now a <code>configure</code> script that actually calls CMake. So we switched to a <code>ConfigureMake</code>     EasyConfig.</p> </li> <li> <p>The package now uses <code>hwloc</code> and <code>libfort</code> as submodules, but they do not appear      in the standard GitHub download. Hence we derived the versions from the commits, download those     two packages separately and install in the correct directory before configuring      and building <code>hpcat</code></p> </li> <li> <p>A symbolic link in the <code>bin</code> directory to <code>libhpcathip.so</code> is also no longer needed.</p> </li> <li> <p>No more edits are needed.</p> </li> <li> <p>The LICENSE file now needs to be copied in <code>postinstallcmds</code>.</p> </li> </ul>","boost":10},{"location":"h/htop/","title":"htop","text":"<p>[package list]</p>","boost":10},{"location":"h/htop/#htop","title":"htop","text":"","boost":10},{"location":"h/htop/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider htop/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>htop/3.1.1 (EasyConfig: htop-3.1.1.eb)</p> </li> <li> <p>htop/3.3.0 (EasyConfig: htop-3.3.0.eb)</p> </li> </ul>","boost":10},{"location":"h/hwloc/","title":"hwloc","text":"<p>[package list]</p>","boost":10},{"location":"h/hwloc/#hwloc","title":"hwloc","text":"","boost":10},{"location":"h/hwloc/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider hwloc/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>hwloc/2.8.0 (EasyConfig: hwloc-2.8.0.eb)</li> </ul>","boost":10},{"location":"h/hwloc/#technical-documentation","title":"Technical documentation","text":"<p>The LUMI hwloc is not always the most recent one, so from time to time we like to experiment with newer version to see if that could solve some problems with, e.g., likwid.</p> <p>The hwloc tools are a part of the Open MPI project.</p> <ul> <li>hwloc web site</li> </ul>","boost":10},{"location":"h/hwloc/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>hwloc support in the EasyBuilders repository</p> </li> <li> <p>hwloc support in the CSCS repository</p> </li> </ul>","boost":10},{"location":"h/hwloc/#version-280","title":"Version 2.8.0","text":"<ul> <li> <p>The EasyConfig is derived from the EasyBuilders one for GCCcore 12.2.0,      but with some elements of the CSCS one mixed in, e.g., the use of the SYSTEM      toolchain</p> </li> <li> <p>This is currently a restricted version with minimal dependencies and not a full     featured one. The support for the AMD GPUs is missing in this version (as it      complained it could not find some stuff, at least when tried on the login nodes).</p> </li> <li> <p>Added the options <code>--disable-rocm --disable-rsmi</code> to disable ROCm and the ROCm      SMI library as that caused <code>lstopo</code> to fail when tested in the sanity check step.</p> </li> </ul>","boost":10},{"location":"i/Imlib2/","title":"Imlib2","text":"<p>[package list]</p>","boost":10},{"location":"i/Imlib2/#imlib2","title":"Imlib2","text":"","boost":10},{"location":"i/Imlib2/#license-information","title":"License information","text":"<p>Imlib2 does not use any of the standard licenses. It includes a COPYING file basicallyo granting everybody the right to deal with the software without restrictions as long as the copyright notice is included.</p> <p>After installing and loading the module, the files explaining the license can be found in <code>$EBROOTIMLIB2/share/licenses/Imlib2</code>.</p>","boost":10},{"location":"i/Imlib2/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Imlib2/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>Imlib2/1.12.3-cpeGNU-24.03 (EasyConfig: Imlib2-1.12.3-cpeGNU-24.03.eb)</p> </li> <li> <p>Imlib2/1.5.1-cpeGNU-24.03 (EasyConfig: Imlib2-1.5.1-cpeGNU-24.03.eb)</p> </li> </ul>","boost":10},{"location":"i/Imlib2/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>Imlib2 home page     though this page doesn't seem to be maintained anymore.</p> </li> <li> <p>Download from SourceForge</p> </li> </ul>","boost":10},{"location":"i/Imlib2/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support for Imlib2 in the EasyBuilders repository</p> </li> <li> <p>There is no support for Imlib2 in the CSCS repository</p> </li> <li> <p>Imlib2 support in Spack</p> </li> </ul>","boost":10},{"location":"i/Imlib2/#version-151-in-2403","title":"Version 1.5.1 in 24.03","text":"<ul> <li>The EasyConfig is a direct port of the EasyBuilders one,     but we also copy the license files.</li> </ul>","boost":10},{"location":"i/Imlib2/#version-1123-in-2403","title":"Version 1.12.3 in 24.03","text":"<ul> <li>The EasyConfig is a direct port of the EasyBuilders one,     but we also copy the license files.</li> </ul>","boost":10},{"location":"i/Info-ZIP/","title":"Info-ZIP","text":"<p>[package list]</p>","boost":10},{"location":"i/Info-ZIP/#info-zip","title":"Info-ZIP","text":"","boost":10},{"location":"i/Info-ZIP/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Info-ZIP/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>Info-ZIP/3.0-6.0-cpeGNU-22.06 (EasyConfig: Info-ZIP-3.0-6.0-cpeGNU-22.06.eb)</li> </ul>","boost":10},{"location":"i/Info-ZIP/#technical-documentation","title":"Technical documentation","text":"<p>MOVED TO LUMI-EasyBuild-contrib</p> <p>This EasyConfig is a bundle of the Zip and UnZip EasyConfigs to offer a full suit of zip file tools.</p> <p>This is just for in case one for some reason needs the utilities built with the Cray PE compilers rather than the versions of the tools installed in the system image of LUMI. The package only contains binaries and no libraries, so this is likely not needed.</p> <ul> <li> <p>Info-ZIP Zip home page</p> </li> <li> <p>Info-ZIP UnZip home page</p> </li> <li> <p>Info-ZIP on SourceForge</p> </li> </ul>","boost":10},{"location":"i/Info-ZIP/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Zip support in the EasyBuilders repository</p> </li> <li> <p>UnZip support in the EasyBuilders repository</p> </li> <li> <p>There is no support for UnZip or Zip in the CSCS repository</p> </li> <li> <p>Spack zip package</p> </li> <li> <p>Spack unzip package</p> </li> </ul>","boost":10},{"location":"i/Info-ZIP/#zip-version-30-and-unzip-version-60-for-cpegnu-2206-and-later","title":"Zip version 3.0 and unzip version 6.0 for cpeGNU 22.06 and later","text":"<ul> <li> <p>The EasyConfig is a straightforward adaptation and bundling of the EasyBuilders ones for the     <code>GCCcore</code> toolchains.</p> </li> <li> <p>It may need work for Clang-based compilers.</p> </li> </ul>","boost":10},{"location":"j/json-c/","title":"json-c","text":"<p>[package list]</p>","boost":10},{"location":"j/json-c/#json-c","title":"json-c","text":"","boost":10},{"location":"j/json-c/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider json-c/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>json-c/0.16-cpeGNU-23.03 (EasyConfig: json-c-0.16-cpeGNU-23.03.eb)</li> </ul>","boost":10},{"location":"l/LAMMPS/","title":"LAMMPS","text":"<p>[package list]</p>","boost":10},{"location":"l/LAMMPS/#lammps","title":"LAMMPS","text":"","boost":10},{"location":"l/LAMMPS/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider LAMMPS/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>LAMMPS/2Aug2023_update3-cpeAMD-24.03-rocm (EasyConfig: LAMMPS-2Aug2023_update3-cpeAMD-24.03-rocm.eb)</p> </li> <li> <p>LAMMPS/2Aug2023_update3-cpeGNU-24.03-tabgap-46eefe55-CPU (EasyConfig: LAMMPS-2Aug2023_update3-cpeGNU-24.03-tabgap-46eefe55-CPU.eb)</p> </li> </ul>","boost":10},{"location":"l/libexif/","title":"libexif","text":"<p>[package list]</p>","boost":10},{"location":"l/libexif/#libexif","title":"libexif","text":"","boost":10},{"location":"l/libexif/#license-information","title":"License information","text":"<p>Libexif is distributed under the  GNu Lesser General Public License v2.1. A copy of the license can be found in the COPYING file in the libexif GitHub.</p> <p>After installing and loading the module, this file is also available in the  <code>$EBROOTLIBEXIF/share/licenses/libexif</code> directory.</p>","boost":10},{"location":"l/libexif/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider libexif/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>libexif/0.6.25-cpeGNU-24.03 (EasyConfig: libexif-0.6.25-cpeGNU-24.03.eb)</li> </ul>","boost":10},{"location":"l/libexif/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>libexif home page</p> </li> <li> <p>libexif on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"l/libexif/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support for libexif in the EasyBuilders repository</p> </li> <li> <p>There is no support for libexif in the CSCS repository</p> </li> <li> <p>Spack package for libexif</p> </li> </ul>","boost":10},{"location":"l/libexif/#version-0625-for-cpegnu-2403","title":"Version 0.6.25 for cpeGNU 24.03","text":"<ul> <li>EasyConfig derived from the EasyBuilders one, but we also store the license     information in the installation directories.</li> </ul>","boost":10},{"location":"l/libnsl/","title":"libnsl","text":"<p>[package list]</p>","boost":10},{"location":"l/libnsl/#libnsl","title":"libnsl","text":"","boost":10},{"location":"l/libnsl/#license-information","title":"License information","text":"<p>The libnsl package is distributed under the GNU Lesser General Public License Version 2.1 which can also be found in the COPYING file in the libnsl GitHub repository.</p> <p>After installating and loading the module, this file can also be found in <code>$EBROOTLIBNSL/share/licenses/libnls</code>.</p>","boost":10},{"location":"l/libnsl/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider libnsl/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>libnsl/2.0.1-cpeCray-25.03 (EasyConfig: libnsl-2.0.1-cpeCray-25.03.eb)</p> </li> <li> <p>libnsl/2.0.1-cpeGNU-25.03 (EasyConfig: libnsl-2.0.1-cpeGNU-25.03.eb)</p> </li> </ul>","boost":10},{"location":"l/libnsl/#technical-documentation","title":"Technical documentation","text":"<p>The libnsl package contains the public client interface for NIS(YP).</p> <p>It turns out to be a dependency for libdap, even though that was not noted by the EasyBuilders at the time we have added this package.</p> <ul> <li> <p>libnsl on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"l/libnsl/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support for libnsl in the EasyBuilders repository</p> </li> <li> <p>There is no support for libnsl in the CSCS repository.</p> </li> <li> <p>Spack package libnsl</p> </li> </ul>","boost":10},{"location":"l/libnsl/#version-201-for-cpe-2503","title":"Version 2.0.1 for CPE 25.03","text":"<ul> <li>The EasyConfig is derived from the EasyBuilders one for GCCcore 13.3.0,     but adapted to the LUST way of working and also with more extensive     sanity checks.</li> </ul>","boost":10},{"location":"l/libreadline/","title":"libreadline","text":"<p>[package list]</p>","boost":10},{"location":"l/libreadline/#libreadline","title":"libreadline","text":"","boost":10},{"location":"l/libreadline/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider libreadline/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>libreadline/7.0-static (EasyConfig: libreadline-7.0-static.eb)</p> </li> <li> <p>libreadline/7.0 (EasyConfig: libreadline-7.0.eb)</p> </li> <li> <p>libreadline/8.1-static (EasyConfig: libreadline-8.1-static.eb)</p> </li> </ul>","boost":10},{"location":"l/libtirpc/","title":"libtirpc","text":"<p>[package list]</p>","boost":10},{"location":"l/libtirpc/#libtirpc","title":"libtirpc","text":"","boost":10},{"location":"l/libtirpc/#license-information","title":"License information","text":"<p>The libtirpc copyright information can be found in the COPYING file in the source repository.</p> <p>From LUMI/23.12 on, a copy of the COPYING file can also be found in the <code>$EBROOTLIBTIRPC/share/licenses/libtirpc</code> directory after loading the module.</p>","boost":10},{"location":"l/libtirpc/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider libtirpc/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>libtirpc/1.3.6-cpeAMD-25.03-devel (EasyConfig: libtirpc-1.3.6-cpeAMD-25.03-devel.eb)</p> </li> <li> <p>libtirpc/1.3.6-cpeAOCC-25.03-devel (EasyConfig: libtirpc-1.3.6-cpeAOCC-25.03-devel.eb)</p> </li> <li> <p>libtirpc/1.3.6-cpeCray-25.03-devel (EasyConfig: libtirpc-1.3.6-cpeCray-25.03-devel.eb)</p> </li> <li> <p>libtirpc/1.3.6-cpeCray-25.03-gcc (EasyConfig: libtirpc-1.3.6-cpeCray-25.03-gcc.eb)</p> <p>This one uses a trick to compile with gcc-native instead of with the Cray compilers.</p> </li> <li> <p>libtirpc/1.3.6-cpeGNU-25.03-devel (EasyConfig: libtirpc-1.3.6-cpeGNU-25.03-devel.eb)</p> </li> </ul>","boost":10},{"location":"l/libtirpc/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>libtirpc on SourceForge</p> </li> <li> <p>Development on linux-nfs.org</p> </li> </ul>","boost":10},{"location":"l/libtirpc/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>libtirpc support in the EasyBuilders repository</p> </li> <li> <p>There is no support for libtirpc in the CSCS repository</p> </li> </ul>","boost":10},{"location":"l/libtirpc/#version-132-for-cpe-2108","title":"Version 1.3.2 for CPE 21.08","text":"<ul> <li>The EasyConfig is a straightforward adaptation of the EasyBuilders one.</li> </ul>","boost":10},{"location":"l/libtirpc/#version-133-from-cpe-2212-on","title":"Version 1.3.3 from CPE 22.12 on","text":"<ul> <li> <p>The EasyConfig is a straightforward port of the 1.3.2. one.</p> </li> <li> <p>For LUMI/23.12, license information was added to the installation and the     sanity checks were improved.</p> <p>For clang-based compilers we used <code>--disable-symvers</code> as using that causes a failure with CCE when linking.</p> </li> </ul>","boost":10},{"location":"l/libtirpc/#version-134-from-lumi2403-on","title":"Version 1.3.4 from LUMI/24.03 on","text":"<ul> <li>Trivial port of the EasyConfig for version 1.3.3 in LUMI/23.12.</li> </ul>","boost":10},{"location":"l/libtirpc/#version-136-from-2503-on","title":"Version 1.3.6 from 25.03 on","text":"<ul> <li> <p>Started as a trivial port of the EasyConfig for version 1.3.4 on 24.03/24.11.</p> </li> <li> <p>However, we found out that the clang based compiles break <code>hostname</code> and likely     other commands on LUMI as the library lacks the versioned symbol information     that is present in the system libraries.</p> <p>The solution is to configure with <code>--enable-symvers</code> which in turn required to expliclty use <code>--disable-gssapi</code>. GSS-API is not found in the cpeGNU build either, but in combination with <code>--enable-symvers</code>, <code>configure</code> explicitly complains.</p> <p>This then in turn causes issues when linking as the symbol file <code>src/libtirpc.map</code> also contains routines that are only built with GSS-API enabled. So we also need  to massage the linker flags.</p> <p>For cpeCray, this worked:</p> <pre><code>preconfigopts += 'LDFLAGS=\"$LDFLAGS -Wl,--noinhibit-exec\"'\n</code></pre> </li> <li> <p>We then also added an additional sanity check to ensure that <code>hostname</code> does not produce     the warnings about missing version information.</p> </li> </ul>","boost":10},{"location":"l/libtree/","title":"libtree","text":"<p>[package list]</p>","boost":10},{"location":"l/libtree/#libtree","title":"libtree","text":"","boost":10},{"location":"l/libtree/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider libtree/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>libtree/3.1.1 (EasyConfig: libtree-3.1.1.eb)</li> </ul>","boost":10},{"location":"l/libtree/#technical-documentation","title":"Technical documentation","text":"<p><code>libtree</code> is an <code>ldd</code>-like tool, but it displays the libraries as a tree to better  show how shared libraries are found.</p> <ul> <li> <p>libtree on GitHub</p> <ul> <li>libtree releases</li> </ul> </li> </ul>","boost":10},{"location":"l/libtree/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support for libtree in the EasyBuilders repository</p> </li> <li> <p>Support for libtree in the CSCS repository</p> </li> </ul>","boost":10},{"location":"l/libtree/#version-311-for-the-system-toolchain","title":"Version 3.1.1 for the SYSTEM toolchain","text":"<ul> <li> <p>The EasyConfig is an adaptation of the EasyBuilders one with additional documentation.</p> </li> <li> <p>This EasyConfig is basically meant to prepare for inclusion in the <code>systools</code> package.</p> </li> </ul>","boost":10},{"location":"l/libxc/","title":"libxc","text":"<p>[package list]</p>","boost":10},{"location":"l/libxc/#libxc","title":"libxc","text":"","boost":10},{"location":"l/libxc/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider libxc/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>libxc/7.0.0-cpeGNU-24.03 (EasyConfig: libxc-7.0.0-cpeGNU-24.03.eb)</li> </ul>","boost":10},{"location":"l/libxc/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>Libxc website</p> <ul> <li>Libxc downloads from the web site</li> </ul> </li> <li> <p>Libxc on GitLab</p> <ul> <li>GitLab releases</li> </ul> </li> </ul>","boost":10},{"location":"l/libxc/#general-information","title":"General information","text":"<p>Libxc is a library of exchange-correlation and kinetic energy functionals for  density-functional theory. The original aim was to provide a portable, well  tested and reliable set of LDA, GGA, and meta-GGA  functionals.</p> <ul> <li> <p>Libxc documentation</p> </li> <li> <p>Available functionals</p> </li> </ul>","boost":10},{"location":"l/libxc/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>libxc in the EasyBuilders repository</p> </li> <li> <p>libxc in the CSCS repository</p> </li> <li> <p>libxc in Spack</p> </li> </ul>","boost":10},{"location":"l/libxc/#version-522-for-cpegnu-2208","title":"Version 5.2.2 for cpeGNU 22.08","text":"<ul> <li>Derived from the EasyConfigs used at CSCS.</li> </ul>","boost":10},{"location":"l/libxc/#version-610-for-cpegnu-2208-and-2212","title":"Version 6.1.0 for cpeGNU 22.08 and 22.12","text":"<ul> <li>Derived from the 5.2.2 one, but currently only generating shared libraries.</li> </ul>","boost":10},{"location":"l/libxc/#version-622-for-cpegnu-2212-and-2309","title":"Version 6.2.2 for cpeGNU 22.12 and 23.09","text":"<ul> <li>Derived from the 6.1.0 EasyConfig.</li> </ul>","boost":10},{"location":"l/libxc/#version-700-for-cpegnu-2403","title":"Version 7.0.0 for cpeGNU 24.03","text":"<ul> <li>Derived from the 6.2.2 EasyConfig.</li> </ul>","boost":10},{"location":"l/likwid/","title":"likwid","text":"<p>[package list]</p>","boost":10},{"location":"l/likwid/#likwid","title":"likwid","text":"","boost":10},{"location":"l/likwid/#user-documentation","title":"User documentation","text":"<p>System support</p> <p>LIKWID 5.2.2 does not yet fully support the zen3 architecture and does not support AMD GPUs. Hence the tool may not fully function on LUMI.</p> <p>We do not problems with <code>likwid-topology</code> even on zen2, as the dies are not correctly reported. Hence it is to be expected that <code>likwid-pin</code> may not always function as expected either, at least when specifying at the level of dies (which is not that useful anyway as on the compute nodes the dies corresponds with the outer cache domains anyway).</p> <p>Moreover, the performance measuring tool requires access to the performance counters. This access is not permanent on LUMI and is turned off whenever a security issue in the Linux kernel that can be exploited through the performance counter access appears.</p> <p>The documentation of  LIKWID is available in the likwid wiki on the [likwid GitHub[(https://github.com/RRZE-HPC/likwid). The tool is frequently  used in courses on node level performance engineering lectured by Georg Hager and Gerhard Wellein of the  Erlangen National High Performace Computing Center NHR@FAU, also in European programs.</p> <p>There are also some training movies on the NHR@FAU YouTube channel, including:</p> <ul> <li>A short overview of the LIKWID tool suite</li> <li>How to use likwid-topoplogy</li> <li>How to use likwid-pin</li> <li>How to use likwid-pin (extended version)</li> <li>And other videos in the LIKWID PlayList</li> </ul>","boost":10},{"location":"l/likwid/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider likwid/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>likwid/5.2.2-eb (EasyConfig: likwid-5.2.2-eb.eb)</p> </li> <li> <p>likwid/5.2.2-hwloc (EasyConfig: likwid-5.2.2-hwloc.eb)</p> </li> <li> <p>likwid/5.2.2 (EasyConfig: likwid-5.2.2.eb)</p> </li> </ul>","boost":10},{"location":"l/likwid/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>likwid GitHub repository</p> <ul> <li> <p>GitHub releases</p> </li> <li> <p>Some documentation in the GitHub Wiki</p> </li> </ul> </li> </ul>","boost":10},{"location":"l/likwid/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>likwid support in the EasyBuilders repository.     This EasyConfig does most work by redefining variables from <code>config.mk</code> on the <code>make</code> command line.</p> </li> <li> <p>likwid support in the CSCS repository.     This EasyConfig works by editing <code>config.mk</code>.</p> </li> </ul>","boost":10},{"location":"l/likwid/#version-522-wqith-system","title":"Version 5.2.2 wqith SYSTEM","text":"<ul> <li> <p>This version does not yet fully support zen3, so problems are to be     expected.</p> </li> <li> <p>Started from the CSCS EasyConfig which edits the <code>config.mk</code> file rather     then redefining variables on the <code>make</code> command line as the EasyBuilders     one does.</p> </li> <li> <p>Trying to use the system hwloc to minimize interference.</p> </li> <li> <p>Using the system LUA interpreter turned out to be impossible as the header     files are missing on LUMI.</p> </li> <li> <p>TODO</p> <ul> <li>likwid-bench crashes with floating point exceptions.</li> </ul> </li> </ul>","boost":10},{"location":"l/lumi-CPEtools/","title":"lumi-CPEtools","text":"<p>[package list]</p>","boost":10},{"location":"l/lumi-CPEtools/#lumi-cpetools","title":"lumi-CPEtools","text":"","boost":10},{"location":"l/lumi-CPEtools/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider lumi-CPEtools/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>lumi-CPEtools/1.1a-cpeAMD-22.12 (EasyConfig: lumi-CPEtools-1.1a-cpeAMD-22.12.eb)</p> </li> <li> <p>lumi-CPEtools/1.1a-cpeAOCC-22.12 (EasyConfig: lumi-CPEtools-1.1a-cpeAOCC-22.12.eb)</p> </li> <li> <p>lumi-CPEtools/1.1a-cpeCray-22.12 (EasyConfig: lumi-CPEtools-1.1a-cpeCray-22.12.eb)</p> </li> <li> <p>lumi-CPEtools/1.1a-cpeCray-23.03 (EasyConfig: lumi-CPEtools-1.1a-cpeCray-23.03.eb)</p> </li> <li> <p>lumi-CPEtools/1.1a-cpeGNU-22.12 (EasyConfig: lumi-CPEtools-1.1a-cpeGNU-22.12.eb)</p> </li> </ul>","boost":10},{"location":"l/lumi-GPUtools/","title":"lumi-GPUtools","text":"<p>[package list]</p>","boost":10},{"location":"l/lumi-GPUtools/#lumi-gputools","title":"lumi-GPUtools","text":"","boost":10},{"location":"l/lumi-GPUtools/#license-information","title":"License information","text":"<p>The lumi-GPUtools package is released under the  GNU General Public License version 3.0 a copy of which can also be found in the LICENSE file in the GitHub repository.</p>","boost":10},{"location":"l/lumi-GPUtools/#user-documentation","title":"User documentation","text":"<p>The lumi-GPUtools module provides tools to make life on the compute GPU partition of LUMI a bit easier. It will grow over time.</p> <p>Current tools:</p> <ul> <li><code>select_gpu: This command replaces the</code>select_gpu` script that is generated in     the example job script in the      section on MPI-based jobs     in the Run jobs - GPU examples section     of the LIUMI documentation.</li> </ul> <p>Up-to-date information for the specific version of the module is available after  installation of the module via the <code>module help lumi-GPUtools</code> command and after loading of the module also via man pages. Use</p> <pre><code>man lumi-GPUtools\n</code></pre> <p>as a starting point.</p>","boost":10},{"location":"l/lumi-GPUtools/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider lumi-GPUtools/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>lumi-GPUtools/0.1.0-alpha (EasyConfig: lumi-GPUtools-0.1.0-alpha.eb)</li> </ul>","boost":10},{"location":"l/lumi-GPUtools/#technical-documentation","title":"Technical documentation","text":"<p>This package is a development of the LUMI User Support Team.</p> <ul> <li> <p>lumi-GPUtools development on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"l/lumi-GPUtools/#easybuild","title":"EasyBuild","text":"<p>As this is a development of LUST, there is no support in other repositories.</p>","boost":10},{"location":"l/lumi-GPUtools/#version-010-alpha","title":"Version 0.1.0-alpha","text":"<ul> <li> <p>The EasyConfig is our own development. It was developed in conjunction with the     package itself, whose Makefile was already designed to work wel with EasyBuild.</p> </li> <li> <p>We are using the SYSTEM toolchain so that the tools are completely independent     of any version of the Cray PE and can be easyly used in the CrayEnv and LUMI     environments.</p> </li> </ul>","boost":10},{"location":"l/lumi-allocations/","title":"lumi-allocations","text":"<p>[package list]</p>","boost":10},{"location":"l/lumi-allocations/#lumi-allocations","title":"lumi-allocations","text":"","boost":10},{"location":"l/lumi-allocations/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider lumi-allocations/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>lumi-allocations/20230103-minimal (EasyConfig: lumi-allocations-20230103-minimal.eb)</p> </li> <li> <p>lumi-allocations/20230103 (EasyConfig: lumi-allocations-20230103.eb)</p> </li> <li> <p>lumi-allocations/20230210 (EasyConfig: lumi-allocations-20230210.eb)</p> </li> <li> <p>lumi-allocations/691e4ee (EasyConfig: lumi-allocations-691e4ee.eb)</p> </li> </ul>","boost":10},{"location":"l/lumi-allocations/#technical-documentation","title":"Technical documentation","text":"<p>The lumi-allocations command is an in-house development of LUST.</p> <ul> <li>lumi-allocations GitHub repository</li> </ul>","boost":10},{"location":"l/lumi-allocations/#easybuild","title":"Easy/build","text":"","boost":10},{"location":"l/lumi-allocations/#version-20230103","title":"Version 20230103","text":"<ul> <li>This is simply a first try based on a beta commit and also used     to start the development of the lumi-tools module that will     ultimately replace lumi-allocations.</li> </ul>","boost":10},{"location":"l/lumi-tools/","title":"lumi-tools","text":"<p>[package list]</p>","boost":10},{"location":"l/lumi-tools/#lumi-tools","title":"lumi-tools","text":"","boost":10},{"location":"l/lumi-tools/#license-information","title":"License information","text":"<ul> <li>The lumi-allocations` tool is licensed under the     European Union Public License 1.2 .      The license text is      available in the LICENSE file in the lumi-allocations GitHub</li> <li>The <code>lumi-quota</code> and <code>lumi-workspaces</code> commands are provided through the LUMI-SoftwareStack     repository and hence are covered by the      GNU General Public License version 3.0      a copy of which can be found in the     LICENSE file in the LUMI-SoftwareStack GitHub repository.</li> </ul> <p>When the <code>lumi-tools</code> module is loaded, a copy of the license for <code>lumi-allocations</code> can also be found in the file  <code>$EBROOTLUMIMINTOOLS/share/licenses/lumi-allocations/LICENSE</code>.</p>","boost":10},{"location":"l/lumi-tools/#user-documentation","title":"User documentation","text":"","boost":10},{"location":"l/lumi-tools/#lumi-workspaces","title":"lumi-workspaces","text":"<p>The <code>lumi-workspaces</code> command combines the <code>lumi-quota</code> and <code>lumi-allocations</code> commands shown below, but is currently only capable to show the output for all your workspaces/projects (user workspace on <code>/user</code>and the various project-related workspaces on <code>/project</code>, <code>/scratch</code> and <code>/flash</code>).</p> <p>Note that currently no output is displayed about storage use on the object file  system as that one is still under development.</p>","boost":10},{"location":"l/lumi-tools/#lumi-quota","title":"lumi-quota","text":"<p>The <code>lumi-workspaces</code> command can be used to check your file quota on the  system.</p> <p>The command comes in three different forms:   * <code>lumi-quota</code>         : Shows quota for all your workspaces (user and project)   * <code>lumi-quota -v</code>      : Detailed quota information   * <code>lumi-quota -p prj</code>  : Show quota of project prj</p> <p>This tool only produces output about the Lustre file systems, so directories in <code>/user</code>, <code>/project</code> (or the old name <code>/projappl</code>), <code>/scratch</code> and <code>/flash</code>.</p>","boost":10},{"location":"l/lumi-tools/#lumi-allocations","title":"lumi-allocations","text":"<p>The <code>lumi-allocations</code> command can be used to check the status of your allocations on LUMI.</p> <ul> <li>To check all your remaining allocations, simply run     <code>lumi-allocations</code>. (Does not yet work)</li> <li>To check your allocation in your project_465000000 (replace with your project      number): <code>lumi-allocations -p project_465000000</code></li> <li>Use <code>lumi-allocations --help</code>     for more informations.</li> </ul>","boost":10},{"location":"l/lumi-tools/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider lumi-tools/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>lumi-tools/0.1 (EasyConfig: lumi-tools-0.1.eb)</li> </ul>","boost":10},{"location":"l/lumi-tools/#technical-documentation","title":"Technical documentation","text":"<p>The lumi-tools module provides two in-house developed scripts:</p> <ul> <li>lumi-workspaces to check your quota</li> <li>lumi-allocations to check your allocations</li> </ul> <p>Sources:</p> <ul> <li>lumi-allocations GitHub repository</li> </ul>","boost":10},{"location":"l/lumi-tools/#easybuild","title":"Easy/build","text":"","boost":10},{"location":"l/lumi-tools/#version-01","title":"Version 0.1","text":"<ul> <li> <p>In-house developed EasyConfig, type <code>Bundle</code></p> <ul> <li> <p><code>lumi-quota</code> and <code>lumi-workspaces</code> are currently contained in the EasyConfig itself and      copied to a file in the <code>postinstallcommands</code> of the EasyConfig.</p> </li> <li> <p><code>lumi-allocations</code> is installed from its GitHub repository using     the <code>Tarball</code> generic EasyBlock, as a component of the Bundle.</p> </li> </ul> </li> </ul>","boost":10},{"location":"l/lumi-training-tools/","title":"lumi-training-tools","text":"<p>[package list]</p>","boost":10},{"location":"l/lumi-training-tools/#lumi-training-tools","title":"lumi-training-tools","text":"","boost":10},{"location":"l/lumi-training-tools/#license-information","title":"License information","text":"<p>The <code>mkfile</code> tool is licensed under the GNU General Public License v3.</p>","boost":10},{"location":"l/lumi-training-tools/#user-documentation","title":"User documentation","text":"<p>The lumi-training-tools is a module-under-development that provides tools used during the trainings, mostly for exercises, but that don't make sense to include in modules that are useful outside trainings also such as lumi-CPEtools.</p> <p>Content of the newest versions:</p> <ul> <li>mkfile: A simple tool to generate a file of given size.</li> </ul>","boost":10},{"location":"l/lumi-training-tools/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider lumi-training-tools/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>lumi-training-tools/20240502 (EasyConfig: lumi-training-tools-20240502.eb)</p> <p>Tools used in the training notes and exercises of the 2-day training given by LUST in Amsterdam on May 2-3, 2024. Only includes mkfile, compiled with the system compiler and usable without CPE.</p> </li> </ul>","boost":10},{"location":"l/lumi-training-tools/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>mkfile tool:   </p> <ul> <li> <p>It was originally a tool included with Solaris and can still be found in some     BSD distributions.</p> </li> <li> <p>A simple version with one option less is available on the     GitHub repository vogelchr/mkfile.     Its command line options are different though so we avoid using it for now.</p> </li> </ul> </li> </ul>","boost":10},{"location":"l/lumi-training-tools/#easyconfigs","title":"EasyConfigs","text":"","boost":10},{"location":"l/lumi-training-tools/#version-01","title":"Version 0.1","text":"<ul> <li> <p>Only includes the mkfile tool, but already uses a bundle for future     extensions.</p> </li> <li> <p><code>mkfile</code> comes with a Makefile that can take care of compilation and     installation if the right additional variables are specified when calling     the Makefile, but there is no configure step needed.</p> </li> </ul>","boost":10},{"location":"l/lz4/","title":"lz4","text":"<p>[package list]</p>","boost":10},{"location":"l/lz4/#lz4","title":"lz4","text":"","boost":10},{"location":"l/lz4/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider lz4/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>lz4/1.9.3-static (EasyConfig: lz4-1.9.3-static.eb)</li> </ul>","boost":10},{"location":"l/lz4/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>lz4 home page</p> </li> <li> <p>lz4 on GitHub</p> <ul> <li>lz4 GitHug releases</li> </ul> </li> </ul>","boost":10},{"location":"l/lz4/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>lz4 in the EasyBuilders repository</p> </li> <li> <p>lz4 in the CSCS repository</p> </li> </ul>","boost":10},{"location":"l/lz4/#version-193-static-for-system","title":"Version 1.9.3-static for SYSTEM","text":"<ul> <li> <p>The EasyConfig file is a direct derivative from the one from the EasyBuilders repository.</p> </li> <li> <p>The version with the SYSTEM toolchain is to prepare for inclusion in the syslibs     module, a module of libraries used to build various small tools that we want to build     against the SYSTEM toolchain with minimal runtime dependencies except for libraries     included with the OS.</p> </li> </ul>","boost":10},{"location":"l/lzip-bootstrap/","title":"lzip-bootstrap","text":"<p>[package list]</p>","boost":10},{"location":"l/lzip-bootstrap/#lzip-bootstrap","title":"lzip-bootstrap","text":"","boost":10},{"location":"l/lzip-bootstrap/#user-documentation","title":"User documentation","text":"<p>This EasyConfig is only meant to be used for bootstrapping the installation of lzip-tools. See that page for all information.</p>","boost":10},{"location":"l/lzip-bootstrap/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider lzip-bootstrap/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>lzip-bootstrap/1.25 (EasyConfig: lzip-bootstrap-1.25.eb)</li> </ul>","boost":10},{"location":"l/lzip-tools/","title":"lzip-tools","text":"<p>[package list]</p>","boost":10},{"location":"l/lzip-tools/#lzip-tools","title":"lzip-tools","text":"","boost":10},{"location":"l/lzip-tools/#license-information","title":"License information","text":"<p>The lzip. lziprecover, plzip and tarlz commands are covered by the GNU General Public License version 2 while Zutils is covered by the  GNU General Public License version 3.</p> <p>After installing and loading the module, the license information is also available  for each tool in the respective subdirectory of <code>$EBROOTLZIPMINTOOLS/share/licenses</code>.</p>","boost":10},{"location":"l/lzip-tools/#user-documentation","title":"User documentation","text":"","boost":10},{"location":"l/lzip-tools/#a-note-on-the-installation","title":"A note on the installation","text":"<p>As some of the tools are only available in lzip-compressed format, a special bootstrap process is needed to install these tools. They are currently meant to be used in any <code>LUMI/24.03</code> stack.</p> <pre><code>module load LUMI/24.03 partition/common EasyBuild-user\neb lzip-bootstrap-1.25.eb\nmodule load lzip-bootstrap/1.25\neb lzip-tools-24.03.eb\n</code></pre> <p>The last step will generate a warning that can be ignored.</p> <p>Note: We are looking for a better solution to install these tools, but that will  only happen when a new software stack is started as breaking changes would be needed  to the current stacks.</p>","boost":10},{"location":"l/lzip-tools/#content-of-the-package","title":"Content of the package","text":"<ul> <li> <p><code>lzip</code>: Lzip is a lossless data compressor with a user interface      similar to the one of gzip or bzip2. Lzip uses a simplified form of LZMA      (Lempel-Ziv-Markov chain-Algorithm) designed to achieve complete      interoperability between implementations. Decompression speed is      intermediate between gzip and bzip2.</p> </li> <li> <p><code>lunzip</code>: Lunzip is a decompressor for the lzip format written in C. Its small      size makes it well suited for embedded devices or software installers that      need to decompress files but don't need compression capabilities.</p> <p>Note that you can also decompress with \"lzip -d\" which is different code.</p> </li> <li> <p><code>plzip</code>: Plzip is a massively parallel (multi-threaded) implementation      of lzip.</p> </li> <li> <p><code>lziprecover</code>: Lziprecover is a data recovery tool and decompressor for      files in the lzip compressed data format (.lz). Lziprecover also provides      Forward Error Correction (FEC) able to repair any kind of file.</p> <p>Lziprecover can remove the damaged members from multimember files, for  example multimember tar.lz archives.</p> <p>Lziprecover provides random access to the data in multimember files; it  only decompresses the members containing the desired data.</p> <p>Lziprecover is not a replacement for regular backups, but a last line of  defense for the case where the backups are also damaged.</p> </li> <li> <p><code>tarlz</code>: Tarlz is a massively parallel (multi-threaded) combined implementation     of the tar archiver and the lzip compressor.</p> <p>Keeping the alignment between tar members and lzip members has two  advantages. It adds an indexed lzip layer on top of the tar archive,  making it possible to decode the archive safely in parallel. It also  reduces the amount of data lost in case of corruption. Compressing a  tar archive with plzip may even double the amount of files lost for  each lzip member damaged because it does not keep the members aligned.</p> </li> <li> <p>Zutils is a collection of utilities able to process any combination      of compressed and uncompressed files transparently. If any file given,      including standard input, is compressed, its decompressed content is used.      Compressed files are decompressed on the fly; no temporary files are created.      Data format is detected by its identifier string (magic bytes), not by the      file name extension. Empty files are considered uncompressed.</p> <p>It provides more powerfull versions of the <code>zcat</code>, <code>zcmp</code>, <code>zdiff</code>, <code>zgrep</code>,  <code>zegrep</code> and <code>zfgrep</code> from gzip and additional <code>ztest</code>and <code>zupdate</code> commands </p> </li> </ul>","boost":10},{"location":"l/lzip-tools/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider lzip-tools/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>lzip-tools/24.03 (EasyConfig: lzip-tools-24.03.eb)</p> <p>Lzip and various related tools, to be installed in <code>LUMI/24.03 partition/common</code>.</p> <p>First install <code>lzip-bootstrap-1.25.eb</code>: <code>eb lzip-bootstrap-1.25.eb</code>, then load that module: <code>module load lzip-bootstrap/1.25</code>, and then install this EasyConfig: <code>eb lzip-tools-24.03.eb</code>. </p> </li> </ul>","boost":10},{"location":"l/lzip-tools/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>lzip:</p> <ul> <li> <p>Home page</p> </li> <li> <p>Downloads</p> </li> </ul> </li> <li> <p>lunzip:</p> <ul> <li> <p>Home page</p> </li> <li> <p>Downloads</p> </li> </ul> </li> <li> <p>lziprecover:</p> <ul> <li> <p>Home page</p> </li> <li> <p>Downloads</p> </li> </ul> </li> <li> <p>plzip:</p> <ul> <li> <p>Home page</p> </li> <li> <p>Downloads</p> </li> </ul> </li> <li> <p>tarlz:</p> <ul> <li> <p>Home page</p> </li> <li> <p>Downloads</p> </li> </ul> </li> <li> <p>Zutils:</p> <ul> <li> <p>Home page</p> </li> <li> <p>Downloads</p> </li> </ul> </li> <li> <p>lzlib: Library needed to build some of these tools:</p> <ul> <li> <p>Home page</p> </li> <li> <p>Downloads </p> </li> </ul> </li> </ul>","boost":10},{"location":"l/lzip-tools/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>At the time of development, there was no support for lzip in EasyBuild</p> </li> <li> <p>There is no support in Spack for lzip.</p> </li> </ul>","boost":10},{"location":"l/lzip-tools/#lzip-tools-for-lumi2403","title":"lzip-tools for LUMI/24.03","text":"<ul> <li> <p>The EasyConfig is a LUST development. All packages have a very simple      configure-make build process so developing a Bundle was easy.</p> </li> <li> <p>Two components are only distributed in lzip format. Hence we needed a special     bootstrapping process:</p> <pre><code>module load LUMI/24.03 partition/common EasyBuild-user\neb lzip-bootstrap-1.25.eb\nmodule load lzip-bootstrap/1.25\neb lzip-tools-24.03.eb\n</code></pre> <p>This is only a temporary solution. We will investigate if we can build support for lzip into the EasyBuild module or another module that is centrally installed and whose presence is ignored by EasyBuild.</p> <p>Note that EasyBuild does not know the <code>.tar.lz</code> format and hence we needed to use <code>extract_cmd</code>.</p> </li> </ul>","boost":10},{"location":"m/M4/","title":"M4","text":"<p>[package list]</p>","boost":10},{"location":"m/M4/#m4","title":"M4","text":"","boost":10},{"location":"m/M4/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider M4/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>M4/1.4.19-buildtoolsDevel (EasyConfig: M4-1.4.19-buildtoolsDevel.eb)</li> </ul>","boost":10},{"location":"m/makedepf90/","title":"makedepf90","text":"<p>[package list]</p>","boost":10},{"location":"m/makedepf90/#makedepf90","title":"makedepf90","text":"","boost":10},{"location":"m/makedepf90/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider makedepf90/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>makedepf90/2.8.8 (EasyConfig: makedepf90-2.8.8.eb)</p> </li> <li> <p>makedepf90/2.8.9 (EasyConfig: makedepf90-2.8.9.eb)</p> </li> </ul>","boost":10},{"location":"m/makedepf90/#technical-documentation","title":"Technical documentation","text":"<p>The makedepf90 tool was developed long ago by Erik Edelmann from CSC but is no longer maintained, and the original repository is no longer available. Yet it is  still included in several Linux distributions as an optional packages. Sources for the last official version, 2.8.8, can also still be found as tar files on archives.</p> <ul> <li>Unofficial GitHub with makedepf90 sources.     This is an unofficial copy of the sources, with the claim also that some improvements     have been made to the installation procedure.</li> </ul> <p>This software is no longer maintained so is offered without any warranty that it works properly or can continue to work on LUMI in the future. It is fully offered \"as-is\", without support from the LUMI User Support Team, unless someone would pick up development again.</p>","boost":10},{"location":"m/makedepf90/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support in the EasyBuilders repository</p> </li> <li> <p>There is no support in the CSCS repository</p> </li> </ul> <p>It is best to compile this program in <code>partition/common</code> so that it is available to all partitions in a given LUMI stack.</p>","boost":10},{"location":"m/makedepf90/#version-288-for-the-system-toolchain","title":"Version 2.8.8 for the SYSTEM toolchain","text":"<ul> <li> <p>This is an adaptation of an old EasyBuilders recipe to compile with the     SYSTEM toolchain as it makes no sense at all to compile with the Cray     Programming Environment for such a little tool that is only used during     the build process.</p> </li> <li> <p>We did make a modification to put the man page in <code>share/man/man</code> rather     than into <code>man/man1</code>.</p> </li> </ul>","boost":10},{"location":"m/makedepf90/#version-289-for-the-system-toolchain","title":"Version 2.8.9 for the SYSTEM toolchain","text":"<ul> <li> <p>This is a build based on the new GitHub repository.</p> </li> <li> <p>Even though it claims improvements in the build process, it actually contains     new bugs. E.g., it adds a dot in front of the paths in <code>make install</code> which we     had to work around by setting <code>DESTDIR</code>.</p> </li> <li> <p>An improvement though is that it installs the man page where it should.</p> </li> </ul>","boost":10},{"location":"n/NCO/","title":"NCO","text":"<p>[package list]</p>","boost":10},{"location":"n/NCO/#nco","title":"NCO","text":"","boost":10},{"location":"n/NCO/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider NCO/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>NCO/5.1.5-cpeGNU-23.03 (EasyConfig: NCO-5.1.5-cpeGNU-23.03.eb)</li> </ul>","boost":10},{"location":"n/Nek5000/","title":"Nek5000","text":"<p>[package list]</p>","boost":10},{"location":"n/Nek5000/#nek5000","title":"Nek5000","text":"","boost":10},{"location":"n/Nek5000/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Nek5000/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>Nek5000/19.0-cpeGNU-22.12 (EasyConfig: Nek5000-19.0-cpeGNU-22.12.eb)</li> </ul>","boost":10},{"location":"n/nano/","title":"nano","text":"<p>[package list]</p>","boost":10},{"location":"n/nano/#nano","title":"nano","text":"","boost":10},{"location":"n/nano/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider nano/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>nano/5.9-cpeAMD-21.08 (EasyConfig: nano-5.9-cpeAMD-21.08.eb)</p> </li> <li> <p>nano/5.9-cpeCray-21.08 (EasyConfig: nano-5.9-cpeCray-21.08.eb)</p> </li> <li> <p>nano/5.9-cpeGNU-21.08 (EasyConfig: nano-5.9-cpeGNU-21.08.eb)</p> </li> <li> <p>nano/5.9-static (EasyConfig: nano-5.9-static.eb)</p> </li> <li> <p>nano/5.9 (EasyConfig: nano-5.9.eb)</p> </li> </ul>","boost":10},{"location":"n/nano/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>nano web site</p> <ul> <li> <p>Latest version downloads</p> </li> <li> <p>Download archives</p> </li> </ul> </li> <li> <p>nano on Savannah git</p> </li> </ul>","boost":10},{"location":"n/nano/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support for nano in the EasyBuilders repository is archived</p> </li> <li> <p>Sopport for nano in the CSCS repository</p> </li> </ul>","boost":10},{"location":"n/nano/#nano-59-for-cpe-2108-and-later","title":"nano 5.9 for CPE 21.08 and later","text":"<ul> <li> <p>Nano is a typical tool to compile using the SYSTEM toolchain. It does     however require the header files for ncurses which were missing in the     initial setup of LUMI.</p> </li> <li> <p>Hence we developed new EasyConfig files using the cpe* toolchains.</p> </li> </ul>","boost":10},{"location":"n/ncurses/","title":"ncurses","text":"<p>[package list]</p>","boost":10},{"location":"n/ncurses/#ncurses","title":"ncurses","text":"","boost":10},{"location":"n/ncurses/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider ncurses/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>ncurses/6.1-libsOnly (EasyConfig: ncurses-6.1-libsOnly.eb)</p> </li> <li> <p>ncurses/6.1 (EasyConfig: ncurses-6.1.eb)</p> </li> <li> <p>ncurses/6.2 (EasyConfig: ncurses-6.2.eb)</p> </li> <li> <p>ncurses/6.4-cpeCray-24.03-SUSEcompat (EasyConfig: ncurses-6.4-cpeCray-24.03-SUSEcompat.eb)</p> </li> <li> <p>ncurses/6.4-cpeGNU-24.03-SUSEcompat (EasyConfig: ncurses-6.4-cpeGNU-24.03-SUSEcompat.eb)</p> </li> <li> <p>ncurses/6.4 (EasyConfig: ncurses-6.4.eb)</p> </li> <li> <p>ncurses/6.5 (EasyConfig: ncurses-6.5.eb)</p> </li> </ul>","boost":10},{"location":"n/ncurses/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>GNU ncurses library web page</p> </li> <li> <p>ncurses download from the GNU download site</p> </li> </ul>","boost":10},{"location":"n/ncurses/#easybuild","title":"EasyBuild","text":"<ul> <li>Regular EasyBuild support</li> <li>CSCS EasyConfigs</li> </ul>","boost":10},{"location":"n/ncurses/#62-from-2106-on","title":"6.2 from 21.06 on","text":"<ul> <li> <p>We started from the regular EasyBuild configuration that does a dual pass     build of ncurses to also build a version of the library with more/different     options. We made this choice to ensure maximal compatibility with EasyConfigs     from the main EasyBuild repository.</p> </li> <li> <p>We also generate files for pkg-config, something that the original EasyConfig     files didn't do.</p> </li> <li> <p>There is a more complete setup in comments in the EasyConfig file but that one     is probably even more dangerous as bash will pick it up, so there is a risk     that the shell may not work the way it should anymore if a new shell is loaded.</p> </li> </ul>","boost":10},{"location":"n/ncurses/#62-from-2206-on","title":"6.2 from 22.06 on","text":"<ul> <li> <p>We stuck to 6.2 as there is a bug in the generation of .pc files in 6.3. It is     impossible to put the files in the correct location: The comibnation of      <code>--enable-pc-files</code> and <code>--with-pkg-config-libdir</code> produces problems in     the configure step.</p> </li> <li> <p>Improvements:</p> <ul> <li> <p>Added a checksum</p> </li> <li> <p>Added some symbolic links that are used in the standard EasyBuilders EasyConfig.</p> </li> </ul> </li> </ul>","boost":10},{"location":"n/ncurses/#64-from-2212-on","title":"6.4 from 22.12 on","text":"<ul> <li> <p>Skipped 6.3 used in 2022b and went immediately for 6.4 as it fixes the bug      in the configure process of 6.3 when <code>--enable-pc-files</code> and <code>--with-pkg-config-libdir</code>     are used together.</p> </li> <li> <p>Tried a few new options in the EasyConfig.</p> </li> <li> <p>Did not succeed in solving the compatibility problem with the <code>gdb</code> from SUSE when      working on LUMI/22.12.</p> </li> <li> <p>For LUMI/23.12, license information was added to the installation.</p> <p>The behaviour of the linker has changed in the Cray compiler and it now produces an error if the version script defines versions for symbols with exact matches that are not present. So we needed to add <code>-Wl,--undefined-version</code> to the linker options to work around this issue.</p> <p>We also did further work on trying to figure out how to get the proper version symbols in the libraries. We are now using a different set of options and also dropped the application-specific EasyBlock as that only added stuff in the background which is misleading while experimenting. The problem appears to be that NCURSEST/NCURSESTW symbols are used in the SUSE libraries, which should stand for the threaded version, yet the libraries have the names of the unthreaded versions, so it looks like some renaming may have taken place.</p> <p>We have tried with <code>--enable-weak-symbols</code> which should not add the <code>t</code> to the file name but haven't gotten it to work yet. It may need some special flags for the compiler and/or linker to work as expected.</p> </li> </ul> <p>### 6.4 -SUSEcompat version</p> <ul> <li> <p>Found how SUSE builds <code>ncurses</code>:       See the spec sheet.</p> </li> <li> <p>SUSE uses the weak symbols feature from the GNU compiler. It generates libraries with the regular      names, but that also have the multithreaded code in them and the versioned symbols are the      multithreaded ones. </p> <p>This is accompished by a combination of compiler/linker flags and arguments to the configure  script, see the EasyConfig.</p> </li> <li> <p>To be sure that the weak symbols work, we do not compile via the Cray wrappers, but overwrite <code>CC</code>,      etc., to always use a suitable version of the GCC compiler, even for non-GCC toolchains.</p> </li> <li> <p>We stay close to the SUSE options, but also generate debug libraries as that is done in the regular      EasyBuild ncurses.</p> </li> </ul>","boost":10},{"location":"n/ncurses-headers/","title":"ncurses-headers","text":"<p>[package list]</p>","boost":10},{"location":"n/ncurses-headers/#ncurses-headers","title":"ncurses-headers","text":"","boost":10},{"location":"n/ncurses-headers/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider ncurses-headers/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>ncurses-headers/6.1 (EasyConfig: ncurses-headers-6.1.eb)</li> </ul>","boost":10},{"location":"n/nmap/","title":"nmap","text":"<p>[package list]</p>","boost":10},{"location":"n/nmap/#nmap","title":"nmap","text":"","boost":10},{"location":"n/nmap/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider nmap/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>nmap/7.92 (EasyConfig: nmap-7.92.eb)</li> </ul>","boost":10},{"location":"n/nmap/#technical-documentation","title":"Technical documentation","text":"<ul> <li>nmap home page</li> </ul>","boost":10},{"location":"n/nmap/#easybuild","title":"EasyBuild","text":"<p>There is no support in the EasyBuild repository at the time of writing.</p> <p>The nmap code is compiled via Autotools.</p>","boost":10},{"location":"n/nmap/#792","title":"7.92","text":"<p>Remarks: -   Still needs old-style PCRE and not PCRE2 so may add that to syslibs -   What is libssh2 and can we install it safely through EasyBuild? For now     it uses an internal one. -   What is pcap? -   And it looks like a lot of other potential network libraries that can     be recognized aren't on the system either but that is difficult to figure     out without clear documentation. -   The tool also detects libibvers so we may not want to use the binaries after     the system update.</p>","boost":10},{"location":"o/ORCA/","title":"ORCA","text":"<p>[package list]</p>","boost":10},{"location":"o/ORCA/#orca","title":"ORCA","text":"","boost":10},{"location":"o/ORCA/#license-information","title":"License information","text":"<p>The license is only visible after registering on the forum. ORCA should only be used for academic research and teaching and for private use.</p> <p>Link: https://orcaforum.kofo.mpg.de/app.php/privacypolicy</p> <p>The license forbids to make the software available to third parties so cannot be installed by LUST for others.</p>","boost":10},{"location":"o/ORCA/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider ORCA/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>ORCA/5.0.4-cpeGNU-22.12-EasyBlock (EasyConfig: ORCA-5.0.4-cpeGNU-22.12-EasyBlock.eb)</li> </ul>","boost":10},{"location":"o/ORCA/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>ORCA web site</p> </li> <li> <p>ORCA forum</p> </li> </ul>","boost":10},{"location":"o/OpenFOAM/","title":"OpenFOAM","text":"<p>[package list]</p>","boost":10},{"location":"o/OpenFOAM/#openfoam","title":"OpenFOAM","text":"","boost":10},{"location":"o/OpenFOAM/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider OpenFOAM/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>OpenFOAM/2.1.1-cpeGNU-21.08-EasyBlock (EasyConfig: OpenFOAM-2.1.1-cpeGNU-21.08-EasyBlock.eb)</p> </li> <li> <p>OpenFOAM/2.1.1-cpeGNU-21.08 (EasyConfig: OpenFOAM-2.1.1-cpeGNU-21.08.eb)</p> </li> <li> <p>OpenFOAM/dev-cpeGNU-24.03-20250217 (EasyConfig: OpenFOAM-dev-cpeGNU-24.03-20250217.eb)</p> </li> </ul>","boost":10},{"location":"o/OpenFOAM/#technical-documentation","title":"Technical documentation","text":"<p>This folder contains some EasyConfigs for an ancient version of OpenFOAM. They do not work however. it turned out to be impossible to compile that ancient version properly on LUMI with the information we have about needed versions of dependencies etc.</p>","boost":10},{"location":"o/OpenSSL/","title":"OpenSSL","text":"<p>[package list]</p>","boost":10},{"location":"o/OpenSSL/#openssl","title":"OpenSSL","text":"","boost":10},{"location":"o/OpenSSL/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider OpenSSL/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>OpenSSL/1.1 (EasyConfig: OpenSSL-1.1.eb)</li> </ul>","boost":10},{"location":"o/OpenStackClient/","title":"OpenStackClient","text":"<p>[package list]</p>","boost":10},{"location":"o/OpenStackClient/#openstackclient","title":"OpenStackClient","text":"","boost":10},{"location":"o/OpenStackClient/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider OpenStackClient/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>OpenStackClient/5.5.0-cpeGNU-21.08 (EasyConfig: OpenStackClient-5.5.0-cpeGNU-21.08.eb)</p> </li> <li> <p>OpenStackClient/5.5.0-cpeGNU-21.12 (EasyConfig: OpenStackClient-5.5.0-cpeGNU-21.12.eb)</p> </li> <li> <p>OpenStackClient/5.5.0-GCCcore-10.2.0 (EasyConfig: OpenStackClient-5.5.0-GCCcore-10.2.0.eb)</p> </li> </ul>","boost":10},{"location":"o/oneAPI-DPCPP-compiler/","title":"oneAPI-DPCPP-compiler","text":"<p>[package list]</p>","boost":10},{"location":"o/oneAPI-DPCPP-compiler/#oneapi-dpcpp-compiler","title":"oneAPI-DPCPP-compiler","text":"","boost":10},{"location":"o/oneAPI-DPCPP-compiler/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider oneAPI-DPCPP-compiler/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>oneAPI-DPCPP-compiler/2024.2.1 (EasyConfig: oneAPI-DPCPP-compiler-2024.2.1.eb)</li> </ul>","boost":10},{"location":"p/PCRE2/","title":"PCRE2","text":"<p>[package list]</p>","boost":10},{"location":"p/PCRE2/#pcre2","title":"PCRE2","text":"","boost":10},{"location":"p/PCRE2/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider PCRE2/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>PCRE2/10.31-static (EasyConfig: PCRE2-10.31-static.eb)</p> </li> <li> <p>PCRE2/10.37-static (EasyConfig: PCRE2-10.37-static.eb)</p> </li> </ul>","boost":10},{"location":"p/PDT/","title":"PDT","text":"<p>[package list]</p>","boost":10},{"location":"p/PDT/#pdt","title":"PDT","text":"","boost":10},{"location":"p/PDT/#license-information","title":"License information","text":"<p>PDT is covered by multiple licenses as it also uses components from Edison Design Group and GNU Fortran. The license is not accessible online, but can be found when loading the PDT module as the file <code>$EBROOTPDT/share/licenses/PDT/LICENSE</code>.</p>","boost":10},{"location":"p/PDT/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider PDT/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>PDT/3.25.2-cpeAMD-23.09 (EasyConfig: PDT-3.25.2-cpeAMD-23.09.eb)</p> </li> <li> <p>PDT/3.25.2-cpeAOCC-23.09 (EasyConfig: PDT-3.25.2-cpeAOCC-23.09.eb)</p> </li> <li> <p>PDT/3.25.2-cpeCray-23.09 (EasyConfig: PDT-3.25.2-cpeCray-23.09.eb)</p> </li> <li> <p>PDT/3.25.2-cpeGNU-23.09 (EasyConfig: PDT-3.25.2-cpeGNU-23.09.eb)</p> </li> <li> <p>PDT/3.25.2 (EasyConfig: PDT-3.25.2.eb)</p> </li> </ul>","boost":10},{"location":"p/PDT/#technical-documentation","title":"Technical documentation","text":"<p>PDT is a dependency for TAU. Note that it is basically abandonware that only gets the minimal maintenance required to keep it running: Version 3.25 was released in November 2017,  version 3.25.1 in May 2019, and version 3.25.2 in January 2024 to finally properly support the new LLVM-based Intel compilers that at that time  had been around for a while.</p> <p>PDT or Program Database Toolkit is a tool infrastructure that provides access to the high-level interface of source code for analysis tools and applications.  Currently, the toolkit consists of the C/C++ and Fortran 77/90/95 IL (Intermediate Language) Analyzers, and DUCTAPE (C++ program Database Utilities and Conversion Tools APplication Environment) library and applica- tions.  The EDG C++ (or Mutek Fortran 90) Front End first parses a source file, and produces an intermediate language file.  The appropriate IL Analyzer processes this IL file, and creates a \"program database\" (PDB) file consisting of the high-level interface of the original source.  Use of the DUCTAPE library then makes the contents of the PDB file accessible to applications. This release also includes the Flint F95 parser from Cleanscape Inc.</p> <p>See http://www.cs.uoregon.edu/research/pdt for more information on PDT.</p> <ul> <li> <p>PDT home page</p> <ul> <li> <p>PDT documentation.</p> <p>There is no proper installation manual available online though. </p> </li> <li> <p>PDT downloads:      Registration is required so one needs to manually download the sources.</p> </li> </ul> </li> </ul>","boost":10},{"location":"p/PDT/#installation-instructions","title":"Installation instructions","text":"<p>Though officially registration is required to download PDT, looking at the Spack package there is a trick: The URL is of the type <code>https://www.cs.uoregon.edu/research/paracomp/pdtoolkit/Download/pdtoolkit-3.25.2.tar.gz</code>.</p> <p>The build process is completely unconventional (to be kind as it is really a  disaster):</p> <ul> <li> <p>The configure script has very untraditional behaviour. The      EasyBuild EasyBlock for PDT     claims that the environment variables that set compiler options, are simply neglected.     This indicates that it may give problems to on one hand have the configure script add     proper compiler-specific optimisations, but on the other hand also use the compiler wrappers     to compile the code. Spack does it by editing <code>ductape/Makefile</code> for some compilers.</p> <p>The installation directory must be created before calling the configure script, passing the installation directory with the <code>-prefix</code> option.</p> <p>The configure script already builds and installs the software that goes in the <code>contrib</code> subdirectory of the installation directory. It looks like those are actually build in-place rather than in the temporary directory in which the PDT package is unpacked. The whole process leaves behind a mess of files that are no longer needed after the build. The executables are static executables so in principle they could be just moved around rather than linked to from the bin directory of PDT, but it is not clear if they need other files at runtime that are found based on the location of the executable.</p> </li> <li> <p>The build process itself is also strange. It is triggered by <code>make install</code> so      there is no separate build and install step. It does build <code>libpdb.a</code> that is     installed in the <code>x86_64/lib</code> subdirectory, and some other executables     (pdbconv, pdbtree, pdbmerge, pdbcomment, pdbstmt, xmlgen) that     go in the <code>x86_64/bin</code> subdirectory. These are build in the build directory,     so not in-place, and simply copied to their final locationat the end of the      <code>make install</code> process.</p> </li> <li> <p>The name of the executables in <code>roseparse</code> suggest that PDT is based on version      4.4 of the Edison Design Group C/C++ front-end. This is a very old frontend that     will not support newer C++ options.In fact, feature tables on the website of EDG     show that even C++11 support was not complete in version 4.4. The question is      what effect this has on the operation of the software.</p> <p>When we developed the first easyconfigs for this package, in July 2024, the version that EDG was distributing, was 6.6, released in December 2023.</p> </li> </ul>","boost":10},{"location":"p/PDT/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>There is support for PDT in the EasyBuilders repository     which relies on a      software-specific EasyBlock     to set the architecture option and specific compiler.</p> </li> <li> <p>There is support for PDT in the CSCS repository,     installing the lite version.</p> <p>CSCS compiles PDT in the SYSTEM toolchain likely to work around the problem with compiler wrappers and proper optimisation options described above, yet to end up with a library that likely works with all other compilers on the system. Because they are simply using GCC without wrappers, they can use the standard EasyBlock for PDT.</p> </li> <li> <p>The spack package <code>pdt</code> also offers PDT.</p> </li> </ul>","boost":10},{"location":"p/PDT/#version-3252-for-lumi2309","title":"Version 3.25.2 for LUMI/23.09","text":"<ul> <li> <p>As we need a clean installation directory already during the configure step,     there is no other option than to adapt the custom EasyBlock for LUMI.</p> <p>This of course could create a maintenance nightmare as we may need to port the changes to future versions of EasyBuild.</p> </li> <li> <p>The problem with this setup is that a number of contributed packages are simply     compiled with <code>gcc</code> and <code>g++</code> so in practice with the system compiler except for     <code>cpeGNU</code>. This is certainly the case for the rose component. This may also explain     why CSCS simply uses the SYSTEM toolchain to install a lite verion of PDT.</p> <p>Even the version detection of that compiler is not always correct...</p> </li> <li> <p>We take away the part of code that causes <code>-h conform,instantiate=used</code>     to be added to the compiler flags as these options are not recognised by the     compiler. Could this be options from the days that Cray had its own C/C++     compiler rather than one based on Clang/LLVM?</p> </li> <li> <p>The EasyBlock that comes with EasyBuild was enhanced in several ways:</p> <ul> <li> <p>Two configuration parameters were added to overwrite automatically determined     values: <code>useropt</code> for the argument of <code>-useropt</code>, and <code>compopt</code> for the      <code>-CC</code>/<code>-GCC</code> etc. options of the <code>configure</code> command</p> </li> <li> <p>The code used to detect the compiler type option was enhanced to use <code>-CC</code>     whenever one of our CPE toolchains is used.</p> </li> <li> <p>The code used to detect the value for <code>-useropt</code> was enhanced to not set the     option if the computed value is empty, which was the case when the SYSTEM toolchain     is used. This enables overwriten the option not only with the <code>useropt</code> parameter     (which we only added later as we had even more problems). but also to add it via     <code>configopts</code> instead. In any case, the Python code was problematic and needed to     be secured as it really passed <code>-useropt=None</code> if no value was found, which of course     led to crashed.</p> </li> </ul> </li> <li> <p>To learn more about what setups we need, a version using only the SYSTEM toolchain      was made, and versions with every one of our programming environments.</p> </li> </ul>","boost":10},{"location":"p/PLUMED/","title":"PLUMED","text":"<p>[package list]</p>","boost":10},{"location":"p/PLUMED/#plumed","title":"PLUMED","text":"","boost":10},{"location":"p/PLUMED/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider PLUMED/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>PLUMED/2.7.3-cpeAOCC-21.12 (EasyConfig: PLUMED-2.7.3-cpeAOCC-21.12.eb)</p> </li> <li> <p>PLUMED/2.7.3-cpeCray-21.12 (EasyConfig: PLUMED-2.7.3-cpeCray-21.12.eb)</p> </li> <li> <p>PLUMED/2.7.3-cpeGNU-21.12 (EasyConfig: PLUMED-2.7.3-cpeGNU-21.12.eb)</p> </li> <li> <p>PLUMED/2.7.4-cpeCray-24.03-noPython (EasyConfig: PLUMED-2.7.4-cpeCray-24.03-noPython.eb)</p> </li> <li> <p>PLUMED/2.7.4-cpeGNU-22.08-cray-python-3.9.12.1 (EasyConfig: PLUMED-2.7.4-cpeGNU-22.08-cray-python-3.9.12.1.eb)</p> </li> <li> <p>PLUMED/2.7.4-cpeGNU-22.08-custom (EasyConfig: PLUMED-2.7.4-cpeGNU-22.08-custom.eb)</p> </li> <li> <p>PLUMED/2.7.4-cpeGNU-22.08-noPython (EasyConfig: PLUMED-2.7.4-cpeGNU-22.08-noPython.eb)</p> </li> <li> <p>PLUMED/2.7.4-cpeGNU-24.03-cray-python-3.11.7 (EasyConfig: PLUMED-2.7.4-cpeGNU-24.03-cray-python-3.11.7.eb)</p> </li> <li> <p>PLUMED/2.9.2-cpeGNU-24.03-cray-python-3.11.7 (EasyConfig: PLUMED-2.9.2-cpeGNU-24.03-cray-python-3.11.7.eb)</p> </li> </ul>","boost":10},{"location":"p/PROJ/","title":"PROJ","text":"<p>[package list]</p>","boost":10},{"location":"p/PROJ/#proj","title":"PROJ","text":"","boost":10},{"location":"p/PROJ/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider PROJ/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>PROJ/9.1.1-cpeGNU-22.08 (EasyConfig: PROJ-9.1.1-cpeGNU-22.08.eb)</li> </ul>","boost":10},{"location":"p/PROJ/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>PROJ web site</p> </li> <li> <p>PROJ on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"p/PROJ/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>PROJ in the EasyBuilders repository</p> </li> <li> <p>PROJ in the CSCS repository</p> </li> </ul>","boost":10},{"location":"p/PROJ/#version-911-for-cpegnu2208","title":"Version 9.1.1 for cpeGNU/22.08","text":"<ul> <li> <p>The EasyConfig is derived from th EasyBuilders one, but we are using the internal     nlohmann/json library. As that is a header file-only library there is no need     to have this on the system.</p> <p>We currently also use the internal gtest rather than one installed with EasyBuild.</p> </li> <li> <p>Switched to <code>lib</code> as the install directory for the libraries.</p> </li> </ul>","boost":10},{"location":"p/PRoot/","title":"PRoot","text":"<p>[package list]</p>","boost":10},{"location":"p/PRoot/#proot","title":"PRoot","text":"","boost":10},{"location":"p/PRoot/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider PRoot/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>PRoot/5.4.0-container (EasyConfig: PRoot-5.4.0-container.eb)</p> <p>This easyconfig is meant to be installed in the central software stack in <code>partition/container</code> to make it possible to do a container build from EasyBuild while still storing the container in <code>partition/container</code>. It has minimal build dependencies, using only the system gcc and make.</p> </li> <li> <p>PRoot/5.4.0 (EasyConfig: PRoot-5.4.0.eb)</p> <p>Test EasyConfig to experiment with PRoot to prepare for integration in the  syslibs bundle for LUMI.</p> </li> </ul>","boost":10},{"location":"p/PRoot/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>PRoot home page</p> </li> <li> <p>PRoot on GitHub</p> <ul> <li>PRoot GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"p/PRoot/#easybuild","title":"EasyBuild","text":"<p>There is no support for PRoot in EasyBuild or Spack.</p>","boost":10},{"location":"p/PRoot/#540-for-the-system-toolchain","title":"5.4.0 for the SYSTEM toolchain","text":"<ul> <li> <p>The EasyConfig is a LUST development. </p> </li> <li> <p>We went for build that is fully static except for libc taken from the system to     be as independent from anything else as possible.</p> </li> <li> <p>Needed to fix the Makefile as the warnings about it not being a git repository     caused EasyBuild to stop the build.</p> </li> </ul>","boost":10},{"location":"p/PRoot/#540-container","title":"5.4.0-container","text":"<ul> <li> <p>This EasyConfig is a LUST development, combining EasyConfigs for talloc and PRoot.</p> </li> <li> <p>The idea is to obtain a single executable that only depends on system libraries,     using a build process that EasyBuild can also do in <code>partition/container</code>, so with     minimal tooling, using only the system gcc and make utility.</p> </li> <li> <p>Done as a Bundle:</p> <ul> <li> <p>First a static version of talloc is compiled. This is already tricky as it only     installs shared libraries, so these are removed and replaced with a static one     generated from the object files.</p> </li> <li> <p>Next we build PRoot, using the just built talloc library. Some trickery is      required to create the correct environment for the build process so that it uses     the right compilers and compiler flags and can find the talloc package.</p> </li> <li> <p>In <code>postinstallcmds</code> we then remove all remaining pieces of talloc, to end with     just a <code>proot</code> binary and information about its license.</p> </li> </ul> </li> </ul>","boost":10},{"location":"p/Paraver/","title":"Paraver","text":"<p>[package list]</p>","boost":10},{"location":"p/Paraver/#paraver","title":"Paraver","text":"","boost":10},{"location":"p/Paraver/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Paraver/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>Paraver/4.10.4-cpeGNU-22.08 (EasyConfig: Paraver-4.10.4-cpeGNU-22.08.eb)</li> </ul>","boost":10},{"location":"p/Paraver/#technical-documentation","title":"Technical documentation","text":"<p>Paraver is a performance analysis tool.</p> <p>It is here currently as a test vehicle of wxWidgets also.</p> <ul> <li> Paraver web site at BSC</li> </ul>","boost":10},{"location":"p/Paraver/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Paraver support in the EasyBuilders repository.     It compiles Paraver from sources and uses a      custom EasyBlock     for that.</p> </li> <li> <p>Paraver support in the CSCS repository.     Here Paraver is installed from downloaded binaries.</p> </li> <li> <p>PAraver (paraver) in Spack</p> </li> </ul>","boost":10},{"location":"p/Paraver/#version-4104","title":"Version 4.10.4","text":"<ul> <li>The EasyConfig is a direct port of the EasyBuilders one for the foss/2021a       toolchain due to the lack of a more recent one. The version was bumped to 4.10.4      as 3.9.2 does not compile.</li> </ul> <p>The program does not yet completely work as it should. Part of it is likely due to  the problem with adwaita in GTK3, but the segmentation violation when quitting the program may have a different cause.</p>","boost":10},{"location":"p/Perl/","title":"Perl","text":"<p>[package list]</p>","boost":10},{"location":"p/Perl/#perl","title":"Perl","text":"","boost":10},{"location":"p/Perl/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Perl/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>Perl/5.36.0-cpeGNU-23.03 (EasyConfig: Perl-5.36.0-cpeGNU-23.03.eb)</p> </li> <li> <p>Perl/5.36.1-cpeAMD-23.12-bare (EasyConfig: Perl-5.36.1-cpeAMD-23.12-bare.eb)</p> </li> <li> <p>Perl/5.36.1-cpeAOCC-23.12-bare (EasyConfig: Perl-5.36.1-cpeAOCC-23.12-bare.eb)</p> </li> <li> <p>Perl/5.36.1-cpeCray-23.12-bare (EasyConfig: Perl-5.36.1-cpeCray-23.12-bare.eb)</p> </li> <li> <p>Perl/5.36.1-cpeGNU-23.12-bare (EasyConfig: Perl-5.36.1-cpeGNU-23.12-bare.eb)</p> </li> <li> <p>Perl/5.38.0-cpeAMD-24.03-bare (EasyConfig: Perl-5.38.0-cpeAMD-24.03-bare.eb)</p> </li> <li> <p>Perl/5.38.0-cpeAOCC-24.03-bare (EasyConfig: Perl-5.38.0-cpeAOCC-24.03-bare.eb)</p> </li> <li> <p>Perl/5.38.0-cpeCray-24.03-bare (EasyConfig: Perl-5.38.0-cpeCray-24.03-bare.eb)</p> </li> <li> <p>Perl/5.38.0-cpeGNU-24.03-bare (EasyConfig: Perl-5.38.0-cpeGNU-24.03-bare.eb)</p> </li> </ul>","boost":10},{"location":"p/PyTorch/","title":"PyTorch","text":"<p>[package list]</p>","boost":10},{"location":"p/PyTorch/#pytorch","title":"PyTorch","text":"","boost":10},{"location":"p/PyTorch/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider PyTorch/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>PyTorch/2.2.0-rocm-5.6.1-python-3.10-singularity-venv-1-20240209 (EasyConfig: PyTorch-2.2.0-rocm-5.6.1-python-3.10-singularity-venv-1-20240209.eb)</p> <p>Contains PyTorch 2.2.0 with torchaudio 2.2.0, torchdata 0.7.1+cpu, torchtext 0.17.0+cpu, torchvision 0.17.0 GPU version, DeepSpeed 0.12.3,  flash-attention 2.0.4 and xformers 0.0.25+8dd471d.d20240209, on Python 3.10 and ROCm 5.6.1. The container also fully assists the procedure to add extra packages in a Python virtual environment.</p> <p>This version works with $WITH_CONDA, $WITH_VENV and $WITH_CONDA_VENV for initialisation of the  conda / Python venv / or both environments respectively.</p> </li> <li> <p>PyTorch/2.2.0-rocm-5.6.1-python-3.10-singularity-venv-2-20240209 (EasyConfig: PyTorch-2.2.0-rocm-5.6.1-python-3.10-singularity-venv-2-20240209.eb)</p> <p>Contains PyTorch 2.2.0 with torchaudio 2.2.0, torchdata 0.7.1+cpu, torchtext 0.17.0+cpu, torchvision 0.17.0 GPU version, DeepSpeed 0.12.3,  flash-attention 2.0.4 and xformers 0.0.25+8dd471d.d20240209, on Python 3.10 and ROCm 5.6.1. The container also fully assists the procedure to add extra packages in a Python virtual environment.</p> <p>This version works with $WITH_CONDA, $WITH_VENV and $WITH_CONDA_VENV for initialisation of the  conda / Python venv / or both environments respectively.</p> </li> </ul>","boost":10},{"location":"p/PyTorch/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p><code>PyTorch-2.2.0-rocm-5.6.1-python-3.10-singularity-venv-1-20240209.eb</code>:     This is an example where we use a Conda environment inside the container,     but also already add a virtual environment outside the container during     the installation process. See the module help for instructions: This version     provides some scripts to start PyTorch, but it still uses      <code>$WITH_CONDA</code>/<code>$WITH_VENV</code>/<code>$WITH_CONDA_VENV</code> for initialising the     environments.</p> <p>Example command(s) to check:</p> <ul> <li> <p>Import a package that is in the Python virtual environment and check its      version just to be sure:</p> <pre><code>start-shell -c 'conda-python-simple -c \"import torchmetrics ; print( torchmetrics.__version__ )\"'\n</code></pre> <p>Calling <code>conda-python-simple</code> in this example ensures that the conda and Python virtual  environment are correctly initialised before passing its arguments to <code>python</code>.</p> </li> </ul> <p>Matching <code>create_container_vars</code> in the LMOD <code>SitePackage.lua</code> file at the time of testing:</p> <pre><code>function create_container_vars( sif_file, package_name, installdir, bind )\n\n    local SIF_file = get_SIF_file( sif_file, package_name, installdir )    \n    local SIF_attributes = lfs.attributes( SIF_file )\n\n    if SIF_attributes ~= nil and ( SIF_attributes.mode == 'file' or SIF_attributes.mode == 'link' ) then\n        -- The SIF file exists so we can set the environment variables.\n        local varname = convert_to_EBvar( package_name, 'SIF' )\n        setenv( 'SIF',   SIF_file )\n        setenv( varname, SIF_file )\n    else\n        -- The SIF file does not exist.\n        if mode() == 'load' then\n            LmodError( 'ERROR: Cannot locate the singularity container file ' .. sif_file ..\n                       '. One potential cause is that it may have been removed from the system.' )\n        end\n    end\n\n    if bind ~= nil then\n\n        local user_software_squashfs_attributes = lfs.attributes( pathJoin( installdir, 'user-software.squashfs' ) )\n        local user_software_dir_attributes =      lfs.attributes( pathJoin( installdir, 'user-software' ) )\n\n        if user_software_squashfs_attributes ~= nil and ( user_software_squashfs_attributes.mode == 'file' or user_software_squashfs_attributes.mode == 'link' ) then\n\n            setenv( 'SINGULARITY_BIND', bind .. ',' .. pathJoin( installdir, 'user-software.squashfs') .. ':/user-software:image-src=/' )\n\n        elseif user_software_dir_attributes ~= nil and ( user_software_dir_attributes.mode == 'directory' or user_software_dir_attributes.mode == 'link' ) then\n\n            setenv( 'SINGULARITY_BIND', bind .. ',' .. pathJoin( installdir, 'user-software') .. ':/user-software' )\n\n        else -- No user-software as either a squashfs file or a directory\n\n            setenv( 'SINGULARITY_BIND', bind )\n\n        end\n\n    end\n\nend\n</code></pre> </li> <li> <p><code>PyTorch-2.2.0-rocm-5.6.1-python-3.10-singularity-venv-2-20240209.eb</code>:     Version with automatic initialisation of the conda and python virtual environments.</p> <p>Example command(s) to check:</p> <ul> <li> <p>Import a package that is in the Python virtual environment and check its      version just to be sure:</p> <pre><code>start-shell -c 'python -c \"import torchmetrics ; print( torchmetrics.__version__ )\"'\n</code></pre> <p>or</p> <pre><code>singularity exec $SIFPYTORCH python -c \"import torchmetrics ; print( torchmetrics.__version__ )\"\n</code></pre> </li> <li> <p>Using <code>mnist_CPP.py</code> and <code>model/model_gpu.dat</code> from the     LUMI ReFrame test repo,     one can run the following jobscript:</p> <pre><code>#!/bin/bash -e\n#SBATCH --nodes=4\n#SBATCH --gpus-per-node=8\n#SBATCH --tasks-per-node=8\n#SBATCH --cpus-per-task=7\n#SBATCH --output=\"output_%x_%j.txt\"\n#SBATCH --partition=standard-g\n#SBATCH --mem=480G\n#SBATCH --time=00:15:00\n#SBATCH --account=project_&lt;your_project_id&gt;\n\nmodule load LUMI  # Which version doesn't matter, it is only to get the container and wget.\nmodule load wget  # Compute nodes don't have wget preinstalled. Version and toolchain don't matter in this example.\nmodule load PyTorch/2.2.0-rocm-5.6.1-python-3.10-singularity-venv-2-20240209\n\n# Get the files from the LUMI ReFrame repository\n# It is not recommended to do this in a jobscript but it works to ensure that\n# you get the correct files for the example. And even worse, the example itself\n# downloads a lot more data.\nwget https://raw.githubusercontent.com/Lumi-supercomputer/lumi-reframe-tests/main/checks/containers/ML_containers/src/pytorch/mnist/mnist_DDP.py\nmkdir -p model ; cd model\nwget https://github.com/Lumi-supercomputer/lumi-reframe-tests/raw/main/checks/containers/ML_containers/src/pytorch/mnist/model/model_gpu.dat\ncd ..\n\n# Optional: Inject the environment variables for NCCL debugging into the container.   \n# This will produce a lot of debug output!     \nexport SINGULARITYENV_NCCL_DEBUG=INFO\nexport SINGULARITYENV_NCCL_DEBUG_SUBSYS=INIT,COLL\n\nc=fe\nMYMASKS=\"0x${c}000000000000,0x${c}00000000000000,0x${c}0000,0x${c}000000,0x${c},0x${c}00,0x${c}00000000,0x${c}0000000000\"\n\nsrun --cpu-bind=mask_cpu:$MYMASKS \\\n  singularity exec $SIFPYTORCH \\\n    conda-python-distributed -u mnist_DDP.py --gpu --modelpath model\n</code></pre> </li> </ul> </li> </ul>","boost":10},{"location":"p/p7zip/","title":"p7zip","text":"<p>[package list]</p>","boost":10},{"location":"p/p7zip/#p7zip","title":"p7zip","text":"","boost":10},{"location":"p/p7zip/#license-information","title":"License information","text":"<p>The p7zip package is covered by the  GNU Lesser General Public License v2.1 or later. Files for RAR (un)compression though have a restriction. See the License.txt file in the p7zip GitHub repository.</p> <p>After loading the module, the license information can also be found in <code>$EBROOTP7ZIP/share/licenses/p7zip</code>.</p>","boost":10},{"location":"p/p7zip/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider p7zip/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>p7zip/17.05 (EasyConfig: p7zip-17.05.eb)</p> </li> <li> <p>p7zip/9.38.1 (EasyConfig: p7zip-9.38.1.eb)</p> </li> </ul>","boost":10},{"location":"p/p7zip/#technical-documentation","title":"Technical documentation","text":"<p>The p7zip package is a POSIX/Linux port of some of the  p7zip Windows tools. Note that the latest version of 7zip do now support Linux already.</p> <p>The p7zip tools however are used in certain EasyConfigs to work with ISO files, e.b., the MATLAB EasyConfigs in the EasyBuilders repository.</p> <ul> <li> <p>New developments on GitHub.     It is a fork from previous versions that are no longer maintained.     It also extends the tools of the 7zip project</p> <ul> <li>GitHub releases</li> </ul> </li> <li> <p>Older versions on SourceForge</p> <ul> <li>SourceForge downloads     (up to version 16.02)</li> </ul> </li> </ul>","boost":10},{"location":"p/p7zip/#easybuild","title":"EasyBuild","text":"<ul> <li>p7zip in the EasyBuilders repository</li> </ul>","boost":10},{"location":"p/p7zip/#version-9381","title":"Version 9.38.1","text":"<ul> <li>Trivial port of the EasyConfig in the EasyBuilders repository.</li> </ul>","boost":10},{"location":"p/p7zip/#version-1705","title":"Version 17.05","text":"<ul> <li> <p>Based on the EasyBuilders p7zip one for 17.04, but moved to the SYSTEM     toolchain, hence combined with the 9.38.1 one, and also downloading the     sources differently so that the sources file gets a proper name and can     be shared with other sources in a Bundle.</p> <p>The work was done in preparation for inclusion in the <code>EasyBuild-tools/23.09</code> bundle in the LUMI Software Stack.</p> </li> </ul>","boost":10},{"location":"p/pocl-UNFINISHED/","title":"pocl-UNFINISHED","text":"<p>[package list]</p>","boost":10},{"location":"p/pocl-UNFINISHED/#pocl-unfinished","title":"pocl-UNFINISHED","text":"","boost":10},{"location":"p/pocl-UNFINISHED/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider pocl-UNFINISHED/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>pocl-UNFINISHED/pocl-3.0-cpeGNU-22.08 (EasyConfig: pocl-3.0-cpeGNU-22.08.eb)</li> </ul>","boost":10},{"location":"p/pocl-UNFINISHED/#technical-documentation","title":"Technical documentation","text":"<p>PoCL was introduced in this repository as a dependency of VirtualGL.</p> <ul> <li> <p>PoCL web site</p> <ul> <li>PoCL documentation on that web site</li> </ul> </li> <li> <p>PoCL on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"p/pocl-UNFINISHED/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>pocl support in EasyBuild</p> </li> <li> <p>There is no support for pocl in the CSCS repository.</p> </li> </ul>","boost":10},{"location":"p/pocl-UNFINISHED/#version-30-for-cpegnu2208","title":"Version 3.0 for cpeGNU/22.08","text":"<ul> <li>The EasyConfig is derived from the EasyBuilders one for version 1.8 as     there was none yet for 3.0. 3.0 is needed however if Clan 14 is used.</li> </ul> <p>UNFINISHED as building the necessary Clang 14.0.2 module is a rather complicated.</p>","boost":10},{"location":"q/Qt5/","title":"Qt5","text":"<p>[package list]</p>","boost":10},{"location":"q/Qt5/#qt5","title":"Qt5","text":"","boost":10},{"location":"q/Qt5/#license-information","title":"License information","text":"<p>Information on the Qt5 license can be found on the \"Qt Licensing\" page on the Qt website.</p> <p>We do not have a commercial license for LUMI.</p>","boost":10},{"location":"q/Qt5/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Qt5/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>Qt5/5.15.15-cpeGNU-24.03 (EasyConfig: Qt5-5.15.15-cpeGNU-24.03.eb)</p> </li> <li> <p>Qt5/5.9.4-cpeGNU-21.08-noOpengl (EasyConfig: Qt5-5.9.4-cpeGNU-21.08-noOpengl.eb)</p> </li> </ul>","boost":10},{"location":"q/Qt5/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>Qt home page</p> </li> <li> <p>Qt downloads</p> </li> </ul>","boost":10},{"location":"q/Qt5/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support for Qt5 in the EasyBuilders repository</p> </li> <li> <p>Support for Qt in the CSCS repository</p> </li> <li> <p>qt in Spack </p> </li> </ul>","boost":10},{"location":"q/Qt5/#51515-for-cpegnu2403","title":"5.15.15 for cpeGNU/24.03","text":"<ul> <li>The EasyConfig is derived from the EasyBuilders but brought in the LUMI style     and adapted for what works on LUMI.</li> </ul>","boost":10},{"location":"q/QuantumESPRESSO/","title":"QuantumESPRESSO","text":"<p>[package list]</p>","boost":10},{"location":"q/QuantumESPRESSO/#quantumespresso","title":"QuantumESPRESSO","text":"","boost":10},{"location":"q/QuantumESPRESSO/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider QuantumESPRESSO/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>QuantumESPRESSO/6.8.0-cpeGNU-21.08-autoconf (EasyConfig: QuantumESPRESSO-6.8.0-cpeGNU-21.08-autoconf.eb)</p> </li> <li> <p>QuantumESPRESSO/6.8.0-cpeGNU-21.08-CMake (EasyConfig: QuantumESPRESSO-6.8.0-cpeGNU-21.08-CMake.eb)</p> </li> </ul>","boost":10},{"location":"q/QuantumESPRESSO/#technical-documentation","title":"Technical documentation","text":"<p>Manual build.</p> <p>module load PrgEnv-gnu/8.1.0 module load cray-fftw/3.3.8.11</p> <p>./configure F90=ftn MPIF90=ftn CC=cc BLAS_LIBS=\"-L/opt/cray/pe/libsci/21.08.1.2/GNU/9.1/x86_64/lib -llibsci_gnu_mp\" LAPACK_LIBS=\"-L/opt/cray/pe/libsci/21.08.1.2/GNU/9.1/x86_64/lib -llibsci_gnu_mp\" SCALAPACK_LIBS=\"-L/opt/cray/pe/libsci/21.08.1.2/GNU/9.1/x86_64/lib -llibsci_gnu_mp\" FFTW_INCLUDE=$FFTW_INC FFT_LIBS=\"-L$FFTW_DIR -lfftw3\" --enable-parallel --enable-openmp --with-scalapack</p>","boost":10},{"location":"r/R/","title":"R","text":"<p>[package list]</p>","boost":10},{"location":"r/R/#r","title":"R","text":"","boost":10},{"location":"r/R/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider R/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>R/4.2.1-cpeGNU-22.06-raw (EasyConfig: R-4.2.1-cpeGNU-22.06-raw.eb)</p> </li> <li> <p>R/4.2.1-cpeGNU-22.06 (EasyConfig: R-4.2.1-cpeGNU-22.06.eb)</p> </li> </ul>","boost":10},{"location":"r/R/#technical-documentation","title":"Technical documentation","text":"<p>ALSO IN LUMI-EasyBuild-contrib but using this version for development.</p> <ul> <li>R web site</li> </ul>","boost":10},{"location":"r/R/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support in the EasyBuilders repository</p> <p>R uses an application-specific EasyBlock</p> </li> <li> <p>Support in the CSCS repository</p> </li> </ul>","boost":10},{"location":"r/R/#version-421-for-cpegnu-2206","title":"Version 4.2.1 for cpeGNU 22.06","text":"<ul> <li> <p>Worked from the EasyBuilders EasyConfig but removed all OpenGL-related stuff     and also removed all extensions to create the <code>-raw</code> version which has no     external packages at all.</p> </li> <li> <p>PROBLEM: Suffers from the multiple Cray LibSci libraries linked in problem, and     it is not clear how they come in.</p> <ul> <li> <p>The R <code>infoSession()</code> command shows that the non-MPI multithreaded library     is used.</p> </li> <li> <p>The configure script does discover the right option to compile with OpenMP.</p> </li> <li> <p>Enforcing the OpenMP compiler flag through <code>toolchainopts</code> though fails. It      is not used at link time, resulting in undefined OpenMP symbols when linking.</p> </li> </ul> <p>SOLUTION: Enforce OpenMP through <code>toolchainopts</code> and manually add <code>-fopenmp</code> to <code>LDFLAGS</code> in <code>preconfigopts</code>.</p> </li> <li> <p>Extensions</p> <ul> <li> <p>Rmpi:</p> <ul> <li> <p>Typically uses an EasyBlock, but that EasyBlock does not support the Cray     environment so we avoid using it and instead manually build the right     <code>--configure-args</code> flag for the R installation command.</p> </li> <li> <p>There is still a problem as when loading <code>Rmpi.so</code>, the load fails because     <code>mpi_universe_size</code> cannot be found. Now this is a routine defined in Rmpi      itself but only compiles in certain cases. However, it looks like routines      that reference to this function are not correctly disabled when this routine     is not included in the compilation.</p> <p>Now in fact, the configure script does correctly determine that it should  add <code>-DMPI2</code> to the command line. However, it does so after a faulty <code>-I</code> flag that does not contain a directory. Hence the compiler interprets the <code>-DMPI2</code> flag as the argument of <code>-I</code> instead.</p> <p>The solution to this last problem is a bit complicated.</p> <ul> <li> <p>The empty <code>-I</code> argument is a bug in the configure script that occurs      when <code>--with-Rmpi-include</code> is not used.</p> </li> <li> <p>Adding just any directory with that argument does not work; the configure     script checks if it contains <code>mpi.h</code>. We used an environment variable to     find the directory that Cray MPI uses.</p> </li> <li> <p>But adding <code>--with-Rmpi-include</code> also requires adding <code>--with-Rmpi-libpath</code>     for which we used the same environment variable.</p> </li> <li> <p>So hopefully these options do not conflict with anything the Cray compiler     wrappers add. <code>--with-Rmpi-include</code> and <code>--with-Rmpi-libpath</code> really should     not be needed when using the Cray wrappers.</p> </li> </ul> </li> </ul> </li> </ul> </li> </ul>","boost":10},{"location":"r/Rust/","title":"Rust","text":"<p>[package list]</p>","boost":10},{"location":"r/Rust/#rust","title":"Rust","text":"","boost":10},{"location":"r/Rust/#user-documentation","title":"User documentation","text":"<p>Rust is offered \"as is\", without support from the LUMI User Support Team as it is not a typical HPC language and as we don't have the personpower to build up proper knowledge about Rust. </p> <p>The Rust compiler is known to conflict with the Cray PE in certain circumstances and recent versions are also incompatible with the system GCC of LUMI causing the bootstrap procedure during installation to fail.</p> <p>The Rust EasyConfig files that we provide rely on GCC for the installation of the compiler but don't need GCC anymore afterwards which is why no toolchain is loaded explicitly.</p> <p>We cannot guarantee that object files generated by the Rust compiler can link with object files or libraries from the Cray PE as the Rust compiler is based on its own version of LLVM which may not correspond with any Cray or AMD compiler version on  the system at a given time.</p>","boost":10},{"location":"r/Rust/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Rust/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>Rust/1.70.0-cpeGNU-22.12 (EasyConfig: Rust-1.70.0-cpeGNU-22.12.eb)</p> </li> <li> <p>Rust/1.70.0 (EasyConfig: Rust-1.70.0.eb)</p> </li> </ul>","boost":10},{"location":"r/rclone/","title":"rclone","text":"<p>[package list]</p>","boost":10},{"location":"r/rclone/#rclone","title":"rclone","text":"","boost":10},{"location":"r/rclone/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider rclone/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>rclone/1.57.0-source (EasyConfig: rclone-1.57.0-source.eb)</li> </ul>","boost":10},{"location":"r/rclone/#technical-documentation","title":"Technical documentation","text":"<p>Rclone is written in Go but there are binaries available that are fully statically linked and may run.</p> <ul> <li> <p>rclone web site</p> <ul> <li>rclone downloads</li> </ul> </li> <li> <p>rclone on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"r/rclone/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>[rclone support in the EasyBuilders repository]|(https://github.com/easybuilders/easybuild-easyconfigs/tree/develop/easybuild/easyconfigs/r/rclone)</p> </li> <li> <p>There is no rclone support in the CSCS repository</p> </li> </ul>","boost":10},{"location":"r/rclone/#version-1570","title":"Version 1.57.0","text":"<ul> <li> <p>For now we simply download the binary and will see if that one works.     The binary is fully statically linked.</p> </li> <li> <p>If needed the new EasyBuild approach of compiling the package also     works.</p> </li> </ul>","boost":10},{"location":"s/SCons/","title":"SCons","text":"<p>[package list]</p>","boost":10},{"location":"s/SCons/#scons","title":"SCons","text":"","boost":10},{"location":"s/SCons/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider SCons/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>SCons/3.1.2-buildtoolsDevel (EasyConfig: SCons-3.1.2-buildtoolsDevel.eb)</p> </li> <li> <p>SCons/3.1.2-python2 (EasyConfig: SCons-3.1.2-python2.eb)</p> </li> <li> <p>SCons/4.1.0.post1-buildtoolsDevel (EasyConfig: SCons-4.1.0.post1-buildtoolsDevel.eb)</p> </li> </ul>","boost":10},{"location":"s/SCons/#technical-documentation","title":"Technical documentation","text":"<ul> <li>SCons web site</li> <li>SCons on GitHub<ul> <li>Releases</li> </ul> </li> <li>SCons on SourceForge<ul> <li>Downloads on SourceForge</li> </ul> </li> </ul>","boost":10},{"location":"s/SCons/#general-information","title":"General information","text":"<ul> <li>SCons is Python software<ul> <li>Version 3.1 (when this documentation was first written) Requires 2.7 or 3.5+</li> </ul> </li> </ul>","boost":10},{"location":"s/SCons/#easybuild","title":"EasyBuild","text":"<p>This documentation was written when installing version 3.1.2 in the 2020a build round.</p> <p>There is support for SCons in the  EasyBuilders repository. It however relies on EasyBuild-generated Python modules which is kind of stupid for a tool that is used to install some very basic software.</p>","boost":10},{"location":"s/SCons/#312","title":"3.1.2","text":"<ul> <li>Developed with the goal of integrating into out buildtools module.</li> <li>Started from an EasyBuilders recipe.</li> <li>Switched to the SYSTEM toolchain and using a system-installed Python.</li> <li>Since we already had a package in the buildtools bundle that requires Python 3   (Meson) we decided to go for Python 3. This implies:<ul> <li>Forcing EasyBuild to use the right Python executable by setting   req_py_majver and req_py_minver.</li> <li>Since the wrapper script use <code>/usr/bin/env python</code>, we edited them with   sed to use <code>python3</code> instead to ensure that the right version of Python   corresponding to the installed libraries is used. Otherwise we could   expect conflicts with the PYTHONPATH in buildtools.</li> </ul> </li> <li>Since our system Python does not have pip installed, we turned off pip   installation.</li> <li>Tested on the CSCS system</li> </ul>","boost":10},{"location":"s/SCons/#410post1","title":"4.1.0.post1","text":"<ul> <li>4.1.0 contained a bug in the installation procedure.</li> <li>The <code>postinstallcmds</code> needed for 3.1.2 are no longer needed:<ul> <li>The Windows batch file was not installed.</li> <li>The shebang line already refered to python3 (and has a path rather than     using env)</li> </ul> </li> <li>The sanity check also needed changes as the set of additional tools is different     from SCons 3.</li> </ul>","boost":10},{"location":"s/SQLite/","title":"SQLite","text":"<p>[package list]</p>","boost":10},{"location":"s/SQLite/#sqlite","title":"SQLite","text":"","boost":10},{"location":"s/SQLite/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider SQLite/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>SQLite/3.36.0-static (EasyConfig: SQLite-3.36.0-static.eb)</p> </li> <li> <p>SQLite/3.36.0 (EasyConfig: SQLite-3.36.0.eb)</p> </li> </ul>","boost":10},{"location":"s/SQLite/#technical-documentation","title":"Technical documentation","text":"<ul> <li>SQLite web site</li> </ul>","boost":10},{"location":"s/SQLite/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>SQLite support in the EasyBuilders repository</p> </li> <li> <p>SQLite support in the CSCS repository</p> </li> </ul>","boost":10},{"location":"s/SQLite/#version-3360-static-for-system","title":"Version 3.36.0-static for SYSTEM","text":"<ul> <li>This is an installation for SQLite3 with fewer dependencies (based on a     CSCS EasyConfig) meant for inclusion in syslibs, a module of static libraries     used to build some tools that we want to run with minimal dependencies and compile     with the SYSTEM compiler.</li> </ul>","boost":10},{"location":"s/ScaLAPACK/","title":"ScaLAPACK","text":"<p>[package list]</p>","boost":10},{"location":"s/ScaLAPACK/#scalapack","title":"ScaLAPACK","text":"","boost":10},{"location":"s/ScaLAPACK/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider ScaLAPACK/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>ScaLAPACK/3.2-cpeCray-22.06-amd (EasyConfig: ScaLAPACK-3.2-cpeCray-22.06-amd.eb)</p> </li> <li> <p>ScaLAPACK/3.2-cpeCray-22.08-amd (EasyConfig: ScaLAPACK-3.2-cpeCray-22.08-amd.eb)</p> </li> <li> <p>ScaLAPACK/4.0-cpeCray-22.12-amd (EasyConfig: ScaLAPACK-4.0-cpeCray-22.12-amd.eb)</p> </li> <li> <p>ScaLAPACK/4.0-cpeGNU-22.12-amd-ILP64 (EasyConfig: ScaLAPACK-4.0-cpeGNU-22.12-amd-ILP64.eb)</p> </li> </ul>","boost":10},{"location":"s/ScaLAPACK/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>ScaLAPACK home page</p> </li> <li> <p>ScaLAPACK on GitHub</p> </li> <li> <p>AMD fork of ScaLAPACK in GitHub</p> </li> </ul>","boost":10},{"location":"s/ScaLAPACK/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support in the EasyBuilders repository</p> </li> <li> <p>There is no support in the CSCS repository.</p> </li> </ul>","boost":10},{"location":"s/ScaLAPACK/#version-31-for-cpe-2108","title":"Version 3.1 for CPE 21.08","text":"<ul> <li>Own EasyConfig, only superficially based on the EasyBuilders one.</li> </ul>","boost":10},{"location":"s/ScaLAPACK/#version-32-for-cpe-2206","title":"Version 3.2 for CPE 22.06","text":"<ul> <li> <p>Straightforward port of the 3.1 EasyConfig.</p> </li> <li> <p>Re-tried a Cray version also, but that still fails.</p> <ul> <li> <p>CMake adds the <code>-cpp</code> option to the Fortran compiler command line to force     preprocessing of <code>.f</code> files but that is not correct for the Cray compiler.     So one should edit <code>CMakeLists.txt</code> to replace <code>-cpp</code> with the roughly      equivalent Cray option <code>-eT</code>.</p> </li> <li> <p>But that is apparently not enough, compilation still breaks for the      <code>SRC/icopypv.f</code> file on line 89, with the message that a scalar integer expression     is needed as a subscript. It is unclear though why the expression in the code     is not considered a scalar integer expression by the compiler. The problem is that     the parameter <code>CTXT_</code>, though seemingly initialized with an integer, is considered     a floating point number by the compiler as any type declaration is missing.      The solution is to declare this parameter as an integer which is easily done      through a patch file.</p> </li> <li> <p>But then linking of the shared library still fails with undefined symbols for      the IDMIN and ISMIN functions,     and there are also a lot of warnings. Those IDMIN and ISMIN functions should be     in BLAS or an extension thereof so it is not clear why they are found in the     GNU version but not in the Cray version.</p> </li> </ul> </li> </ul>","boost":10},{"location":"s/Serf/","title":"Serf","text":"<p>[package list]</p>","boost":10},{"location":"s/Serf/#serf","title":"Serf","text":"","boost":10},{"location":"s/Serf/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Serf/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>Serf/1.3.9-static (EasyConfig: Serf-1.3.9-static.eb)</li> </ul>","boost":10},{"location":"s/Serf/#technical-documentation","title":"Technical documentation","text":"<ul> <li>Serf home page</li> </ul>","boost":10},{"location":"s/Serf/#problems","title":"Problems","text":"<p>Serf currently fails to compile due to several bugs combined</p> <ul> <li> <p>The .pc file of APR-util is wrong. It adds -lexpat to the libraries     as it should, but it doesn't add the path for the library though that     is correct in the .pc file of expat.</p> <p>However, even after fixing the pkgconfig file, Serf still fails to pick up all the linker flags.</p> </li> <li> <p>Moreover, LINKFLAGS is not correctly processed by the SConstruct script     of Serf. Otherwise this could be used to add the necessary -L option to     fix the problems.</p> </li> </ul> <p>Hence it looks like Serf can only be build when APR, APR-util and expat are bundled together as then the -L link flags for APR and APR-util would automatically also include the expat library.</p>","boost":10},{"location":"s/Serf/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Serf support in the EasyBuilders repository</p> </li> <li> <p>Serf support in the CSCS repository</p> </li> </ul>","boost":10},{"location":"s/Serf/#139-in-the-system-toolchain","title":"1.3.9 in the SYSTEM toolchain","text":"<ul> <li> <p>This EasyConfig is really meant to experiment with Serf in preparation     of inclusion in the syslibs bundle.</p> <p>In fact, it turns out that it is impossible to build Serf with the SYSTEM toolchain unless expat, APR andAPT-util come in a Bundle as there seems to be no robust way to tell the linker where to find the expat libraries.</p> </li> <li> <p>Used a patch to make the SConstruct script Python 3-compatible from the     EasyBuilders repository.</p> </li> <li> <p>There seems to be no way to build static libraries only, but as we want     to use this library purely as a build dependency, we simply remove the     shared libraries at the end.</p> <p>We keep it that way as long as the only package that uses Serf is Subversion, which we want to make as independent as possible from Cray toolchains and only dependent on some libraries in the OS, to ensure minimal interference with workflows.</p> </li> </ul>","boost":10},{"location":"s/Subversion/","title":"Subversion","text":"<p>[package list]</p>","boost":10},{"location":"s/Subversion/#subversion","title":"Subversion","text":"","boost":10},{"location":"s/Subversion/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Subversion/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>Subversion/1.14.1 (EasyConfig: Subversion-1.14.1.eb)</li> </ul>","boost":10},{"location":"s/Subversion/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>Subversion home page</p> <ul> <li>Source download for version check</li> </ul> </li> </ul>","boost":10},{"location":"s/Subversion/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Subversion support in the EasyBuilders repository</p> </li> <li> <p>Subversion support in the CSCS repository</p> </li> <li> <p>Subversion support in Spack</p> </li> </ul>","boost":10},{"location":"s/Subversion/#subversion-141-for-system","title":"Subversion 1.4.1 for SYSTEM","text":"<ul> <li> <p>Development started from the CSCS setup.</p> </li> <li> <p>Getting the dependencies to compile and find each other was a bit of a pain,     follow in our background repository.     In particular the compilation of Serf turned out to be rather difficult as it failed     to find the expat libraries when not included in a bundle with APR and APR-util,     probably because they were included as build dependencies and EasyBuild didn't     set all variables, but this is not sure.</p> </li> </ul>","boost":10},{"location":"s/seq-integer-headerlib/","title":"seq-integer-headerlib","text":"<p>[package list]</p>","boost":10},{"location":"s/seq-integer-headerlib/#seq-integer-headerlib","title":"seq-integer-headerlib","text":"","boost":10},{"location":"s/seq-integer-headerlib/#license-information","title":"License information","text":"<p>The <code>seq</code> library is licensed under an MIT license a copy of which can be found in the <code>LICENSE</code> file in the GitHub repository.</p>","boost":10},{"location":"s/seq-integer-headerlib/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider seq-integer-headerlib/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>seq-integer-headerlib/0.2.1 (EasyConfig: seq-integer-headerlib-0.2.1.eb)</li> </ul>","boost":10},{"location":"s/seq-integer-headerlib/#technical-documentation","title":"Technical documentation","text":"<p>As there are many different packages called <code>seq</code> , or with <code>seq</code> as part of their  name, we use a more descriptive name for the module.</p> <p>This is a pure header library.</p> <ul> <li> <p><code>seq</code> on GitHub</p> <ul> <li>Releases via GitHub tags</li> </ul> </li> </ul>","boost":10},{"location":"s/seq-integer-headerlib/#easybuild","title":"EasyBuild","text":"<p>There is no known EasyBuild or spack support for this package.</p>","boost":10},{"location":"s/seq-integer-headerlib/#seq-021-from-lumi2309-on","title":"seq 0.2.1 from LUMI/23.09 on","text":"<ul> <li> <p>The EasyConfig was developed specifically for LUMI as there were no prior ones. </p> </li> <li> <p>As this is a pure header file library, it is built with the SYSTEM toolchain so     that it can be used with all CPE toolchains.</p> </li> </ul>","boost":10},{"location":"s/snakemake/","title":"snakemake","text":"<p>[package list]</p>","boost":10},{"location":"s/snakemake/#snakemake","title":"snakemake","text":"","boost":10},{"location":"s/snakemake/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider snakemake/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>snakemake/6.9.1-cpeGNU-21.08-notOK (EasyConfig: snakemake-6.9.1-cpeGNU-21.08-notOK.eb)</p> </li> <li> <p>snakemake/6.9.1 (EasyConfig: snakemake-6.9.1.eb)</p> </li> </ul>","boost":10},{"location":"s/snakemake/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>Snakemake home page</p> </li> <li> <p>Snakemake on github.io</p> </li> <li> <p>Snakemake on PyPi</p> </li> <li> <p>Snakemake on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"s/snakemake/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>snakemake support in the EasyBuilders repository -     not very useful for building on top of Cray Python though.</p> </li> <li> <p>There is no snakemake support in the CSCS repository</p> </li> </ul>","boost":10},{"location":"s/snakemake/#691-for-cpe-2108","title":"6.9.1 for CPE 21.08","text":"<ul> <li> <p>We started with a clean sheet as we wanted to build on top of Cray Python.</p> </li> <li> <p>As Cray Python seems to simply rely on the system GCC, a version was build     using the SYSTEM toolchain.</p> </li> <li> <p>Some packages were not installed in the most recent version because they fail     in the sanity check of EasyBuild. Some relaxing may be needed as some recent     Python modules don't seem to return their version number in the way that     EasyBuild expects.</p> <p>The EasyBuild community may not even have a full solution for this at this time (EasyBuild 4.4.2 in October 2021) as even recent development EasyConfigs return to old versions of those packages.</p> </li> <li> <p>Also tried to make a cpeGNU version but that doesn't work yet. For some unknown     reason some packages install differently when <code>cpeGNU/21.08</code> is loaded.</p> <ul> <li> <p>The installation process breaks when installing <code>toposort</code>, complaining that a     <code>setup.py</code> is missing, but that doesn't seem to be an issue when installing     with the SYSTEM toolchain. In fact, there is a <code>pyproject.toml</code> which together     with <code>setup.cfg</code> should be sufficient, but for some reason it is not for an     EasyBuild-initiated process.</p> <p>A workarround is to install from a downloaded wheel.</p> </li> <li> <p>The installation process breaks when installing <code>datrie</code>. Here the error message     comes from setuptools, complaining that there is no attribute <code>__legacy__</code>.</p> <p>There is no easy solution here. One could install from a downloaded wheel but as this contains binary code, compatibility is not guaranteed.</p> <p>Falling back to an older version was also no option as that one does not support Python 3.8 and compilation fails.</p> </li> </ul> </li> </ul>","boost":10},{"location":"s/spdlog/","title":"spdlog","text":"<p>[package list]</p>","boost":10},{"location":"s/spdlog/#spdlog","title":"spdlog","text":"","boost":10},{"location":"s/spdlog/#license-information","title":"License information","text":"<p>The spdlog package is covered by an MIT license which can be found in the LICENSE file in the spdlog GitHub repository.</p> <p>After installing the software and loading the module, the <code>LICENSE</code> file can also be found in <code>$EBROOTSPDLOG/share/licenses/spdlog</code>.</p>","boost":10},{"location":"s/spdlog/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider spdlog/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>spdlog/1.14.1-cpeCray-23.09 (EasyConfig: spdlog-1.14.1-cpeCray-23.09.eb)</p> </li> <li> <p>spdlog/1.14.1-cpeGNU-23.09 (EasyConfig: spdlog-1.14.1-cpeGNU-23.09.eb)</p> </li> </ul>","boost":10},{"location":"s/spdlog/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>spdlog on GitHub</p> <ul> <li>GitHub releases</li> </ul> </li> </ul>","boost":10},{"location":"s/spdlog/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>spdlog support in the EasyBuilders repository</p> </li> <li> <p>There is no support for spdlog in the CSCS repository.</p> </li> <li> <p>spdlog support in Spack</p> </li> </ul>","boost":10},{"location":"s/spdlog/#version-1141-fore-cpegnu2309-and-cpecray2309","title":"Version 1.14.1 fore cpeGNU/23.09 and cpeCray/23.09","text":"<ul> <li> <p>The EasyConfig is based on the EasyBuilder ones, but changed to align     with the LUMI customs.</p> </li> <li> <p>For now, we build both shared and static libs even though the EasyBuilders     version only builds the static libs.</p> </li> <li> <p>We've also added testing the software during the build process.</p> </li> </ul>","boost":10},{"location":"s/stack/","title":"stack","text":"<p>[package list]</p>","boost":10},{"location":"s/stack/#stack","title":"stack","text":"","boost":10},{"location":"s/stack/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider stack/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>stack/25.03-cpeAMD-25.03-G-noOpenMP (EasyConfig: stack-25.03-cpeAMD-25.03-G-noOpenMP.eb)</p> </li> <li> <p>stack/25.03-cpeCray-25.03-G-noOpenMP (EasyConfig: stack-25.03-cpeCray-25.03-G-noOpenMP.eb)</p> </li> <li> <p>stack/25.03-cpeCray-25.03-LC-noOpenMP (EasyConfig: stack-25.03-cpeCray-25.03-LC-noOpenMP.eb)</p> </li> <li> <p>stack/25.03-cpeGNU-25.03-G-noOpenMP (EasyConfig: stack-25.03-cpeGNU-25.03-G-noOpenMP.eb)</p> </li> <li> <p>stack/25.03-cpeGNU-25.03-LC-noOpenMP (EasyConfig: stack-25.03-cpeGNU-25.03-LC-noOpenMP.eb)</p> </li> </ul>","boost":10},{"location":"s/syslibs/","title":"syslibs","text":"<p>[package list]</p>","boost":10},{"location":"s/syslibs/#syslibs","title":"syslibs","text":"","boost":10},{"location":"s/syslibs/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider syslibs/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>syslibs/15.1.0 (EasyConfig: syslibs-15.1.0.eb)</p> </li> <li> <p>syslibs/15.1.1-static (EasyConfig: syslibs-15.1.1-static.eb)</p> </li> <li> <p>syslibs/22.08-static-devel (EasyConfig: syslibs-22.08-static-devel.eb)</p> </li> <li> <p>syslibs/24.03-static-nocurses (EasyConfig: syslibs-24.03-static-nocurses.eb)</p> </li> </ul>","boost":10},{"location":"s/syslibs/#technical-documentation","title":"Technical documentation","text":"<p>This is a bundle of basic libraries all of which were also present on LUMI except one at the time of development, but without the development packages. They are all build as static libraries using the system GCC and are meant to be used as build dependencies for a number of tools that we want to be able to use without dependencies.</p> <p>Currently included are:   * ncurses   * libreadline   * bzip2   * zlib   * lz4   * expat   * APR and APR-util   * Serf   * file   * PCRE2   * SQLite3 (limited configuration, but enough for, e.g., subversion)</p> <p>For those libraries that are present on SUSE Linux, we tried to take the same versions as much as possible for optimal compatibility with other files that the libraries might use.</p>","boost":10},{"location":"s/syslibs/#easybuild","title":"EasyBuild","text":"","boost":10},{"location":"s/syslibs/#1510","title":"15.1.0","text":"<ul> <li>First version of this library. The 15.1 in the name comes from SLES15 update 1.</li> </ul>","boost":10},{"location":"s/syslibs/#1511-static","title":"15.1.1-static","text":"<ul> <li> <p>Added lz4, APR/APR-util. Serf and SQLite-3 so that the module can be used to build     Subversion.</p> </li> <li> <p>Added -static as a versionsuffix to stress that the package only provides static libraries     meant to be used as a build dependency and for consistency with other modules.</p> </li> <li> <p>We now had to include buildtools as a build dependency since Serf needs SCons which     is not available in the OS image.</p> </li> </ul>","boost":10},{"location":"s/systools/","title":"systools","text":"<p>[package list]</p>","boost":10},{"location":"s/systools/#systools","title":"systools","text":"","boost":10},{"location":"s/systools/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider systools/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>systools/15.1.0 (EasyConfig: systools-15.1.0.eb)</li> </ul>","boost":10},{"location":"t/tabulate-pranav/","title":"tabulate-pranav","text":"<p>[package list]</p>","boost":10},{"location":"t/tabulate-pranav/#tabulate-pranav","title":"tabulate-pranav","text":"","boost":10},{"location":"t/tabulate-pranav/#license-information","title":"License information","text":"<p>The tabulate code provided by the <code>tabulate-pranav</code> modules is covered by multiple licenses. The primary license is an MIT license that can be found in the <code>LICENSE</code> file of the GitHub repository.</p> <p>After installing and loading the module, the <code>LICENSE</code> file and other license-related files can also be found in <code>$EBROOTTABNULATEMINPRANOV/share/licenses/tabulate-pranov</code>.</p>","boost":10},{"location":"t/tabulate-pranav/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider tabulate-pranav/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>tabulate-pranav/1.5 (EasyConfig: tabulate-pranav-1.5.eb)</li> </ul>","boost":10},{"location":"t/tabulate-pranav/#technical-documentation","title":"Technical documentation","text":"<p>As this seems to be a rather little known header library and as we suspect there are many packages that are called <code>tabulate</code>, we've chosen to call this one <code>tabulate-pranav</code>.</p> <ul> <li> <p>tabulate GitHub</p> <ul> <li>Releases via GitHub tags</li> </ul> </li> </ul>","boost":10},{"location":"t/tabulate-pranav/#easybuild","title":"EasyBuild","text":"<p>At the time of first installation on LUMI, the package was not found in either EasyBuild or Spack.</p>","boost":10},{"location":"t/tabulate-pranav/#version-15-for-lumi2309","title":"Version 1.5 for LUMI/23.09","text":"<ul> <li> <p>The EasyConfig was developed specifically for LUMI as there were no prior ones. </p> </li> <li> <p>As this is a pure header file library, it is built with the SYSTEM toolchain so     that it can be used with all CPE toolchains.</p> </li> </ul>","boost":10},{"location":"t/talloc/","title":"talloc","text":"<p>[package list]</p>","boost":10},{"location":"t/talloc/#talloc","title":"talloc","text":"","boost":10},{"location":"t/talloc/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider talloc/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>talloc/2.4.2-static (EasyConfig: talloc-2.4.2-static.eb)</li> </ul>","boost":10},{"location":"t/talloc/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>talloc web page</p> </li> <li> <p>talloc downloads</p> </li> </ul>","boost":10},{"location":"t/talloc/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>There is no support for talloc in EasyBuild.</p> </li> <li> <p>Support for talloc in Spackhttps://packages.spack.io/package.html?name=talloc)</p> </li> </ul>","boost":10},{"location":"t/talloc/#version-242-static-for-the-system-toolchain","title":"Version 2.4.2 -static for the SYSTEM toolchain","text":"<ul> <li> <p>Developed a build procedure for a static version based on     https://github.com/green-green-avk/build-proot-android/blob/master/make-talloc-static.sh.</p> <p>This is done specifically for use in proot which we want to be a fully static executable.</p> </li> </ul>","boost":10},{"location":"t/tree/","title":"tree","text":"<p>[package list]</p>","boost":10},{"location":"t/tree/#tree","title":"tree","text":"","boost":10},{"location":"t/tree/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider tree/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>tree/1.8.0 (EasyConfig: tree-1.8.0.eb)</li> </ul>","boost":10},{"location":"t/tree/#technical-documentation","title":"Technical documentation","text":"<ul> <li>tree web page</li> </ul>","boost":10},{"location":"t/tree/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>There is no support for tree in the EasyBuilders repository</p> </li> <li> <p>Support for tree in the CSCS repository</p> </li> </ul>","boost":10},{"location":"t/tree/#version-180-for-the-system-toolchain","title":"Version 1.8.0 for the System toolchain","text":"<ul> <li>The EasyConfig file is a direct adaptation of the CSCS one.</li> </ul>","boost":10},{"location":"u/UnZip/","title":"UnZip","text":"<p>[package list]</p>","boost":10},{"location":"u/UnZip/#unzip","title":"UnZip","text":"","boost":10},{"location":"u/UnZip/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider UnZip/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>UnZip/6.0-cpeGNU-22.06 (EasyConfig: UnZip-6.0-cpeGNU-22.06.eb)</li> </ul>","boost":10},{"location":"u/UnZip/#technical-documentation","title":"Technical documentation","text":"<p>The UnZip module contains the Info-ZIP tools to inspect or uncompress zip files.</p> <ul> <li> <p>Info-ZIP UnZip home page</p> </li> <li> <p>Info-ZIP on SourceForge</p> </li> </ul>","boost":10},{"location":"u/UnZip/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support in the EasyBuilders repository</p> </li> <li> <p>There is no support for UnZip in the CSCS repository</p> </li> <li> <p>Spack package</p> </li> </ul>","boost":10},{"location":"u/UnZip/#version-60-for-cpegnu-2206-and-later","title":"Version 6.0 for cpeGNU 22.06 and later","text":"<ul> <li> <p>The EasyConfig is a straightforward adaptation of the EasyBuilders one for the     <code>GCCcore</code> toolchains, including the security patches in recent EasyBuild versions.</p> </li> <li> <p>It may need work for Clang-based compilers.</p> </li> </ul>","boost":10},{"location":"v/VirtualGL-UNFINISHED/","title":"VirtualGL-UNFINISHED","text":"<p>[package list]</p>","boost":10},{"location":"v/VirtualGL-UNFINISHED/#virtualgl-unfinished","title":"VirtualGL-UNFINISHED","text":"","boost":10},{"location":"v/VirtualGL-UNFINISHED/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider VirtualGL-UNFINISHED/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>VirtualGL-UNFINISHED/VirtualGL-3.0.1-cpeGNU-22.08 (EasyConfig: VirtualGL-3.0.1-cpeGNU-22.08.eb)</li> </ul>","boost":10},{"location":"v/VirtualGL-UNFINISHED/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>VirtualGL web site</p> </li> <li> <p> VirtualGL on GitHub</p> <ul> <li>VirtualGL releases</li> </ul> </li> </ul>","boost":10},{"location":"v/VirtualGL-UNFINISHED/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>VirtualGL support in the EasyBuilders repository</p> </li> <li> <p>There is no support for VirtualGL in the CSCS repository.</p> </li> </ul>","boost":10},{"location":"v/VirtualGL-UNFINISHED/#version-301-for-cpegnu2208","title":"Version 3.0.1 for cpeGNU/22.08","text":"<ul> <li> <p>The EasyConfig is derived from the EasyBuilders one for version 3.0 as no     newer one was available.</p> </li> <li> <p>The OpenCL/OpenGL interoperability feature is currently disabled to avoid      having to build the pocl dependency which then requires Clang which then     requires ...</p> </li> <li> <p>The code contains some dirty type casts so the error message advise to      turn on <code>-fpermissive</code>. </p> <p>This however still leaves some conflicting declarations that cannot be masked:</p> <ul> <li><code>XkbOpenDisplay</code> in <code>server/faker-x11.cpp</code> does not have the <code>const</code> attribute     for the first argument (or <code>_Xconst</code>).</li> </ul> </li> </ul> <p>Building the patch:</p> <pre><code>diff -ruN virtualgl-3.0.1/server/faker-x11.cpp.orig virtualgl-3.0.1/server/faker-x11.cpp\n</code></pre> <p>UNFINBISHED: Cannot find how to use this properly.</p> <p>TODO: It looks like we need to use EGL and that it will only work on nodes with a GPU.  EGL ensures that VirtualGL can talk directly to the GPU driver stack and doesn't need the help of an X server.</p>","boost":10},{"location":"x/X11/","title":"X11","text":"<p>[package list]</p>","boost":10},{"location":"x/X11/#x11","title":"X11","text":"","boost":10},{"location":"x/X11/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider X11/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>X11/21.08-cpeCray-21.08-extended (EasyConfig: X11-21.08-cpeCray-21.08-extended.eb)</p> </li> <li> <p>X11/21.08-cpeGNU-21.08-extended (EasyConfig: X11-21.08-cpeGNU-21.08-extended.eb)</p> </li> </ul>","boost":10},{"location":"x/xmlto/","title":"xmlto","text":"<p>[package list]</p>","boost":10},{"location":"x/xmlto/#xmlto","title":"xmlto","text":"","boost":10},{"location":"x/xmlto/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider xmlto/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>xmlto/0.0.28 (EasyConfig: xmlto-0.0.28.eb)</li> </ul>","boost":10},{"location":"z/Zip/","title":"Zip","text":"<p>[package list]</p>","boost":10},{"location":"z/Zip/#zip","title":"Zip","text":"","boost":10},{"location":"z/Zip/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Zip/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li>Zip/3.0-cpeGNU-22.06 (EasyConfig: Zip-3.0-cpeGNU-22.06.eb)</li> </ul>","boost":10},{"location":"z/Zip/#technical-documentation","title":"Technical documentation","text":"<p>The Zip module contains the Info-ZIP compression tools, but not the <code>unzip</code> command.</p> <ul> <li> <p>Info-ZIP Zip home page</p> </li> <li> <p>Info-ZIP on SourceForge</p> </li> </ul>","boost":10},{"location":"z/Zip/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>Support in the EasyBuilders repository</p> </li> <li> <p>There is no support for Zip in the CSCS repository</p> </li> <li> <p>Spack package</p> </li> </ul>","boost":10},{"location":"z/Zip/#version-30-for-cpegnu-2206-and-later","title":"Version 3.0 for cpeGNU 22.06 and later","text":"<ul> <li> <p>The EasyConfig is a straightforward adaptation of the EasyBuilders one for the     <code>GCCcore</code> toolchains.</p> </li> <li> <p>It may need work for Clang-based compilers.</p> </li> </ul>","boost":10},{"location":"z/Zoltan/","title":"Zoltan","text":"<p>[package list]</p>","boost":10},{"location":"z/Zoltan/#zoltan","title":"Zoltan","text":"","boost":10},{"location":"z/Zoltan/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider Zoltan/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>Zoltan/3.90-cpeAMD-21.08-minimal (EasyConfig: Zoltan-3.90-cpeAMD-21.08-minimal.eb)</p> </li> <li> <p>Zoltan/3.90-cpeCray-21.08-minimal (EasyConfig: Zoltan-3.90-cpeCray-21.08-minimal.eb)</p> </li> <li> <p>Zoltan/3.90-cpeGNU-21.08-minimal (EasyConfig: Zoltan-3.90-cpeGNU-21.08-minimal.eb)</p> </li> </ul>","boost":10},{"location":"z/Zoltan/#technical-documentation","title":"Technical documentation","text":"<ul> <li> <p>Zoltan web site</p> </li> <li> <p>Zoltan on GitHub</p> </li> </ul> <p>Zoltan is part of Trilinos but can also be installed independently which is what these EasyConfigs do.</p>","boost":10},{"location":"z/Zoltan/#easybuild","title":"EasyBuild","text":"<ul> <li> <p>There is no support for Zoltan in the EasyBuilders repository</p> </li> <li> <p>There is no support for Zoltan in the CSCS repository</p> </li> <li> <p>Zoltan support in Spack</p> </li> </ul>","boost":10},{"location":"z/Zoltan/#version-390-for-cpe-2108","title":"Version 3.90 for CPE 21.08","text":"<ul> <li> <p>Building with CMake doesn't work as there are files from Trilinos     missing.</p> </li> <li> <p>Building with configure gives problems also as the packages wants     configure to be run in a separate directory. We solve this by adding     <code>mkdir build &amp;&amp; cd build &amp;&amp; ln -s ../configure &amp;&amp;</code> to <code>preconfigopts</code>     and <code>cd build &amp;&amp;</code> to <code>prebuildopts</code> and <code>preinstallopts</code>.</p> </li> <li> <p>The Fortran 90 interfaces produce the infamous type mismatch error message     when using gfortran 10, so we enabled the toolchain option <code>gfortran90-compat</code>     when using cpeGNU.</p> </li> <li> <p>The Fortran 90 interfaces fail to build with the Cray compiler. This is somewhat     strange as the Cray build script suggests they should work, but it may be that     that build script has only been tested with older versions of Zoltan. Cray does     build Trilinos without the support for ParMETIS and Scotch.</p> <p>The error message is very strange: Make complains that it has no rules to make one of the module files, but when using cpeGNU or cpeAMD it does find the rule.</p> </li> </ul>","boost":10},{"location":"z/zlib/","title":"zlib","text":"<p>[package list]</p>","boost":10},{"location":"z/zlib/#zlib","title":"zlib","text":"","boost":10},{"location":"z/zlib/#available-modules-and-corresponding-easyconfigs","title":"Available modules and corresponding EasyConfigs","text":"<p>Install with the EasyBuild-user module: <pre><code>eb &lt;easyconfig&gt; -r\n</code></pre> To access module help after installation and get reminded for which stacks and partitions the module is installed, use <code>module spider zlib/&lt;version&gt;</code>.</p> <p>EasyConfig:</p> <ul> <li> <p>zlib/1.2.11-static (EasyConfig: zlib-1.2.11-static.eb)</p> </li> <li> <p>zlib/1.2.12-cpeAMD-22.08-test (EasyConfig: zlib-1.2.12-cpeAMD-22.08-test.eb)</p> </li> <li> <p>zlib/1.2.12-cpeAOCC-22.05-CMakeMake (EasyConfig: zlib-1.2.12-cpeAOCC-22.05-CMakeMake.eb)</p> </li> <li> <p>zlib/1.2.12-cpeAOCC-22.05-ConfigureMake (EasyConfig: zlib-1.2.12-cpeAOCC-22.05-ConfigureMake.eb)</p> </li> <li> <p>zlib/1.2.12-cpeAOCC-22.08-test (EasyConfig: zlib-1.2.12-cpeAOCC-22.08-test.eb)</p> </li> <li> <p>zlib/1.2.12-cpeCray-22.05-CMakeMake (EasyConfig: zlib-1.2.12-cpeCray-22.05-CMakeMake.eb)</p> </li> <li> <p>zlib/1.2.12-cpeCray-22.05-ConfigureMake (EasyConfig: zlib-1.2.12-cpeCray-22.05-ConfigureMake.eb)</p> </li> <li> <p>zlib/1.2.12-cpeCray-22.08-test (EasyConfig: zlib-1.2.12-cpeCray-22.08-test.eb)</p> </li> <li> <p>zlib/1.2.12-cpeGNU-22.05-CMakeMake (EasyConfig: zlib-1.2.12-cpeGNU-22.05-CMakeMake.eb)</p> </li> <li> <p>zlib/1.2.12-cpeGNU-22.05-ConfigureMake (EasyConfig: zlib-1.2.12-cpeGNU-22.05-ConfigureMake.eb)</p> </li> </ul>","boost":10}]}
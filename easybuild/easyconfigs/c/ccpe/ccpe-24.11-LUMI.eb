# Developed by Kurt Lust for LUMI
# Before installing set the secret source path of the container in 
# EASYBUILD_SOURCEPATH.
#DOC This module provides a modified version of the CPE container as it comes from HPE.
#DOC The goal is to integrate it better with the current LUMI environment. Changes to the
#DOC container are also made through this EasyConfig, so you may use it as a template to
#DOC adapt the CPE containers to your needs.
#DOC
#DOC As this EasyConfig needs access to the `proot` command, it cannot be used with `partition/container`
#DOC but should install in a software stack. For this EasyConfig, we recommend running EasyBuild in
#DOC `LUMI/24.03 partition/common`.
easyblock = 'MakeCp'

import os as local_os
local_LUMI_version = local_os.environ['LUMI_STACK_CPE_VERSION'] # Version used for systools

name =          'ccpe'
version =       '24.11'
versionsuffix = '-LUMI'

local_ccpe_version = ''.join(version.split('.'))
local_sif = f'cpe_{local_ccpe_version}.sif'

homepage = 'https://cpe.ext.hpe.com/docs/24.11/index.html'

whatis = [
    'Description: Containerised HPE-Cray Programming Environment'
]

description = f"""
This version provides the {version} programming environment in a container
to start experimenting with this version before it is generally available
on LUMI.

This version of the container is enhanced with some additional SUSE packages
to be more suited for developement for software in the LUMI software stacks.

The module sets the necessary bindings to be able to access regular user
files on LUMI, to import some bits and pieces that are not in the container,
and to be able to call Slurm from within the container.

The module defines a number of environment variables:
*   SIF and SIFCCPE: The full path and name of the Singularity SIF file 
    to use with singularity exec etc.
    
Inside the container only:
*   INITCCPE: `eval $INITCCPE` can be used to fully re-initialise the 
    environment in the container.
    
Helper scripts outside the container:
*   `ccpe-shell` starts a shell in the container using `singularity shell`.
*   `ccpe-exec` executes the command passed as arguments in the container 
    using `singularity exec`.
"""

toolchain = SYSTEM

sources = [
    {
        'filename':    local_sif,
        'extract_cmd': '/bin/cp -L %s .'
    },
]

builddependencies = [
    ('systools', local_LUMI_version),
]

skipsteps = ['build']

files_to_copy = [
    ([local_sif], '.'),
]


################################################################################
#
# Script Container definition for `singularity build`.
#
local_container_def = f"""
Bootstrap: localimage

From: {local_sif}

%environment

    export BASH_ENV=/opt/cray/pe/lmod/lmod/init/bash

%files

    %(installdir)s/config/99-z-init-ccpe.sh /.singularity.d/env
    %(installdir)s/config/profile.local     /etc
    %(installdir)s/config/bash.bashrc.local /etc
    %(installdir)s/config/runscript         /.singularity.d
    /etc/group
    /etc/passwd
    /etc/slurm/slurm.conf

%post

     # Install additional packages
#    zypper -n --no-gpg-checks addrepo https://download.opensuse.org/distribution/leap/15.5/repo/oss/ oss
    
#    zypper -n --no-gpg-checks --no-refresh install --no-recommends --allow-downgrade --oldpackage libopenssl-devel
#    zypper -n --no-gpg-checks --no-refresh install --no-recommends --allow-downgrade --oldpackage libcurl-devel
#    zypper -n --no-gpg-checks --no-refresh install --no-recommends --allow-downgrade --oldpackage unzip
#    zypper -n --no-gpg-checks --no-refresh install --no-recommends --allow-downgrade --oldpackage glibc-devel-static
    
    # Tweak Lmod to use a different cache directory
    sed -e 's|.cache/lmod|.cache/lmod/ccpe-{version}{versionsuffix}|' -i /opt/cray/pe/lmod/lmod/libexec/myGlobals.lua
    
    # No longer needed, we prefer to bind the system one to always be up-to-date.
    /bin/rm -rf /etc/slurm

""".replace( '$', '\\$' )


################################################################################
#
# Runscript for the container
#
local_runscript = """
#!/bin/bash
#
# This is the most basic runscript possible: "singularity run" for this
# container, starts "bash" and as the "singularity run" prescribes,
# all arguments are simply passed to bash.
#
/usr/bin/bash "$@"

""".replace( '$', '\\$' )


################################################################################
#
# Script 99-z-init-ccpe.sh
#
# Initialisation script for /etc/profile.d
#
local_99_z_ccpe_init = """
export INITCCPE='
if [ "$CCPE_VERSION" != "24.11" ] ;
then

    lmod_dir="/opt/cray/pe/lmod/lmod" ;
        
    function clear-lmod() { [ -d $HOME/.cache/lmod ] && /bin/rm -rf $HOME/.cache/lmod ; } ;
    
    source /etc/cray-pe.d/cray-pe-configuration.sh ;
    
    source $lmod_dir/init/profile ;
    
    mod_paths="/opt/cray/pe/lmod/modulefiles/core /opt/cray/pe/lmod/modulefiles/craype-targets/default $mpaths /opt/cray/modulefiles /opt/modulefiles" ;
    MODULEPATH="" ;
    for p in $(echo $mod_paths) ; do 
        if [ -d $p ] ; then
            MODULEPATH=$MODULEPATH:$p ;
        fi
    done ;
    export MODULEPATH=${MODULEPATH/:/} ;
    
    LMOD_SYSTEM_DEFAULT_MODULES=$(echo ${init_module_list:-PrgEnv-$default_prgenv} | sed -E "s_[[:space:]]+_:_g") ;
    export LMOD_SYSTEM_DEFAULT_MODULES ;
    eval "source $BASH_ENV && module --initial_load --no_redirect restore" ;
    unset lmod_dir ;
    
fi ;

export CCPE_VERSION="%(version)s"
'

""".replace( '$', '\\$' )


################################################################################
#
# Custom script /etc/bash.bashrc.local
#
local_bashrc_local = """
#! /bin/sh

eval $INITCCPE

""".replace( '$', '\\$' )


################################################################################
#
# Custom script /etc/profile.local
#
#
local_profile_local = """

# Currently empty

""".replace( '$', '\\$' )


################################################################################
#
# Script clearLmod-save
#
# A script that defines a function that can be used to clear Lmod while saving
# some environment variables that were set by Lmod.
#
local_clearLmod_save = """
#!/bin/bash

function clearLmod-save {
    # The arguments are the variables set by Lmod that should be restored.

    # Save the variables that should be restored
    for var in "$@"
    do
        eval save_$var="'${!var}'"
    done

    # Now clean up
    module --force purge
    eval $($LMOD_DIR/clearLMOD_cmd --shell bash --full --quiet)
    unset LUMI_INIT_FIRST_LOAD
    ## Make sure that /etc/profile does not quit immediately when called.
    unset PROFILEREAD

    # Restore the variables
    for var in "$@"
    do
        varname="save_$var"
        eval export $var="'${!varname}'"
        unset $varname
    done

}

""".replace( '$', '\\$' )

################################################################################
#
# Script ccpe-shell
#
# Start a shell in the container with proper initialisation.
#
local_ccpe_shell="""
#!/bin/bash

source %(installdir)s/config/clearLmod-save

if [ "$CCPE_VERSION" != "24.11" ]
then
    clearLmod-save SIF SIFCCPE SINGULARITY_BIND SINGULARITYENV_PS1
fi

singularity shell "$SIFCCPE" "$@"

""".replace( '$', '\\$' )


################################################################################
#
# Script ccpe-exec
#
# Execute in the container with proper initialisation.
#
local_ccpe_exec = """
#!/bin/bash

source %(installdir)s/config/clearLmod-save

if [ "$CCPE_VERSION" != "24.11" ]
then
    clearLmod-save SIF SIFCCPE SINGULARITY_BIND SINGULARITYENV_PS1
fi

singularity exec "$SIFCCPE" "$@"

""".replace( '$', '\\$' )


################################################################################
#
# Script ccpe-run
#
# Run the container with proper initialisation.
#
local_ccpe_run = """
#!/bin/bash

source %(installdir)s/config/clearLmod-save

if [ "$CCPE_VERSION" != "24.11" ]
then
    clearLmod-save SIF SIFCCPE SINGULARITY_BIND SINGULARITYENV_PS1
fi

singularity run "$SIFCCPE" "$@"

""".replace( '$', '\\$' )


################################################################################
#
# Script ccpe-singularity
#
# Run singularity with proper initialisation.
#
local_ccpe_singularity = """
#!/bin/bash

source %(installdir)s/config/clearLmod-save

if [ "$CCPE_VERSION" != "24.11" ]
then
    clearLmod-save SIF SIFCCPE SINGULARITY_BIND SINGULARITYENV_PS1
fi

singularity "$@"

""".replace( '$', '\\$' )


################################################################################
#
# EasyBuild build commands
#
postinstallcmds = [
    # First copy files that we want to inject in the container
    'mkdir -p %(installdir)s/config',
    f'cat >%(installdir)s/config/runscript <<EOF {local_runscript}EOF',
    'chmod a+rx %(installdir)s/config/runscript',
    f'cat >%(installdir)s/config/99-z-init-ccpe.sh <<EOF {local_99_z_ccpe_init}EOF',
    'chmod a+rx %(installdir)s/config/99-z-init-ccpe.sh',
    f'cat >%(installdir)s/config/bash.bashrc.local <<EOF {local_bashrc_local}EOF',
    'chmod a+rx %(installdir)s/config/bash.bashrc.local',
    f'cat >%(installdir)s/config/profile.local <<EOF {local_profile_local}EOF',
    'chmod a+rx %(installdir)s/config/profile.local',
    # Now create the definition file
    f'cat >%(installdir)s/config/ccpe-additional-packages.def <<EOF {local_container_def}EOF',
    'chmod a+r %(installdir)s/config/ccpe-additional-packages.def',
    #'false',
    # Build the container
    # We need to bind Slurm to keep the license check happy?
    f'cd %(installdir)s && SINGULARITY_CACHEDIR=/tmp SINGULARITY_TMPDIR=/tmp singularity build --force {local_sif} %(installdir)s/config/ccpe-additional-packages.def',
    # Install scripts that run outside the container
    'mkdir -p %(installdir)s/bin',
    f'cat >%(installdir)s/config/clearLmod-save <<EOF {local_clearLmod_save}EOF',
    'chmod a+rx %(installdir)s/config/clearLmod-save',
    f'cat >%(installdir)s/bin/ccpe-shell <<EOF {local_ccpe_shell}EOF',
    'chmod a+rx %(installdir)s/bin/ccpe-shell',
    f'cat >%(installdir)s/bin/ccpe-exec <<EOF {local_ccpe_exec}EOF',
    'chmod a+rx %(installdir)s/bin/ccpe-exec',
    f'cat >%(installdir)s/bin/ccpe-run <<EOF {local_ccpe_run}EOF',
    'chmod a+rx %(installdir)s/bin/ccpe-run',
    f'cat >%(installdir)s/bin/ccpe-singularity <<EOF {local_ccpe_singularity}EOF',
    'chmod a+rx %(installdir)s/bin/ccpe-singularity',
]

sanity_check_paths = {
    'files': [local_sif],
    'dirs':  ['bin', 'config'],
}

local_expected_cce = '18.0.1'

sanity_check_commands = [
    # The next test will check if modules are correctly initialised and if the correct cce
    # module is present.
    f'echo "INFO: Testing if cce/{local_expected_cce} is present" ; ccpe-singularity exec "$SIFCCPE" bash -i -c \'module --terse list\' |& grep -q "cce/{local_expected_cce}"',
    # Check if libfabric is loaded correctly and if it is the version of the system.
    'echo "INFO: Checking if the system libfabric is loaded by default." ; module load libfabric && test $(ccpe-singularity exec "$SIFCCPE" bash -i -c \'module --terse list\' |& grep "libfabric") = $(module --terse list |& grep "libfabric")',  
    # Check if the CXI provider is found.
    'echo "INFO: Checking for the CXI provider." ; ccpe-singularity exec "$SIFCCPE" bash -i -c \'fi_info\' | egrep -q "provider:[[:space:]]+cxi"',
    # Test of the Slurm integration
    'echo "INFO: Checking Slurm sinfo command." ; ccpe-exec sinfo | grep -q standard-g',
    #
    # Tried testing with ccpe-run or ccpe-singularity run also but for some reason, this does not work in Easybuild,
    # and the runscript gets stuck, possibly trying to use a terminal which is not there. So even though running
    # something with `singularity run` seems to work on the command line, it may not work in batch mode.
]


################################################################################
#
# Custom module that does a lot of the magic.
#
modextravars = {
    'SIF':     '%(installdir)s/' + local_sif,
    'SIFCCPE': '%(installdir)s/' + local_sif,
    # The next line is very tricky as both Python and LUA interprete escape sequences in this string.
    # In the shell, we want PS1='\[\e[91m\]Container::\[\e[00m\] \u@\h:\w >'
    # In Lmod, we need setenv( 'SINGULARITYENV_PS1', '\\[\\e[91m\\]Container::\\[\\e[00m\\] \\u@\\h:\\w > ' )
    # And in Python for EasyBuild, this then becomes:
    'SINGULARITYENV_PS1': '\\\\[\\\\e[91m\\\\]Container::\\\\[\\\\e[00m\\\\] \\\\u@\\\\h:\\\\w > ',
}

local_singularity_bind = ','.join( [ # Add bindings here!
    # Files generated by this EasyConfig
    # The following ones are injected in the container already.
    #'%(installdir)s/config/runscript:/.singularity.d/runscript',                    # Overwrite the runscript
    #'%(installdir)s/config/99-z-init-ccpe.sh:/.singularity.d/env/99-z-init-ccpe.sh', # Set INITCCPE 
    #'%(installdir)s/config/bash.bashrc.local:/etc/bash.bashrc.local',                # Properly initialise the module environment
    #'%(installdir)s/config/profile.local:/etc/profile.local',                        # For possible future use, currently empty
    
    # Lustre storage
    '/pfs',
    '/users',
    '/projappl',
    '/project',
    '/scratch',
    '/flash',
    '/appl',

    # GPU SDK mounts
    # Customize these locations per-system
    # GPU SDK mounts
    # Customize these locations per-system
    '/opt/cray/pe/lmod/modulefiles/core/rocm/6.0.3.lua', # module --loc --redirect show rocm
    '/opt/cray/pe/lmod/modulefiles/core/amd/6.0.3.lua',  # module --loc --redirect show amd
    '/opt/rocm-6.0.3',                                   # module --redirect show rocm | grep ROCM_PATH | awk -F'"' '{ print $4 }'
    '/usr/lib64/pkgconfig/rocm-6.0.3.pc',                # echo "$(module --redirect show rocm | grep PKG_CONFIG_PATH | awk -F'"' '{ print $4 }')/$(module --redirect show rocm | grep PE_PKGCONFIG_LIBS | awk -F'"' '{ print $4 }').pc"
    # Do we need to bind /dev/kfd and /dev/dri? They seem to be in the container by default.

    # System libfabric install: Different from the ccpe-config script as that was for Red Hat
    # For the modules, binding the specific version is not enough as that would leave the newer
    # module in the container.
    '/opt/cray/libfabric/1.15.2.0',    # module --redirect show libfabric | grep '"PATH"' | awk -F'"' '{ print $4 }' | sed -e 's|/bin||'
    '/opt/cray/modulefiles/libfabric', # module --loc --redirect show libfabric | sed -e 's|\(.*libfabric.*\)/.*|\1|'
    '/usr/lib64/libcxi.so.1',          # ldd $(module --redirect show libfabric | grep '"LD_LIBRARY_PATH"' | awk -F'"' '{ print $4 }')/libfabric.so | grep libcxi | awk '{print $3}'
    
    # System mounts - List from Alfio webinar
    '/var/spool',
    '/run/cxi',
    '/etc/host.conf',
    '/etc/nsswitch.conf',
    '/etc/resolv.conf',
    '/etc/ssl/openssl.cnf',
    # Additional one for the specific setup of the container in this module
    '/etc/cray-pe.d/cray-pe-configuration.sh',

    # Slurm mounts
    '/etc/slurm', # Even if Slurm support does not yet work, we need this to detect we're on LUMI.
    '/usr/bin/sacct',
    '/usr/bin/salloc',
    '/usr/bin/sattach',
    '/usr/bin/sbatch',
    '/usr/bin/sbcast',
    '/usr/bin/scontrol',
    '/usr/bin/sinfo',
    '/usr/bin/squeue',
    '/usr/bin/srun',
    '/usr/lib64/slurm',
    '/var/spool/slurmd',
    '/var/run/munge',
    '/usr/lib64/libmunge.so.2',
    '/usr/lib64/libmunge.so.2.0.0',
    '/usr/include/slurm',

] )

modluafooter = f"""

-- Set the bind mounts
prepend_path( 'SINGULARITY_BIND', '{local_singularity_bind}', ',' )

-- Inject some configuration files from LUMI.
-- These are currently done in the main list (first one) or included in the container.
-- prepend_path( 'SINGULARITY_BIND', '/etc/cray-pe.d/cray-pe-configuration.sh:/etc/cray-pe.d/cray-pe-configuration.sh', ',' )
-- prepend_path( 'SINGULARITY_BIND', '%(installdir)s/config/99-z-init-ccpe.sh:/.singularity.d/env/99-z-init-ccpe.sh', ',' )
-- prepend_path( 'SINGULARITY_BIND', '%(installdir)s/config/bash.bashrc.local:/etc/bash.bashrc.local', ',' ) -- Or could chose to take the one from the system.
-- prepend_path( 'SINGULARITY_BIND', '%(installdir)s/config/profile.local:/etc/profile.local', ',' )

"""

moduleclass = 'devel'
